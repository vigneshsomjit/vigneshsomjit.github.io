[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nVignesh Somjit\n",
    "section": "",
    "text": "Vignesh Somjit\n\n\nI am a Research Professional at the University of Chicago Booth School of Business, where I work with Professor Richard Hornbeck. Before joining Booth, I received my B.A. in Economics (with honors) and B.A. in Mathematics from Boston University in 2025. I maintain a research blog, where I write about topics in math, econometrics, statistics, and machine learning."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Vignesh Somjit",
    "section": "About Me",
    "text": "About Me\nI am a Research Professional at the University of Chicago Booth School of Business, where I work with Professor Richard Hornbeck. I received my B.A. in Economics and B.A. in Mathematics from Boston University in 2025."
  },
  {
    "objectID": "blog/blog-index.html",
    "href": "blog/blog-index.html",
    "title": "Vignesh Somjit",
    "section": "",
    "text": "Statistical Inference II: Point Estimation\n\n\n\n\n\n\nMathematical Statistics\n\n\n\nI describe point estimation under the frequentist framework and motivate the need for statistical models.\n\n\n\n\n\nOct 13, 2025\n\n\n\n\n\n\n\nStatistical Inference III: Hypothesis Testing and Confidence Intervals\n\n\n\n\n\n\nMathematical Statistics\n\n\n\nI introduce key concepts in hypothesis testing using the running example of the normal sampling model.\n\n\n\n\n\nOct 13, 2025\n\n\n\n\n\n\n\nStatistical Inference I: Random Sampling\n\n\n\n\n\n\nMathematical Statistics\n\n\n\nIntroducing frequentist statistical inference under the random sampling framework.\n\n\n\n\n\nOct 13, 2025\n\n\n\n\n\n\n\nSummary Index\n\n\n\n\n\n\nMathematical Statistics\n\n\n\nI provide a detailed treatment of the summary index used in Anderson (2008) for multiple inference.\n\n\n\n\n\nOct 13, 2025\n\n\n\n\n\n\n\nBasic Concepts in Linear Algebra\n\n\n\n\n\n\nLinear Algebra\n\n\n\nDiscussion of fundamental concepts in linear algebra, including vector spaces, linear combination and independence, basis vectors, and subspaces.\n\n\n\n\n\nSep 20, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/regressions.html",
    "href": "blog/regressions.html",
    "title": "An Applied Econometrics Rationale for Linear Regression",
    "section": "",
    "text": "Regression Approximates Conditional Averages\nWe are interested in predicting the value of a random variable \\(Y_i\\), called the outcome, given some realized value of a random vector \\(X_i\\) of covariates. As a starting point, we let our predictions be a function of \\(X_i\\) and want our predictions to minimize the mean squared error (MSE) objective function\n\\[\n\\mathbb{E} [Y_i - f(X_i)]^2.\n\\] With the law of iterated expectation and some calculus, we can show that for every possible realized value \\(X_i = x\\), the optimal function that solves the minimum mean squared error problem is the conditional expectation function (CEF)\n\\[\n\\mu(x) = \\mathbb{E}[Y_i | X_i = x].\n\\]\nIn most empirical cases, however, the CEF of interest has no analytic form. Thus, it is more practical to model the relationship between the outcome and covariates using a simpler function. One option is to find a linear approximation of the CEF, which takes the form\n\\[\n\\ell(x) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_k x_k = x^T\\beta.\n\\]\nNote that the word “linear” here refers to the simplifying assumption that the function is a linear combination of the covariates. Since we want our predictions to minimize the MSE function, the best linear predictor is found by setting the coefficients as\n\\[\n\\beta^\\star = \\underset{\\beta}{\\arg\\min} \\, \\mathbb{E} [Y_i - (X_i^T \\beta)]^2 = \\mathbb{E}[X_i X_i^T]^{-1}\\mathbb{E}[X_iY_i].\n\\] Thus, the linear regression model that describes the relationship between \\(Y_i\\) and \\(X_i\\) is given by \\[\nY_i = \\underbrace{X_i^T \\beta^\\star}_{\\text{best linear predictor}} + \\underbrace{\\epsilon_i}_{\\text{residual}},\n\\] where \\(\\epsilon_i\\) captures the difference between the realized outcome and the best linear predictor.\nTo summarize, the conditional expectation function is the optimal predictor of an outcome given covariates, in the sense that it minimizes the mean squared prediction error. Since the CEF is typically a complex function, linear regression approximates it by selecting the linear combination of covariates that minimizes the mean squared error. The resulting linear predictor provides a simple model of the relationship between the outcome and the covariates.\n\n\nApproximate and Exact Conditional Averages\n\nset.seed(123)\n\n# Sample size \nn &lt;- 1000 \n\n# Covariates\nsex &lt;- rbinom(n, 1, 0.5)\nrace &lt;- rbinom(n, 1, 0.3)                   \n\n# Non-linear data generating process; no interactions\noutcome1 &lt;- 5 + 2^sex + 3^race \n\n# Non-linear data generating process; interactions \noutcome2 &lt;- 5 + 2^sex + 3^race + 1.5^(sex*race)\n\n# Consolidate in a dataset \ndf &lt;- data.frame(\n  outcome1 = outcome1,\n  outcome2 = outcome2,\n  sex = sex,\n  race = race\n)"
  },
  {
    "objectID": "blog/random-sampling.html",
    "href": "blog/random-sampling.html",
    "title": "Random Sampling and Model-Based Inference",
    "section": "",
    "text": "Observational data is inherently random: if we were to measure the same variables repeatedly, we would almost certainly get different values each time. A classical explanation for the source of this randomness is the model-based (or sampling-based) perspective. In this abstraction, we assume there exists an underlying superpopulation or data generating process (DGP): a fixed but unknown probability distribution \\(F\\) that can, in principle, generate infinitely many observations. Randomness then arises because we only observe finitely many realizations from \\(F\\) — never the entire distribution. Within this framework, we define statistical inference as the process of using the observed random data to estimate features of \\(F\\) and quantify the uncertainty in those estimates.\nNotice that the exposition above implicitly assumes that there is a single underlying distribution \\(F\\) from which all observed data are drawn. To make this mathematically precise, we need to introduce the random sampling assumption. This provides the framework to connect the observed data to the DGP, and thereby lays the foundation for statistical inference."
  },
  {
    "objectID": "blog/random-sampling.html#mathematical-formalization-of-observational-datasets",
    "href": "blog/random-sampling.html#mathematical-formalization-of-observational-datasets",
    "title": "Random Sampling Framework",
    "section": "",
    "text": "Cross-sectional datasets consist of several observations of a collection of variables for a given point in time and can be denoted as\n\\[\n\\{x_{1i}, x_{2i}, \\ldots, x_{Ki}\\}_{i=1}^n,\n\\]\nwhere \\(x_{ki}\\) is the value of the \\(k\\)-th variable for the \\(i\\)-th observation. A typical source of cross-sectional data in economics is through surveys like the Current Population Survey (CPS) or the American Community Survey (ACS).\nWe are interested in making statements about the underlying process that generates the dataset. In statistics, we do this by mathematically formalizing the way the data was generated. Specifically, we view each observational vector \\[\n\\boldsymbol{x}_i = (x_{1i}, \\ldots, x_{Ki})' \\in \\mathbb{R}^k \\quad \\text{for } i = 1, \\ldots, n,\n\\] as a realization of the random vector \\[\n\\boldsymbol X_i = (X_{1i}, \\ldots, X_{K_i})' \\in \\mathbb{R}^k \\quad \\text{for } i = 1, \\ldots, n,\n\\]\nwith some associated probability distribution. For example, we can think of the CPS dataset as consisting of random vectors\n\\[\n\\boldsymbol X_i = (sex_i, age_i, educ_i, wage_i)' \\quad \\text{for } i = 1, \\ldots, n.\n\\] For some specific individual \\(i\\) in the CPS dataset, we then observe the vector of realized values1\n\\[\n\\boldsymbol x_i = (1, 25, 16, 25000)'.\n\\] Intuitively, the distinction between the random vector \\(\\boldsymbol X_i\\) and the realization \\(\\boldsymbol x_i\\) is that the former represents the \\(i\\)-th observation before viewing the data (unknown and random) and the latter represents the \\(i\\)-th observation after viewing the data (specific known value)."
  },
  {
    "objectID": "blog/random-sampling.html#random-sampling-assumption",
    "href": "blog/random-sampling.html#random-sampling-assumption",
    "title": "Random Sampling Framework",
    "section": "Random Sampling Assumption",
    "text": "Random Sampling Assumption\nThe assumption of random sampling is a characterization of the probability distribution of the random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\).\n\nRandom Sampling Assumption. The random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are mutually independent and have the same probability distribution \\(F(X_1, \\ldots, X_K)\\). Equivalently, we say that the random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are independent and identically distributed (iid) with distribution \\(F\\).\n\nThe random sampling framework is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets2, and (ii) it is the backbone of several statistical theorems and methods.3\n\nAlternative Sampling Assumptions"
  },
  {
    "objectID": "blog/random-sampling.html#footnotes",
    "href": "blog/random-sampling.html#footnotes",
    "title": "Random Sampling and Model-Based Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere, the value of \\(1\\) refers to the individual being a male and \\(16\\) means \\(16\\) years of education.↩︎\nFor example, if we collected data on a random subset of individuals from a large common population (e.g. the USA), it is reasonable to assume that the characteristics of one individual are independent of another individual and that they all come from the same population distribution.↩︎\nCrucial theorems in asymptotic statistical theory, like the Law of Large Numbers and the Central Limit Theorem, require the random sampling assumption to hold.↩︎\nTechnically, under iid sampling, the empirical distribution converges to the true distribution as the sample size tends to infinity — a result known as the Glivenko–Cantelli theorem. Nevertheless, in any finite sample, uncertainty remains, and with it the need for statistical inference.↩︎\nTo quote my Mathematical Statistics Professor Daniel Weiner: “Do to the sample to get your estimator, as you would do to your population to get your estimand.”↩︎\nTo be more precise, \\(\\hat\\theta\\) is unbiased for \\(\\theta\\) if \\(\\mathbb{E}[\\hat\\theta]=\\theta\\) for all \\(F \\in \\mathcal{F}\\), where \\(\\mathcal{F}\\) is a class of distributions.↩︎"
  },
  {
    "objectID": "blog/random-sampling.html#parameters-and-statistics",
    "href": "blog/random-sampling.html#parameters-and-statistics",
    "title": "Random Sampling Framework",
    "section": "Parameters and Statistics",
    "text": "Parameters and Statistics"
  },
  {
    "objectID": "blog/random-sampling.html#sampling-distribution",
    "href": "blog/random-sampling.html#sampling-distribution",
    "title": "Random Sampling Framework",
    "section": "Sampling Distribution",
    "text": "Sampling Distribution"
  },
  {
    "objectID": "blog/random-sampling.html#estimands-estimators-and-sampling-distribution",
    "href": "blog/random-sampling.html#estimands-estimators-and-sampling-distribution",
    "title": "Random Sampling Framework",
    "section": "Estimands, Estimators, and Sampling Distribution",
    "text": "Estimands, Estimators, and Sampling Distribution\nAn estimand \\(\\theta\\) is a function of the data generating process \\(F\\). For example, the population mean of the \\(k\\)-th variable is an estimand defined as\n\\[\n\\mu_k = \\mathbb{E}_F[ X_k].\n\\] However, we do not know the data generating process \\(F\\) and therefore cannot calculate any estimand. Instead, we make certain simplifying assumptions about the general structure of \\(F\\) and then use the observed data to guess the value of the estimand. More formally, an estimator is a function that maps the sample to an estimand under the assumptions we make about \\(F\\). For example, the sample mean of the \\(k\\)-th variable is an estimator for the population mean:\n\\[\n\\hat{\\mu}_k = \\frac{1}{n} \\sum_{i=1}^n x_{ki}.\n\\]"
  },
  {
    "objectID": "blog/random-sampling.html#estimands-and-estimators",
    "href": "blog/random-sampling.html#estimands-and-estimators",
    "title": "Model-Based Inference Under Random Sampling",
    "section": "Estimands and Estimators",
    "text": "Estimands and Estimators\nAn estimand \\(\\theta\\) is a function of the data generating process \\(F\\). For example, the the population mean of a random variable \\(X\\) \\[\n\\mu = \\mathbb{E}_F[X]\n\\] is an estimand. However, we do not know the data generating process \\(F\\) and therefore cannot calculate any estimand. Instead, we use the observed data to guess the value of the estimand. An estimator \\(\\hat \\theta\\) is a function of the sample that provides a “good guess” for \\(\\theta\\).\nIn statistics, there are several estimation methods that provide systematic ways (i.e. rules) to construct estimators. One common method is the analog principle (or plug-in principle). The idea is to construct the estimator by replacing the population quantities in the estimand with their sample analogs.4 Thus, the sample mean is the analog estimator for the population mean:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\n\nSampling Distribution\nHow do we define a good guess? How do we choose between two different estimators?\nwe make certain simplifying assumptions about the general structure of \\(F\\) and then\nWe will be able to quantify the uncertainty of the guess if we make stronger starting assumptions about the data generating process."
  },
  {
    "objectID": "blog/random-sampling.html#random-sampling",
    "href": "blog/random-sampling.html#random-sampling",
    "title": "Random Sampling Framework",
    "section": "Random Sampling",
    "text": "Random Sampling\nThe mathematical formalization of the dataset now allows us to make a connection between the observed data and the underlying process that generates it. Specifically, we establish this connection by characterizing the probability distribution of each random vector \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\).\nThe simplest characterization is the random sampling framework. Here, we assume that the random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are independent and identically distributed (iid) with some common but unknown distribution \\(F(X_1, \\ldots, X_K)\\). Notice that \\(F\\) is exactly the underlying process we want to learn about, and is thus aptly called the data generating process (DGP). We also sometimes refer to \\(F\\) as the population. This captures the idea that the dataset is a random subset of some infinitely large population.\nIt’s useful to explicitly clarify the notation being used above. The random variables \\(X_1, \\ldots, X_K\\) are mathematical objects used to represent the generic or population-level variable associated with the DGP. For example, the random variable \\(wage\\) represents the generic variable for wage in the population. The random vector \\(\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})\\) are mathematical objects used to represent the sample-level variable associated with specific units. For example, the random variable \\(wage_i\\) represents the wage of individual \\(i\\) before the data is observed. Lastly, the realizations \\(\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK})\\) are the actual observed values of the sample-level random variables. For example, the value \\(wage_i = 25000\\) is the observed wage of individual \\(i\\) after the data is observed.\n\nAlternative Sampling Assumptions\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets2, and (ii) it is the backbone of several statistical theorems and methods.3"
  },
  {
    "objectID": "blog/random-sampling.html#random-samples",
    "href": "blog/random-sampling.html#random-samples",
    "title": "Random Sampling Framework",
    "section": "Random Samples",
    "text": "Random Samples\nThe random sampling assumption is one way to characterize the probability distribution of the random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\). The definition below helps formalize the idea.\n\nDefinition. The random vectors \\(\\{\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\}\\) are called a random sample from the distribution \\(F\\) if they are mutually independent and have the same probability distribution \\(F\\). Equivalently, we say that the random vectors \\(\\{\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\}\\) are independent and identically distributed (iid) with distribution \\(F\\).\n\nThe random sampling framework asserts that our observed dataset is a random sample from some common, but unknown distribution \\(F\\). The distribution \\(F\\) is often called the data generating process or the population.2\n\nAlternative Sampling Assumptions\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets[^4], and (ii) it is the backbone of several statistical theorems and methods.3"
  },
  {
    "objectID": "blog/random-sampling.html#random-sampling-framework",
    "href": "blog/random-sampling.html#random-sampling-framework",
    "title": "Random Sampling and Model-Based Inference",
    "section": "Random Sampling Framework",
    "text": "Random Sampling Framework\nThe discussion going forward will primarily focus on cross-sectional datasets. These consist of several observations of a collection of variables for a given point in time and can be denoted as\n\\[\n\\{x_{i1}, x_{i2} \\ldots, x_{iK}\\}_{i=1}^n,\n\\]\nwhere \\(x_{ik}\\) is the value of the \\(k\\)-th variable for the \\(i\\)-th unit. A typical source of cross-sectional data in economics is through surveys like the Current Population Survey (CPS) or the American Community Survey (ACS).\n\nMathematical Formalization of the Dataset\nSince observational data is random, it is natural to we view the observed data vector \\[\n\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\] as a realization of the random vector \\[\n\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\]\nwith some associated probability distribution. For example, we can think of the CPS dataset as consisting of random vectors\n\\[\n\\boldsymbol X_i = (sex_i, age_i, educ_i, wage_i)' \\quad \\text{for } i = 1, \\ldots, n.\n\\] For some specific individual \\(i\\) in the CPS dataset, we then observe the vector of realized values1\n\\[\n\\boldsymbol x_i = (1, 25, 16, 25000)'.\n\\] Intuitively, the distinction between the random vector \\(\\boldsymbol X_i\\) and the realization \\(\\boldsymbol x_i\\) is that the former represents the \\(i\\)-th observation before viewing the data (unknown and random) and the latter represents the \\(i\\)-th observation after viewing the data (specific known value).\n\n\nRandom Sampling\nWe have now represented the dataset as a collection of random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\), each with some probability distribution \\(F_1 \\ldots, F_n\\). However, the connection between the underlying DGP and the observed data remains unclear. Specifically, we need a simplifying assumption that will allow us to connect the distributions of each \\(\\boldsymbol X_i\\) to the underlying DGP in a straightforward manner. The simplest framework is that of random sampling. Here, we assume that the random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are independent and identically distributed (iid) with some common but unknown distribution \\(F\\) on \\(\\mathbb{R}^K\\). Thus, under this assumption, the data generating process is precisely the distribution that governs each individual random vector \\(\\boldsymbol X_i\\).\n\nAlternative Assumptions\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets2, and (ii) it is the backbone of several statistical theorems and methods.3 However, it does not necessarily have to hold. For example, we often work with data where the units are connected via some underlying factor (location, industry, etc.). In such cases, the assumption of independence across individual units is violated. An alternative approach in such cases is to instead assume mutual independence across clusters of units. Another example of a violation to the independence assumption is time-series data, where the individual unit is indexed by time. Here, consecutive observations are usually correlated and independence is instead formulated in terms of stationarity and other concepts outside the scope of this post.\n\n\n\nNotation and Example\nThe discussion so far has purely been conceptual, and so it is useful to consider a concrete example. Before doing so, however, let’s clarify some notation used in the random sampling framework. We denote the population-level random variables as \\(X_1, \\ldots, X_K\\). The data generating process \\(F\\) is the joint distribution of these random variables. For example, \\(X_1\\) could denote the generic random variable for wage in the entire US population and we are interested in making inferences about its distribution. We denote the sample-level random variables as \\(X_{i1}, \\ldots, X_{iK}\\). These represent the random variables associated with specific units in the sample. Continuing the example, \\(X_{i1}\\) denotes the random variable representing the wage of individual \\(i\\) in the sample. Finally, we denote the realized observations as \\(X_{i1}=x_{i1}, \\ldots, X_{iK}=x_{iK}\\). These are the actual values we observe. So, \\(X_{i1} = 25,000\\) means that the observed wage of individual \\(i\\) is \\(25,000\\).\nNow suppose our data generating process consists of one random variable with an exponential distribution with scale parameter \\(\\beta = 1\\): \\[\nX \\sim \\text{Exp}(1) \\quad \\text{with density } f(x) = e^{-x} \\text{ for } x \\geq 0.\n\\]\nIf we assume our dataset is a random sample of size 30 from the above DGP, then \\[\nX_{i} \\sim \\text{Exp}(1) \\, \\, \\text{ for } i = 1, \\ldots, 30 \\quad  \\text{and} \\quad  X_i \\perp X_j  \\, \\, \\text{ for } i \\neq j.\n\\]\nThe figure below plots the empirical kernel density of such a random sample (black line) and the true density of the exponential distribution (red line). In practice, we do not know the true DGP and need to guess its characteristics using the observed data. Randomness in the finite observed data makes this a non-trivial task — as illustrated by the discrepancy between the empirical and true densities in the figure below.4\n\n\nCode\n# Simulate IID sample of 30 obs from exp(1)\nset.seed(123)\nn &lt;- 30\nx &lt;- rexp(n, rate = 1)\n\n# Empirical Density \ndens &lt;- density(x)\n\n# True Exponential Density\nxs &lt;- seq(0, max(x), length.out = 200)\nys &lt;- dexp(xs, rate = 1)\n\n# Plot\nplot(dens, main = \"\", xlab = \"Observed Data\", ylab = \"Density\", xlim = c(0, 5), ylim = c(0, max(c(dens$y, ys))))\ncurve(dexp(x, rate = 1), from = min(x), add = TRUE, col = \"red\", lwd = 2)"
  },
  {
    "objectID": "blog/random-sampling.html#mathematical-formalization-of-observational-data",
    "href": "blog/random-sampling.html#mathematical-formalization-of-observational-data",
    "title": "Random Sampling Framework",
    "section": "Mathematical Formalization of Observational Data",
    "text": "Mathematical Formalization of Observational Data\nTo keep things concrete, the rest of this post will focus on cross-sectional datasets. These consist of several observations of a collection of variables for a given point in time and can be denoted as\n\\[\n\\{x_{i1}, x_{i2} \\ldots, x_{iK}\\}_{i=1}^n,\n\\]\nwhere \\(x_{ik}\\) is the value of the \\(k\\)-th variable for the \\(i\\)-th unit. A typical source of cross-sectional data in economics is through surveys like the Current Population Survey (CPS) or the American Community Survey (ACS).\nLet us now mathematically formalize the connection between the observed dataset and the underlying DGP \\(F\\). Specifically, we view each observational vector \\[\n\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\] as a realization of the random vector \\[\n\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\]\nwith some associated probability distribution. For example, we can think of the CPS dataset as consisting of random vectors\n\\[\n\\boldsymbol X_i = (sex_i, age_i, educ_i, wage_i)' \\quad \\text{for } i = 1, \\ldots, n.\n\\] For some specific individual \\(i\\) in the CPS dataset, we then observe the vector of realized values1\n\\[\n\\boldsymbol x_i = (1, 25, 16, 25000)'.\n\\] Intuitively, the distinction between the random vector \\(\\boldsymbol X_i\\) and the realization \\(\\boldsymbol x_i\\) is that the former represents the \\(i\\)-th observation before viewing the data (unknown and random) and the latter represents the \\(i\\)-th observation after viewing the data (specific known value)."
  },
  {
    "objectID": "blog/random-sampling.html#radnom-sampling",
    "href": "blog/random-sampling.html#radnom-sampling",
    "title": "Random Sampling Framework",
    "section": "Radnom Sampling",
    "text": "Radnom Sampling\nThe random sampling assumption is one way to characterize the probability distribution of the random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\). Specifically, it asserts that the random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are independent and identically distributed (iid) with some common but unknown distribution \\(F(X_1, \\ldots, X_K)\\). The distribution \\(F\\) is often called the data generating process (DGP) because if we knew the distribution, then we could reproduce the dataset by drawing \\(n\\) independent samples from \\(F\\). We also refer to \\(F\\) as the population. This captures the intuition that the dataset is a random subset of some infinitely large population.\nIt’s easy to get confused about the notation and terminology here, so let’s clarify.\nIn this setting, making statements about the underlying process that generates the dataset is now equivalent to learning about the distribution \\(F\\) using the sample. This idea is the basis of statistical inference and is briefly explored in the next section.\n\nAlternative Sampling Assumptions\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets[^4], and (ii) it is the backbone of several statistical theorems and methods.2"
  },
  {
    "objectID": "blog/random-sampling.html#what-is-statistical-inference",
    "href": "blog/random-sampling.html#what-is-statistical-inference",
    "title": "Random Sampling and Model-Based Inference",
    "section": "",
    "text": "Observational data is inherently random: if we were to measure the same variables repeatedly, we would almost certainly get different values each time. A classical explanation for the source of this randomness is the model-based (or sampling-based) perspective. In this abstraction, we assume there exists an underlying superpopulation or data generating process (DGP): a fixed but unknown probability distribution \\(F\\) that can, in principle, generate infinitely many observations. Randomness then arises because we only observe finitely many realizations from \\(F\\) — never the entire distribution. Within this framework, we define statistical inference as the process of using the observed random data to estimate features of \\(F\\) and quantify the uncertainty in those estimates.\nNotice that the exposition above implicitly assumes that there is a single underlying distribution \\(F\\) from which all observed data are drawn. To make this mathematically precise, we need to introduce the random sampling assumption. This provides the framework to connect the observed data to the DGP, and thereby lays the foundation for statistical inference."
  },
  {
    "objectID": "blog/random-sampling.html#random-sampling-framework-for-cross-sectional-data",
    "href": "blog/random-sampling.html#random-sampling-framework-for-cross-sectional-data",
    "title": "Random Sampling and Model-Based Inference",
    "section": "Random Sampling Framework for Cross-Sectional Data",
    "text": "Random Sampling Framework for Cross-Sectional Data\n\nMathematical Formalization of the Dataset\nSince observational data is random, it is natural to we view the observed data vectors \\[\n\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\] as a realization of the random vector \\[\n\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\]\nwith some associated probability distribution. For example, we can think of the CPS dataset as consisting of random vectors\n\\[\n\\boldsymbol X_i = (sex_i, age_i, educ_i, wage_i)' \\quad \\text{for } i = 1, \\ldots, n.\n\\] For some specific individual \\(i\\) in the CPS dataset, we then observe the vector of realized values1\n\\[\n\\boldsymbol x_i = (1, 25, 16, 25000)'.\n\\] Intuitively, the distinction between the random vector \\(\\boldsymbol X_i\\) and the realization \\(\\boldsymbol x_i\\) is that the former represents the \\(i\\)-th observation before viewing the data (unknown and random) and the latter represents the \\(i\\)-th observation after viewing the data (specific known value).\n\n\nRandom Sampling\nWe have now represented the dataset as a collection of random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\), each with some probability distribution \\(F_1 \\ldots, F_n\\). As it stands right now, the connection between the underlying DGP and the observed data is still unclear. Specifically, we need a simplifying assumption that will allow us to connect the distributions of each \\(\\boldsymbol X_i\\) to the underlying DGP in a straightforward manner.\nThe simplest framework is that of random sampling. Here, we assume that the random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are independent and identically distributed (iid) with some common but unknown distribution \\(F\\) on \\(\\mathbb{R}^K\\). Under this assumption, the data generating process \\(F\\) is precisely the distribution that governs each individual random vector \\(\\boldsymbol X_i\\).\n\n\nAlternative Sampling Assumptions\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets2, and (ii) it is the backbone of several statistical theorems and methods.3"
  },
  {
    "objectID": "blog/random-sampling.html#notation",
    "href": "blog/random-sampling.html#notation",
    "title": "Random Sampling and Model-Based Inference",
    "section": "Notation",
    "text": "Notation\nIt’s useful to explicitly clarify the notation being used above. The random variables \\(X_1, \\ldots, X_K\\) are mathematical objects used to represent the generic or population-level variable associated with the DGP. For example, the random variable \\(wage\\) represents the generic variable for wage in the population. The random vector \\(\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})\\) are mathematical objects used to represent the sample-level variable associated with specific units. For example, the random variable \\(wage_i\\) represents the wage of individual \\(i\\) before the data is observed. Lastly, the realizations \\(\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK})\\) are the actual observed values of the sample-level random variables. For example, the value \\(wage_i = 25000\\) is the observed wage of individual \\(i\\) after the data is observed."
  },
  {
    "objectID": "blog/random-sampling.html#point-estimation",
    "href": "blog/random-sampling.html#point-estimation",
    "title": "Random Sampling and Model-Based Inference",
    "section": "Point Estimation",
    "text": "Point Estimation\nPoint estimation is the first step of statistical inference, and involves constructing a “good guess” for a feature of the unknown data generating process. To be more precise, this feature is called an estimand \\(\\theta\\) and is defined as a function of the data generating process \\(F\\):\n\\[\n\\theta = \\theta(F).\n\\]\nAn example of an estimand is the the population mean of a random variable \\(X\\): \\[\n\\mu = \\mathbb{E}_F[X].\n\\]\nSince the DGP is unknown, the best we can do is use the observed data to guess the value of the estimand. An estimator \\(\\hat \\theta\\) is a function of the sample that is intended to provide a guess of the estimand:\n\\[\n\\hat{\\theta} = \\hat{\\theta}(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n).\n\\]\nWhen the estimator is evaluated at a specific realization of the sample, we obtain an estimate \\(\\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n)\\) of the estimand. It’s worth emphasizing that the estimand is a fixed but unknown number, the estimator is a random variable, and the estimate is a fixed and known number.\nIn statistics, there are several estimation principles that provide systematic ways (i.e. rules) to construct estimators. One common method is the analog principle (or plug-in principle). The idea is to construct the estimator by replacing the population quantities in the estimand with their sample analogs.5 Thus, the analog estimator for the population mean is the sample mean, defined as\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol X_i.\n\\]\n\nEstimator Properties\nHow do we know if an estimator is any good? To answer this question, statisticians study desirable properties that an estimator should ideally satisfy. A full treatment of estimator properties is typically the focus of a mathematical statistics course, but it is still valuable to briefly highlight some fundamental properties here.\nThe error of an estimator is defined as the difference between the estimate and the estimand:\n\\[\ne(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) = \\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) - \\theta.\n\\] The bias of an estimator is the average error of the estimator across all possible samples of size \\(n\\) from the DGP:\n\\[\nB(\\hat\\theta) = \\mathbb{E}_F[\\hat{\\theta}] - \\theta\n\\] Intuitively, the bias captures the systematic error of the estimator: if the bias is positive, the estimator tends to overestimate the estimand, and if the bias is negative, the estimator tends to underestimate the estimand. We say an estimator \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\) if its bias is zero:6\n\\[\n\\mathbb{E}_F[\\hat{\\theta}] - \\theta = 0.\n\\] Thus, the errors of an unbiased estimator are purely due to randomness in the data. As it turns out, the sample mean is an unbiased estimator of the population mean under the random sampling assumption:\n\\[\n\\mathbb{E}_F[\\hat{\\mu}] = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}_F[\\boldsymbol X_i] = \\frac{1}{n} \\sum_{i=1}^n \\mu = \\mu.\n\\] The first equality follows from the linearity of expectations, the second equality follows from the random sampling assumption, and the third equality is a simplification.\nWhile bias quantifies how far the estimator’s average is from the estimand, the variance (or sampling variance) measures how much the estimator varies across repeated samples of size \\(n\\):\n\\[\nVar(\\hat\\theta) = \\mathbb{E}_F[(\\hat\\theta - \\mathbb{E}_F[\\hat\\theta])^2].\n\\] The variance of the sample mean under the random sampling assumption is given by\n\\[\n\\operatorname {Var} \\left[\\hat\\mu\\right] = \\frac{1}{n^2}\\operatorname{Var} \\left[ \\sum_{i=1}^n \\boldsymbol X_i\\right] = \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}[\\boldsymbol X_i] = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\frac{\\sigma^2}{n},\n\\] where \\(\\sigma^2\\) is the population variance \\(\\operatorname{Var}[X]\\). The first equality uses the properties of variance. The second equality follows from the fact that the independence of each \\(\\boldsymbol X_i\\) means they are uncorrelated, and so the variance of their sum equals the sum of their variance. The third equality uses the fact that each \\(\\boldsymbol X_i\\) are drawn from an identical distribution and so have the same variance \\(\\sigma^2\\). The fourth equality is an algebraic simplification."
  },
  {
    "objectID": "blog/random-sampling.html#sampling-distribution-and-the-utility-of-statistical-models",
    "href": "blog/random-sampling.html#sampling-distribution-and-the-utility-of-statistical-models",
    "title": "Model-Based Inference Under Random Sampling",
    "section": "Sampling Distribution and the Utility of Statistical Models",
    "text": "Sampling Distribution and the Utility of Statistical Models\nHow do we define a good guess? How do we choose between two different estimators?\nwe make certain simplifying assumptions about the general structure of \\(F\\) and then\nWe will be able to quantify the uncertainty of the guess if we make stronger starting assumptions about the data generating process."
  },
  {
    "objectID": "blog/random-sampling.html#sampling-distribution-and-the-necessity-for-statistical-models",
    "href": "blog/random-sampling.html#sampling-distribution-and-the-necessity-for-statistical-models",
    "title": "Model-Based Inference Under Random Sampling",
    "section": "Sampling Distribution and the Necessity for Statistical Models",
    "text": "Sampling Distribution and the Necessity for Statistical Models\nHow do we define a good guess? How do we choose between two different estimators?\nwe make certain simplifying assumptions about the general structure of \\(F\\) and then\nWe will be able to quantify the uncertainty of the guess if we make stronger starting assumptions about the data generating process."
  },
  {
    "objectID": "blog/random-sampling.html#necessity-for-statistical-models",
    "href": "blog/random-sampling.html#necessity-for-statistical-models",
    "title": "Random Sampling and Model-Based Inference",
    "section": "Necessity for Statistical Models",
    "text": "Necessity for Statistical Models\n\nSampling Distribution\nwe make certain simplifying assumptions about the general structure of \\(F\\) and then\nWe will be able to quantify the uncertainty of the guess if we make stronger starting assumptions about the data generating process.\n\n\nInference Is Within Statistical Models\nThe discussion in this sectiono is summarized by the figure below.\n\n\n\n\n\nflowchart LR\n  classDef box fill:#f8f9fa,stroke:#444,stroke-width:1px,rx:10,ry:10;\n\n  DGP[\"Data Generating Process\"]:::box\n  Data[\"Observed Data\"]:::box\n  Model[\"Statistical Model\"]:::box\n\n  %% Main flows\n  DGP -- \"Randomness\" --&gt; Data\n  DGP -. \"Assumptions\" .-&gt; Model\n  Model -- \"Probability\" --&gt; Data\n  Data -- \"Inference\" --&gt; Model\n  Model -. \"Approximate Reality\" .-&gt; DGP"
  },
  {
    "objectID": "blog/random-sampling.html#the-necessity-for-statistical-models",
    "href": "blog/random-sampling.html#the-necessity-for-statistical-models",
    "title": "Random Sampling and Model-Based Inference",
    "section": "The Necessity for Statistical Models",
    "text": "The Necessity for Statistical Models\nThe sampling distribution of an estimator is the probability distribution that describes how the estimator’s estimates vary across all possible samples of size \\(n\\) drawn from the DGP. Intuitively, it characterizes the behavior of the estimator under repeated sampling. Under the random sampling assumption, the sampling distribution is completely determined by the DGP \\(F\\), the sample size \\(n\\), and the functional form of the estimator \\(\\hat\\theta\\).\nLet’s revisit the example of the sample mean estimator \\(\\hat\\mu\\) for the population mean \\(\\mu\\). We have already established some features of the sampling distribution of \\(\\hat\\mu\\) despite knowing nothing about \\(F\\). Particularly, the mean of \\(\\hat\\mu\\) is \\(\\mu\\) and its variance is \\(\\sigma^2/n\\). However, to say more about the distribution of \\(\\hat\\mu\\) — like its shape — we need to make assumptions about the DGP.\nA statistical model is a set of assumptions about the general structure of the data generating process \\(F\\). Put differently, we can think of a statistical model as a family of possible distributions that \\(F\\) could belong to. To illustrate the added value of statistical models, suppose our sample \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\) is drawn iid from \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Since\n\\[\n\\hat\\mu = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol X_i,\n\\]\nis a linear combination of normally distributed random variables, it is also normally distributed. Moreover, we have previously established that \\(\\mathbb{E}_F[\\hat\\mu] = \\mu\\) and \\(\\operatorname{Var}[\\hat\\mu] = \\sigma^2/n\\) for any DGP \\(F\\). Thus, assumption of a normal DGP allows us to completely characterize the sampling distribution of \\(\\hat\\mu\\) as \\(\\mathcal{N}(\\mu, \\sigma^2/n)\\). This is powerful because we can use this sampling distribution to quantify the uncertainty in our estimates by constructing confidence intervals and conducting hypothesis tests.\n\nConstructing Confidence Intervals for \\(\\hat\\mu\\)"
  },
  {
    "objectID": "blog/random-sampling.html#conclusion",
    "href": "blog/random-sampling.html#conclusion",
    "title": "Random Sampling and Model-Based Inference",
    "section": "Conclusion",
    "text": "Conclusion\n\n\n\n\n\nflowchart LR\n  classDef box fill:#f8f9fa,stroke:#444,stroke-width:1px,rx:10,ry:10;\n\n  DGP[\"Data Generating Process\"]:::box\n  Data[\"Observed Data\"]:::box\n  Model[\"Statistical Model\"]:::box\n\n  %% Main flows\n  DGP -- \"Random Sampling\" --&gt; Data\n  DGP -. \"Assumptions\" .-&gt; Model\n  Model -- \"Probability\" --&gt; Data\n  Data -- \"Inference\" --&gt; Model\n  Model -. \"Approximate Reality\" .-&gt; DGP\n\n\n\n\n\n\nIt is important to note that statistical inference is valid only if the assumptions of statistical model hold."
  },
  {
    "objectID": "blog/random-sampling.html#the-random-sampling-framework",
    "href": "blog/random-sampling.html#the-random-sampling-framework",
    "title": "Random Sampling and Model-Based Inference",
    "section": "The Random Sampling Framework",
    "text": "The Random Sampling Framework\nThe discussion going forward will primarily focus on cross-sectional datasets. These consist of several observations of a collection of variables for a given point in time and can be denoted as\n\\[\n\\{x_{i1}, x_{i2} \\ldots, x_{iK}\\}_{i=1}^n,\n\\]\nwhere \\(x_{ik}\\) is the value of the \\(k\\)-th variable for the \\(i\\)-th unit. A typical source of cross-sectional data in economics is through surveys like the Current Population Survey (CPS) or the American Community Survey (ACS).\n\nMathematical Formalization of the Dataset\nSince observational data is random, it is natural to we view the observed data vector \\[\n\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\] as a realization of the random vector \\[\n\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\]\nwith some associated probability distribution. For example, we can think of the CPS dataset as consisting of random vectors\n\\[\n\\boldsymbol X_i = (sex_i, age_i, educ_i, wage_i)' \\quad \\text{for } i = 1, \\ldots, n.\n\\] For some specific individual \\(i\\) in the CPS dataset, we then observe the vector of realized values1\n\\[\n\\boldsymbol x_i = (1, 25, 16, 25000)'.\n\\] Intuitively, the distinction between the random vector \\(\\boldsymbol X_i\\) and the realization \\(\\boldsymbol x_i\\) is that the former represents the \\(i\\)-th observation before viewing the data (unknown and random) and the latter represents the \\(i\\)-th observation after viewing the data (specific known value).\n\n\nRandom Sampling\nWe have now represented the dataset as a collection of random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\), each with some probability distribution \\(F_1 \\ldots, F_n\\). However, the connection between the underlying DGP and the observed data remains unclear. Specifically, we need a simplifying assumption that will allow us to connect the distributions of each \\(\\boldsymbol X_i\\) to the underlying DGP in a straightforward manner. The simplest framework is that of random sampling. Here, we assume that the random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are independent and identically distributed (iid) with some common but unknown distribution \\(F\\) on \\(\\mathbb{R}^K\\). Thus, under this assumption, the data generating process is precisely the distribution that governs each individual random vector \\(\\boldsymbol X_i\\).\n\nAlternative Assumptions\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets2, and (ii) it is the backbone of several statistical theorems and methods.3 However, it does not necessarily have to hold. For example, we often work with data where the units are connected via some underlying factor (location, industry, etc.). In such cases, the assumption of independence across individual units is violated. An alternative approach in such cases is to instead assume mutual independence across clusters of units. Another example of a violation to the independence assumption is time-series data, where the individual unit is indexed by time. Here, consecutive observations are usually correlated and independence is instead formulated in terms of stationarity and other concepts outside the scope of this post.\n\n\n\nNotation and Example\nThe discussion so far has purely been conceptual, and so it is useful to consider a concrete example. Before doing so, however, let’s clarify some notation used in the random sampling framework. We denote the population-level random variables as \\(X_1, \\ldots, X_K\\). The data generating process \\(F\\) is the joint distribution of these random variables. For example, \\(X_1\\) could denote the generic random variable for wage in the entire US population and we are interested in making inferences about its distribution. We denote the sample-level random variables as \\(X_{i1}, \\ldots, X_{iK}\\). These represent the random variables associated with specific units in the sample. Continuing the example, \\(X_{i1}\\) denotes the random variable representing the wage of individual \\(i\\) in the sample. Finally, we denote the realized observations as \\(X_{i1}=x_{i1}, \\ldots, X_{iK}=x_{iK}\\). These are the actual values we observe. So, \\(X_{i1} = 25,000\\) means that the observed wage of individual \\(i\\) is \\(25,000\\).\nNow suppose our data generating process consists of one random variable with an exponential distribution with scale parameter \\(\\beta = 1\\): \\[\nX \\sim \\text{Exp}(1) \\quad \\text{with density } f(x) = e^{-x} \\text{ for } x \\geq 0.\n\\]\nIf we assume our dataset is a random sample of size 30 from the above DGP, then \\[\nX_{i} \\sim \\text{Exp}(1) \\, \\, \\text{ for } i = 1, \\ldots, 30 \\quad  \\text{and} \\quad  X_i \\perp X_j  \\, \\, \\text{ for } i \\neq j.\n\\]\nThe figure below plots the empirical kernel density of such a random sample (black line) and the true density of the exponential distribution (red line). In practice, we do not know the true DGP and need to guess its characteristics using the observed data. Randomness in the finite observed data makes this a non-trivial task — as illustrated by the discrepancy between the empirical and true densities in the figure below.4\n\n\nCode\n# Simulate IID sample of 30 obs from exp(1)\nset.seed(123)\nn &lt;- 30\nx &lt;- rexp(n, rate = 1)\n\n# Empirical Density \ndens &lt;- density(x)\n\n# True Exponential Density\nxs &lt;- seq(0, max(x), length.out = 200)\nys &lt;- dexp(xs, rate = 1)\n\n# Plot\nplot(dens, main = \"\", xlab = \"Observed Data\", ylab = \"Density\", xlim = c(0, 5), ylim = c(0, max(c(dens$y, ys))))\ncurve(dexp(x, rate = 1), from = min(x), add = TRUE, col = \"red\", lwd = 2)"
  },
  {
    "objectID": "blog/random-sampling.html#introduction",
    "href": "blog/random-sampling.html#introduction",
    "title": "Random Sampling and Model-Based Inference",
    "section": "",
    "text": "This post is an attempt to provide a big-picture understanding of what statistical inference means. The motivation for this post stems from the following Reddit post that I came across."
  },
  {
    "objectID": "blog/linear-algebra-1.html",
    "href": "blog/linear-algebra-1.html",
    "title": "Basic Concepts in Linear Algebra",
    "section": "",
    "text": "In mathematics, an algebraic structure is an abstraction consisting of (i) a set of elements, (ii) operations that manipulate those elements, and (iii) axioms that the operations must satisfy. The power of this abstraction is that once the core properties of the structure are formalized in general, they can be applied to any specific system — mathematical or real-world — that shares the same structure. For example, the field \\(F\\) is an algebraic structure consisting of elements called scalars with operations of addition and multiplication that satisfy six axioms. An ubiquitous field is the set of real numbers \\(\\mathbb{R}\\).\nLinear algebra is the study of vector spaces \\(V\\), which is an algebraic structure defined in the context of a field. The elements in a vector space are called vectors. For any two vectors \\(\\boldsymbol u,\\boldsymbol v \\in V\\), the operation of vector addition creates a third vector \\(\\boldsymbol u + \\boldsymbol v \\in V\\); this is known as closure under vector addition. For any scalar \\(c \\in F\\) and vector \\(\\boldsymbol u \\in V\\), the operation of scalar multiplication creates another vector \\(c \\boldsymbol u \\in V\\); this is known as closure under scalar multiplication. The 8 axioms that govern these two operations are listed here.\nAny sets of elements equipped with vector addition and scalar multiplication that satisfy the closure property and the 8 axioms is considered a vector space. Of particular interest are \\(n\\)-tuples of the form\n\\[\n\\boldsymbol u = (u_1, u_2, \\ldots, u_n),\n\\]\nwhere the components \\(u_1, \\ldots, u_n\\) are scalars from a field \\(F\\). The set of all such \\(n\\)-tuples is denoted by \\(F^n\\).1 For example, \\(\\mathbb{R}^3\\) is the set of all 3-tuples of real numbers. Here, vector addition is defined as the component-wise operation:\n\\[\n\\begin{aligned}\n\\boldsymbol u = (u_1, u_2, &\\ldots, u_n) \\in F^n \\quad\\text{and}\\quad \\boldsymbol v = (v_1, v_2, \\ldots, v_n) \\in F^n \\\\\n\\\\\n\\boldsymbol u + \\boldsymbol v &= (u_1 + v_1, u_2 + v_2, \\ldots, u_n + v_n) \\in F^n.\n\\end{aligned}\n\\]\nSimilarly, scalar multiplication is defined as the component-wise operation:\n\\[\n\\begin{aligned}\nc \\in F \\quad&\\text{and}\\quad \\boldsymbol u = (u_1,u_2, \\ldots, u_n) \\in F^n \\\\\n\\\\\nc \\boldsymbol u &= (c u_1, c u_2, \\ldots, c u_n) \\in F^n.\n\\end{aligned}\n\\]\nA natural generalization of \\(n\\)-tuples is the \\(m \\times n\\) array called the matrix:\n\\[\nA = \\begin{pmatrix}\na_{11} & a_{12} & \\ldots & a_{1n} \\\\\na_{21} & a_{22} & \\ldots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\ldots & a_{mn}\n\\end{pmatrix}.\n\\]\nThe set of all \\(m \\times n\\) matrices with components in a field \\(F\\) is denoted by \\(F^{m \\times n}\\). Vector addition and scalar multiplication are defined analogously to the component-wise operations for \\(n\\)-tuples. Specifically, for any two matrices \\(A, B \\in F^{m \\times n}\\), vector addition creates a third matrix \\(A + B \\in F^{m \\times n}\\) whose components are given by\n\\[\n(A + B)_{ij} = A_{ij} + B_{ij}.\n\\]\nFor any scalar \\(c \\in F\\), scalar multiplication creates another matrix \\(cA \\in F^{m \\times n}\\) where\n\\[\nc A_{ij} = c (A_{ij}).\n\\]"
  },
  {
    "objectID": "blog/linear-algebra-1.html#vector-spaces-vectors-and-matrices",
    "href": "blog/linear-algebra-1.html#vector-spaces-vectors-and-matrices",
    "title": "Basic Concepts in Linear Algebra",
    "section": "",
    "text": "In mathematics, an algebraic structure is an abstraction consisting of (i) a set of elements, (ii) operations that manipulate those elements, and (iii) axioms that the operations must satisfy. The power of this abstraction is that once the core properties of the structure are formalized in general, they can be applied to any specific system — mathematical or real-world — that shares the same structure. For example, the field \\(F\\) is an algebraic structure consisting of elements called scalars with operations of addition and multiplication that satisfy six axioms. An ubiquitous field is the set of real numbers \\(\\mathbb{R}\\).\nLinear algebra is the study of vector spaces \\(V\\), which is an algebraic structure defined in the context of a field. The elements in a vector space are called vectors. For any two vectors \\(\\boldsymbol u,\\boldsymbol v \\in V\\), the operation of vector addition creates a third vector \\(\\boldsymbol u + \\boldsymbol v \\in V\\); this is known as closure under vector addition. For any scalar \\(c \\in F\\) and vector \\(\\boldsymbol u \\in V\\), the operation of scalar multiplication creates another vector \\(c \\boldsymbol u \\in V\\); this is known as closure under scalar multiplication. The 8 axioms that govern these two operations are listed here.\nAny sets of elements equipped with vector addition and scalar multiplication that satisfy the closure property and the 8 axioms is considered a vector space. Of particular interest are \\(n\\)-tuples of the form\n\\[\n\\boldsymbol u = (u_1, u_2, \\ldots, u_n),\n\\]\nwhere the components \\(u_1, \\ldots, u_n\\) are scalars from a field \\(F\\). The set of all such \\(n\\)-tuples is denoted by \\(F^n\\).1 For example, \\(\\mathbb{R}^3\\) is the set of all 3-tuples of real numbers. Here, vector addition is defined as the component-wise operation:\n\\[\n\\begin{aligned}\n\\boldsymbol u = (u_1, u_2, &\\ldots, u_n) \\in F^n \\quad\\text{and}\\quad \\boldsymbol v = (v_1, v_2, \\ldots, v_n) \\in F^n \\\\\n\\\\\n\\boldsymbol u + \\boldsymbol v &= (u_1 + v_1, u_2 + v_2, \\ldots, u_n + v_n) \\in F^n.\n\\end{aligned}\n\\]\nSimilarly, scalar multiplication is defined as the component-wise operation:\n\\[\n\\begin{aligned}\nc \\in F \\quad&\\text{and}\\quad \\boldsymbol u = (u_1,u_2, \\ldots, u_n) \\in F^n \\\\\n\\\\\nc \\boldsymbol u &= (c u_1, c u_2, \\ldots, c u_n) \\in F^n.\n\\end{aligned}\n\\]\nA natural generalization of \\(n\\)-tuples is the \\(m \\times n\\) array called the matrix:\n\\[\nA = \\begin{pmatrix}\na_{11} & a_{12} & \\ldots & a_{1n} \\\\\na_{21} & a_{22} & \\ldots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\ldots & a_{mn}\n\\end{pmatrix}.\n\\]\nThe set of all \\(m \\times n\\) matrices with components in a field \\(F\\) is denoted by \\(F^{m \\times n}\\). Vector addition and scalar multiplication are defined analogously to the component-wise operations for \\(n\\)-tuples. Specifically, for any two matrices \\(A, B \\in F^{m \\times n}\\), vector addition creates a third matrix \\(A + B \\in F^{m \\times n}\\) whose components are given by\n\\[\n(A + B)_{ij} = A_{ij} + B_{ij}.\n\\]\nFor any scalar \\(c \\in F\\), scalar multiplication creates another matrix \\(cA \\in F^{m \\times n}\\) where\n\\[\nc A_{ij} = c (A_{ij}).\n\\]"
  },
  {
    "objectID": "blog/linear-algebra-1.html#subspaces",
    "href": "blog/linear-algebra-1.html#subspaces",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Subspaces",
    "text": "Subspaces\nIt is often useful to consider a lower-dimension vector space that still preserves the properties of the original vector space. Formally, for a vector space \\(V\\), we define the subspace \\(W\\) to be any vector space that consists of a nonempty subset of the vectors in \\(V\\) endowed with the same operations of vector addition and scalar multiplication defined on \\(V\\).\nThis definition can seem abstract at first, and so it’s valuable to consider a concrete example. Recall that the vector space \\(\\mathbb{R}^3\\) is the set of all 3-tuples of real numbers. This is visualized by the faint blue lattice in Figure 1. Now, consider following subset of \\(\\mathbb{R}^3\\)\n\\[\nW = \\{(x,y,0): x, y \\in \\mathbb{R}\\} \\subseteq {\\mathbb{R^3}},\n\\]\nwhich is visualized as the turquoise \\(x-y\\) plane in the figure below.\n\n\nCode\nL &lt;- 6       # half-size of the cube window\nstep &lt;- 1    # spacing of lattice points\n\n# Lattice points: all 3D triples on a grid\ng &lt;- seq(-L, L, by = step)\npts &lt;- expand.grid(x = g, y = g, z = g)\n\n# Plane through the origin (z=0)\nZ &lt;- matrix(0, length(g), length(g))\n\n# Define cube edges\nedges &lt;- list(\n  rbind(c(-L,-L,-L), c( L,-L,-L)),  rbind(c(-L, L,-L), c( L, L,-L)),\n  rbind(c(-L,-L, L), c( L,-L, L)),  rbind(c(-L, L, L), c( L, L, L)),\n  rbind(c(-L,-L,-L), c(-L, L,-L)),  rbind(c( L,-L,-L), c( L, L,-L)),\n  rbind(c(-L,-L, L), c(-L, L, L)),  rbind(c( L,-L, L), c( L, L, L)),\n  rbind(c(-L,-L,-L), c(-L,-L, L)),  rbind(c( L,-L,-L), c( L,-L, L)),\n  rbind(c(-L, L,-L), c(-L, L, L)),  rbind(c( L, L,-L), c( L, L, L))\n)\n\np &lt;- plot_ly()\n\n# (1) Lattice points (all possible 3-tuples)\np &lt;- add_markers(\n  p, data = pts, x = ~x, y = ~y, z = ~z,\n  opacity = 0.12, marker = list(size = 2),\n  showlegend = FALSE, hoverinfo = \"skip\"\n)\n\n# (2) Plane through the origin\np &lt;- add_surface(\n  p, x = g, y = g, z = Z,\n  opacity = 0.35, showscale = FALSE\n)\n\n# (3) Axes\np &lt;- add_trace(p, type = \"scatter3d\", mode = \"lines\",\n               x = c(-L, L), y = c(0, 0), z = c(0, 0),\n               line = list(width = 6), hoverinfo = \"skip\")\np &lt;- add_trace(p, type = \"scatter3d\", mode = \"lines\",\n               x = c(0, 0), y = c(-L, L), z = c(0, 0),\n               line = list(width = 6), hoverinfo = \"skip\")\np &lt;- add_trace(p, type = \"scatter3d\", mode = \"lines\",\n               x = c(0, 0), y = c(0, 0), z = c(-L, L),\n               line = list(width = 6), hoverinfo = \"skip\")\n\n# (4) Wireframe cube (wideframe)\nfor (e in edges) {\n  p &lt;- add_trace(\n    p, type = \"scatter3d\", mode = \"lines\",\n    x = e[,1], y = e[,2], z = e[,3],\n    line = list(width = 4, color = \"orange\"),\n    showlegend = FALSE, hoverinfo = \"skip\"\n  )\n}\n\n# Layout\np &lt;- layout(\n  p,\n  scene = list(\n    aspectmode = \"cube\",\n    xaxis = list(title = \"x\", range = c(-L, L), showgrid = FALSE, zeroline = FALSE),\n    yaxis = list(title = \"y\", range = c(-L, L), showgrid = FALSE, zeroline = FALSE),\n    zaxis = list(title = \"z\", range = c(-L, L), showgrid = FALSE, zeroline = FALSE),\n    bgcolor = \"white\"\n  ),\n  showlegend = FALSE\n)\n\np\n\n\n\n\n\n\n\n\nFigure 1: A 2D plane through the origin is a subspace of R³.\n\n\n\n\nThe subset \\(W\\) is a subspace of \\(\\mathbb{R}^3\\). To see this, note that for any \\(u = (u_1, u_2, 0) \\in W\\), \\(v = (v_1, v_2, 0) \\in W\\), and \\(c \\in \\mathbb{R}\\), the component-wise definitions of vector addition and scalar multiplication for \\(\\mathbb{R}^3\\) are closed in \\(W\\)\n\\[\n\\begin{aligned}\nu + v = &(u_1 + v_1, u_2 + v_2, 0) \\in W \\\\\n\\\\\nc u &= (c u_1, c u_2, 0) \\in W,\n\\end{aligned}\n\\] and thus \\(W\\) is a valid vector space.\nNotice that the origin \\((0,0,0)\\) — the additive identity for \\(\\mathbb{R}^3\\) — is contained in \\(W\\). This is not a coincidence: every subspace of \\(\\mathbb{R}^3\\) must contain the origin. To see this, consider the \\(x-y\\) plane shifted up by one unit:\n\\[\nW' = \\{(x,y,1): x, y \\in \\mathbb{R}\\} \\subseteq {\\mathbb{R^3}}.\n\\]\nThis set does not include the origin, and it fails to be a subspace because the operations of vector addition and scalar multiplication are not closed in \\(W'\\). Specifically, for any \\(u = (u_1, u_2, 1) \\in W'\\), \\(v = (v_1, v_2, 1) \\in W'\\), and \\(c \\in \\{\\mathbb{R} / 1\\}\\), we have that\n\\[\n\\begin{aligned}\nu + v = &(u_1 + v_1, u_2 + v_2, 2) \\notin W' \\\\\n\\\\\ncu &= (c u_1, c u_2, c) \\notin W',\n\\end{aligned}\n\\] and so \\(W'\\) is not a valid vector space. Importantly, this is a general property not limited to \\(\\mathbb{R}^3\\): any subspace must contain the additive identity (also called the zero vector) of the parent vector space."
  },
  {
    "objectID": "blog/linear-algebra-1.html#linear-combinations-basis-vectors-and-span",
    "href": "blog/linear-algebra-1.html#linear-combinations-basis-vectors-and-span",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Linear Combinations, Basis Vectors and Span",
    "text": "Linear Combinations, Basis Vectors and Span\nA vector space \\(V\\) contains infinitely many vectors. We are interested in constructing a smaller, finite set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent way to say this is that the set of all possible linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span (i.e. the set of all possible linear combinations) of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\)."
  },
  {
    "objectID": "blog/linear-algebra-1.html#footnotes",
    "href": "blog/linear-algebra-1.html#footnotes",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese tuples are usually called vectors in most applied settings, but to avoid confusion with the more general definition of vectors in a vector space, I refer to them as \\(n\\)-tuples.↩︎"
  },
  {
    "objectID": "blog/linear-algebra-1.html#linear-combinations-linear-independence-spans-and-basis-vectors",
    "href": "blog/linear-algebra-1.html#linear-combinations-linear-independence-spans-and-basis-vectors",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Linear Combinations, Linear Independence, Spans, and Basis Vectors",
    "text": "Linear Combinations, Linear Independence, Spans, and Basis Vectors\nA vector space \\(V\\) contains infinitely many vectors. We are interested in constructing a smaller, finite set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent way to say this is that the set of all possible linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span (i.e. the set of all possible linear combinations) of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\)."
  },
  {
    "objectID": "blog/linear-algebra-1.html#linear-combinations-spans-and-basis-vectors",
    "href": "blog/linear-algebra-1.html#linear-combinations-spans-and-basis-vectors",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Linear Combinations, Spans, and Basis Vectors",
    "text": "Linear Combinations, Spans, and Basis Vectors\nA vector space \\(V\\) contains infinitely many vectors. We are interested in constructing a smaller, finite set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent way to say this is that the set of all possible linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span (i.e. the set of all possible linear combinations) of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\).\nTaken together, these two ideas — spanning and linear independence — gives us exactly what we were looking for: a minimal yet complete description of the vector space \\(V\\). More formally, we call a set of vectors a basis for the vector space \\(V\\) if it is a linearly independent subset that spans \\(V\\)."
  },
  {
    "objectID": "blog/linear-algebra-1.html#linear-combinations-spans-and-basis",
    "href": "blog/linear-algebra-1.html#linear-combinations-spans-and-basis",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Linear Combinations, Spans, and Basis",
    "text": "Linear Combinations, Spans, and Basis\nA vector space \\(V\\) contains infinitely many vectors. We are interested in constructing a smaller, finite set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent way to say this is that the set of all possible linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span (i.e. the set of all possible linear combinations) of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\).\nTaken together, these two ideas — spanning and linear independence — gives us exactly what we were looking for: a minimal yet complete description of the vector space \\(V\\). More formally, we call a set of vectors a basis for the vector space \\(V\\) if it is a linearly independent subset that spans \\(V\\)."
  },
  {
    "objectID": "blog/linear-algebra-1.html#linear-combinations-linear-independence-and-basis",
    "href": "blog/linear-algebra-1.html#linear-combinations-linear-independence-and-basis",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Linear Combinations, Linear Independence, and Basis",
    "text": "Linear Combinations, Linear Independence, and Basis\nA vector space \\(V\\) contains infinitely many vectors. We are interested in constructing a smaller, finite set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent way to say this is that the set of all possible linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span (i.e. the set of all possible linear combinations) of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\).\nTaken together, these two ideas — spanning and linear independence — gives us exactly what we were looking for: a minimal yet complete description of the vector space \\(V\\). More formally, we call a set of vectors a basis for the vector space \\(V\\) if it is a linearly independent subset that spans \\(V\\)."
  },
  {
    "objectID": "blog/linear-algebra-1.html#linear-combination-linear-independence-and-basis",
    "href": "blog/linear-algebra-1.html#linear-combination-linear-independence-and-basis",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Linear Combination, Linear Independence, and Basis",
    "text": "Linear Combination, Linear Independence, and Basis\nA vector space \\(V\\) contains infinitely many vectors. We are interested in constructing a smaller, finite set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent way to say this is that the set of all possible linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span (i.e. the set of all possible linear combinations) of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\).\nTaken together, these two ideas — spanning and linear independence — gives us exactly what we were looking for: a minimal yet complete description of the vector space \\(V\\). More formally, we call a set of vectors a basis for the vector space \\(V\\) if it is a linearly independent subset that spans \\(V\\)."
  },
  {
    "objectID": "blog/linear-algebra-1.html#basis-and-dimension",
    "href": "blog/linear-algebra-1.html#basis-and-dimension",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Basis and Dimension",
    "text": "Basis and Dimension\nA vector space \\(V\\) contains infinitely many vectors. We are interested in constructing a smaller set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent way to say this is that the set of all possible linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span (i.e. the set of all possible linear combinations) of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\).\nTaken together, these two ideas — spanning and linear independence — gives us exactly what we were looking for: a minimal yet complete description of the vector space \\(V\\). More formally, we call a set of vectors a basis for the vector space \\(V\\) if it is a linearly independent subset that spans \\(V\\). The vectors in a basis are called basis vectors."
  },
  {
    "objectID": "blog/linalg-basics.html",
    "href": "blog/linalg-basics.html",
    "title": "Basic Concepts in Linear Algebra",
    "section": "",
    "text": "In mathematics, an algebraic structure is an abstraction consisting of (i) a set of elements, (ii) operations that manipulate those elements, and (iii) axioms that the operations must satisfy. The power of this abstraction is that once the core properties of the structure are formalized in general, they can be applied to any specific system — mathematical or real-world — that shares the same structure. For example, the field \\(F\\) is an algebraic structure consisting of elements called scalars with operations of addition and multiplication that satisfy a number of axioms. A ubiquitous field is the set of real numbers \\(\\mathbb{R}\\).\nLinear algebra is the study of vector spaces \\(V\\), which is an algebraic structure defined in the context of a field. The elements in a vector space are called vectors. For any two vectors \\(\\boldsymbol u,\\boldsymbol v \\in V\\), the operation of vector addition creates a third vector \\(\\boldsymbol u + \\boldsymbol v \\in V\\); this is known as closure under vector addition. For any scalar \\(c \\in F\\) and vector \\(\\boldsymbol u \\in V\\), the operation of scalar multiplication creates another vector \\(c \\boldsymbol u \\in V\\); this is known as closure under scalar multiplication. The 8 axioms that govern these two operations are listed here.\nAny sets of elements equipped with vector addition and scalar multiplication that satisfy the closure property and the 8 axioms is considered a vector space. Of particular interest are \\(n\\)-tuples of the form\n\\[\n\\boldsymbol u = (u_1, u_2, \\ldots, u_n),\n\\]\nwhere the components \\(u_1, \\ldots, u_n\\) are scalars from a field \\(F\\). The set of all such \\(n\\)-tuples is denoted by \\(F^n\\).1 For example, \\(\\mathbb{R}^3\\) is the set of all 3-tuples of real numbers. Here, vector addition is defined as the component-wise operation:\n\\[\n\\begin{aligned}\n\\boldsymbol u = (u_1, u_2, &\\ldots, u_n) \\in F^n \\quad\\text{and}\\quad \\boldsymbol v = (v_1, v_2, \\ldots, v_n) \\in F^n \\\\\n\\\\\n\\boldsymbol u + \\boldsymbol v &= (u_1 + v_1, u_2 + v_2, \\ldots, u_n + v_n) \\in F^n.\n\\end{aligned}\n\\]\nSimilarly, scalar multiplication is defined as the component-wise operation:\n\\[\n\\begin{aligned}\nc \\in F \\quad&\\text{and}\\quad \\boldsymbol u = (u_1,u_2, \\ldots, u_n) \\in F^n \\\\\n\\\\\nc \\boldsymbol u &= (c u_1, c u_2, \\ldots, c u_n) \\in F^n.\n\\end{aligned}\n\\]\nA natural generalization of \\(n\\)-tuples is the \\(m \\times n\\) array called the matrix:\n\\[\n\\mathbf A = \\begin{pmatrix}\na_{11} & a_{12} & \\ldots & a_{1n} \\\\\na_{21} & a_{22} & \\ldots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\ldots & a_{mn}\n\\end{pmatrix}, \\quad a_{ij} \\in F.\n\\]\nThe set of all \\(m \\times n\\) matrices with components in a field \\(F\\) is denoted by \\(F^{m \\times n}\\). Vector addition and scalar multiplication are defined analogously to the component-wise operations for \\(n\\)-tuples. Specifically, for any two matrices \\(A, B \\in F^{m \\times n}\\), vector addition creates a third matrix \\(A + B \\in F^{m \\times n}\\) whose components are given by\n\\[\n(\\mathbf{A} + \\mathbf B)_{ij} = \\mathbf A_{ij} + \\mathbf B_{ij}.\n\\]\nFor any scalar \\(c \\in F\\), scalar multiplication creates another matrix \\(cA \\in F^{m \\times n}\\) where\n\\[\nc \\mathbf A_{ij} = c (\\mathbf A_{ij}).\n\\]"
  },
  {
    "objectID": "blog/linalg-basics.html#vector-spaces-vectors-and-matrices",
    "href": "blog/linalg-basics.html#vector-spaces-vectors-and-matrices",
    "title": "Basic Concepts in Linear Algebra",
    "section": "",
    "text": "In mathematics, an algebraic structure is an abstraction consisting of (i) a set of elements, (ii) operations that manipulate those elements, and (iii) axioms that the operations must satisfy. The power of this abstraction is that once the core properties of the structure are formalized in general, they can be applied to any specific system — mathematical or real-world — that shares the same structure. For example, the field \\(F\\) is an algebraic structure consisting of elements called scalars with operations of addition and multiplication that satisfy a number of axioms. A ubiquitous field is the set of real numbers \\(\\mathbb{R}\\).\nLinear algebra is the study of vector spaces \\(V\\), which is an algebraic structure defined in the context of a field. The elements in a vector space are called vectors. For any two vectors \\(\\boldsymbol u,\\boldsymbol v \\in V\\), the operation of vector addition creates a third vector \\(\\boldsymbol u + \\boldsymbol v \\in V\\); this is known as closure under vector addition. For any scalar \\(c \\in F\\) and vector \\(\\boldsymbol u \\in V\\), the operation of scalar multiplication creates another vector \\(c \\boldsymbol u \\in V\\); this is known as closure under scalar multiplication. The 8 axioms that govern these two operations are listed here.\nAny sets of elements equipped with vector addition and scalar multiplication that satisfy the closure property and the 8 axioms is considered a vector space. Of particular interest are \\(n\\)-tuples of the form\n\\[\n\\boldsymbol u = (u_1, u_2, \\ldots, u_n),\n\\]\nwhere the components \\(u_1, \\ldots, u_n\\) are scalars from a field \\(F\\). The set of all such \\(n\\)-tuples is denoted by \\(F^n\\).1 For example, \\(\\mathbb{R}^3\\) is the set of all 3-tuples of real numbers. Here, vector addition is defined as the component-wise operation:\n\\[\n\\begin{aligned}\n\\boldsymbol u = (u_1, u_2, &\\ldots, u_n) \\in F^n \\quad\\text{and}\\quad \\boldsymbol v = (v_1, v_2, \\ldots, v_n) \\in F^n \\\\\n\\\\\n\\boldsymbol u + \\boldsymbol v &= (u_1 + v_1, u_2 + v_2, \\ldots, u_n + v_n) \\in F^n.\n\\end{aligned}\n\\]\nSimilarly, scalar multiplication is defined as the component-wise operation:\n\\[\n\\begin{aligned}\nc \\in F \\quad&\\text{and}\\quad \\boldsymbol u = (u_1,u_2, \\ldots, u_n) \\in F^n \\\\\n\\\\\nc \\boldsymbol u &= (c u_1, c u_2, \\ldots, c u_n) \\in F^n.\n\\end{aligned}\n\\]\nA natural generalization of \\(n\\)-tuples is the \\(m \\times n\\) array called the matrix:\n\\[\n\\mathbf A = \\begin{pmatrix}\na_{11} & a_{12} & \\ldots & a_{1n} \\\\\na_{21} & a_{22} & \\ldots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\ldots & a_{mn}\n\\end{pmatrix}, \\quad a_{ij} \\in F.\n\\]\nThe set of all \\(m \\times n\\) matrices with components in a field \\(F\\) is denoted by \\(F^{m \\times n}\\). Vector addition and scalar multiplication are defined analogously to the component-wise operations for \\(n\\)-tuples. Specifically, for any two matrices \\(A, B \\in F^{m \\times n}\\), vector addition creates a third matrix \\(A + B \\in F^{m \\times n}\\) whose components are given by\n\\[\n(\\mathbf{A} + \\mathbf B)_{ij} = \\mathbf A_{ij} + \\mathbf B_{ij}.\n\\]\nFor any scalar \\(c \\in F\\), scalar multiplication creates another matrix \\(cA \\in F^{m \\times n}\\) where\n\\[\nc \\mathbf A_{ij} = c (\\mathbf A_{ij}).\n\\]"
  },
  {
    "objectID": "blog/linalg-basics.html#basis-and-dimension",
    "href": "blog/linalg-basics.html#basis-and-dimension",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Basis and Dimension",
    "text": "Basis and Dimension\nA vector space \\(V\\) contains infinitely many vectors. We are interested in finding a smaller set of vectors that captures the entire structure in a much more tractable manner. For example, consider the vector space \\(\\mathbb{R}^3\\) in Figure 1. It seems like any point (i.e. vector or 3-tuple) on the blue lattice structure can be described by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. This section formalizes this idea.\n\n\n\n\n\n\n\n\nFigure 1: The R³ vector space.\n\n\n\n\n\nLinear Combination, Span, and Linear Independence\nLet \\(\\mathcal{A} = \\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\}\\) be some finite subset of vectors in \\(V\\). One way to formalize the idea of \\(\\mathcal{A}\\) capturing the entire structure of \\(V\\) is if any vector \\(\\boldsymbol{v} \\in V\\) can be expressed as a linear combination of the vectors in \\(\\mathcal{A}\\):\n\\[\n\\boldsymbol v = c_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = \\sum_{i=1}^n c_i \\boldsymbol u_i \\in V,\n\\]\nwhere \\(c_1, \\ldots, c_n \\in F\\). If this is the case, then we say that the set \\(\\mathcal{A}\\) spans the vector space \\(V\\). An equivalent characterization is that the set of all linear combinations of the vectors in \\(\\mathcal{A}\\) — the span of \\(\\mathcal{A}\\) — is equal to \\(V\\).\nWe are also interested in efficiency. That is to say, we want \\(\\mathcal{A}\\) to be as small as possible while still spanning \\(V\\). We call a set of vectors linearly dependent if one of the vectors can be expressed as a linear combination of the others. More formally, the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) would be linearly dependent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nand not all of the \\(c_i\\) are zero. Thus, we would like to remove any linearly dependent vectors from \\(\\mathcal{A}\\): such vectors are going to be redundant since they will be a part of the span of the other vectors in \\(\\mathcal{A}\\). Formally, we say that the vectors \\(\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_n\\) in \\(\\mathcal{A}\\) are linearly independent if\n\\[\nc_1 \\boldsymbol u_1 + c_2 \\boldsymbol u_2 + \\ldots + c_n \\boldsymbol u_n = 0,\n\\]\nonly if \\(c_1 = c_2 = \\ldots = c_n = 0\\).\nTaken together, these two ideas — spanning and linear independence — gives us exactly what we were looking for: a minimal yet complete description of the vector space \\(V\\). More formally, we call a set of vectors a basis \\(\\mathcal{B}\\) for the vector space \\(V\\) if it is a linearly independent subset that spans \\(V\\). The vectors in a basis are called basis vectors.\n\n\nDimension\nNotice that in the above definition of the basis set \\(\\mathcal{B}\\), we did not assume that the number of basis vectors is finite. In fact, there exists vector spaces that require infinitely many basis vectors. For example, an \\(n\\)-degree polynomial is defined as\n\\[\nf(x) = a_nx^n + a_{n-1}x^{n-1} + \\ldots + a_1 x + a_0,\n\\] where \\(x\\) is a variable, \\(a_i \\in F\\), and \\(n \\geq 0\\) is an integer. The vector space of all polynomials with coefficients in a field \\(F\\), denoted \\(P(F)\\), has the infinite basis set\n\\[\n\\mathcal{B}_{P(F)} = \\{1, x, x^2, x^3, \\ldots\\}.\n\\] Nevertheless, note that the definition of linear combination requires a finite number of vectors. Thus, even if a basis set \\(\\mathcal{B}\\) for a vector space \\(V\\) is infinite, any vector \\(\\boldsymbol v \\in V\\) can be represented as a linear combination of a finite subset of vectors in \\(\\mathcal{B}\\).\nTo distinguish between vector spaces with finite and infinite basis sets, we introduce the notion of dimension, which is simply the number of basis vectors in a basis set \\(\\mathcal{B}\\) for the vector space \\(V\\). If \\(V\\) has a finite basis, then we say that \\(V\\) is finite-dimensional; otherwise, it is infinite-dimensional.\n\n\nBasis Sets Are Not Unique\nAn important property of basis sets is that they are not unique. Let us revisit the vector space \\(\\mathbb{R}^3\\) to illustrate this point. At the start of this section, I mentioned that it seems possible to describe any point in \\(\\mathbb{R}^3\\) by how far it extends along the \\(x\\), \\(y\\), and \\(z\\) axes. With this intuition, we can define the following basis set\n\\[\n\\mathcal{B}_{\\mathbb{R}^3} = \\{(1,0,0), (0,1,0), (0,0,1)\\} = \\{\\boldsymbol e_1, \\boldsymbol e_2, \\boldsymbol e_3\\}.\n\\]\nThis is known as the standard basis for \\(\\mathbb{R}^3\\). We can verify that it is a valid basis by confirming that (i) the three vectors are linearly independent and (ii) any vector \\(\\boldsymbol u = (u_1,u_2,u_3) \\in \\mathbb{R}^3\\) can be expressed as a linear combination of the basis vectors. As an example, the vectors \\(w = (2,1.5,3)\\) and \\(v=(-1.5,0.6, -1.2)\\) are plotted below.\n\n\n\n\n\n\n\n\nFigure 2: Basis vectors and their linear combinations in R³.\n\n\n\n\nHowever, any any set of three linearly independent vectors in \\(\\mathbb{R}^3\\) that span \\(\\mathbb{R}^3\\) can serve as a basis. For example, the following set is also a valid basis for \\(\\mathbb{R}^3\\):\n\\[\n\\mathcal{B}'_{\\mathbb{R}^3} = \\{(1,0,0), (1,1,0), (1,1,1)\\}.\n\\] The figure below provides visual intuition for this basis.\n\n\n\n\n\n\n\n\nFigure 3: Alternative basis vectors for R³."
  },
  {
    "objectID": "blog/linalg-basics.html#subspaces",
    "href": "blog/linalg-basics.html#subspaces",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Subspaces",
    "text": "Subspaces\nIt is often useful to consider a lower-dimension vector space that still preserves the properties of the original vector space. Formally, for a vector space \\(V\\), we define the subspace \\(W\\) to be any vector space that consists of a nonempty subset of the vectors in \\(V\\) endowed with the same operations of vector addition and scalar multiplication defined on \\(V\\).\nThis definition can seem abstract at first, and so it’s valuable to walk through a concrete example. Consider the following subset of \\(\\mathbb{R}^3\\)\n\\[\nW = \\{(x,y,0): x, y \\in \\mathbb{R}\\} \\subseteq {\\mathbb{R^3}},\n\\]\nwhich is visualized as the turquoise \\(x-y\\) plane in the figure below.\n\n\n\n\n\n\n\n\nFigure 4: A 2D plane through the origin is a subspace of R³.\n\n\n\n\nThe subset \\(W\\) is a subspace of \\(\\mathbb{R}^3\\). To see this, note that for any \\(\\boldsymbol u = (u_1, u_2, 0) \\in W\\), \\(\\boldsymbol v = (v_1, v_2, 0) \\in W\\), and \\(c \\in \\mathbb{R}\\), the component-wise definitions of vector addition and scalar multiplication for \\(\\mathbb{R}^3\\) are closed in \\(W\\)\n\\[\n\\begin{aligned}\n\\boldsymbol u + \\boldsymbol v = &(u_1 + v_1, u_2 + v_2, 0) \\in W \\\\\n\\\\\nc \\boldsymbol u &= (c u_1, c u_2, 0) \\in W,\n\\end{aligned}\n\\] and thus \\(W\\) is a valid vector space.\n\nImportance of Origin\nNotice that the origin \\((0,0,0)\\) — the additive identity for \\(\\mathbb{R}^3\\) — is contained in \\(W\\). This is not a coincidence: every subspace of \\(\\mathbb{R}^3\\) must contain the origin. To see this, consider the \\(x-y\\) plane shifted up by one unit:\n\\[\nW' = \\{(x,y,1): x, y \\in \\mathbb{R}\\} \\subseteq {\\mathbb{R^3}}.\n\\]\nThis set does not include the origin, and it fails to be a subspace because the operations of vector addition and scalar multiplication are not closed in \\(W'\\). Specifically, for any \\(\\boldsymbol u = (u_1, u_2, 1) \\in W'\\), \\(\\boldsymbol v = (v_1, v_2, 1) \\in W'\\), and \\(c \\in \\{\\mathbb{R} / 1\\}\\), we have that\n\\[\n\\begin{aligned}\n\\boldsymbol u + \\boldsymbol v = &(u_1 + v_1, u_2 + v_2, 2) \\notin W' \\\\\n\\\\\nc \\boldsymbol u &= (c u_1, c u_2, c) \\notin W',\n\\end{aligned}\n\\] and so \\(W'\\) is not a valid vector space. Importantly, this is a general property not limited to \\(\\mathbb{R}^3\\): any subspace must contain the additive identity (also called the zero vector) of the parent vector space.\n\n\nBasis of Subspaces\nA general property of subspaces of a finite-dimensional vector space is that their dimension is less than the dimension of the parent vector space.2 For example, in the example above, a basis for the \\(x-y\\) plane in \\(\\mathbb{R}^3\\) is\n\\[\n\\mathcal{B}_W = \\{(1,0,0), (0,1,0)\\}.\n\\]\nThus, the dimension of \\(W\\) is 2."
  },
  {
    "objectID": "blog/linalg-basics.html#footnotes",
    "href": "blog/linalg-basics.html#footnotes",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese tuples are usually called vectors in most applied settings, but to avoid confusion with the more general definition of vectors in a vector space, I refer to them as \\(n\\)-tuples.↩︎\nTo be precise, I should say “less than or equal to”, because the vector space is a subspace of itself.↩︎"
  },
  {
    "objectID": "blog/statistical-inference.html",
    "href": "blog/statistical-inference.html",
    "title": "Statistical Inference II: Point Estimation",
    "section": "",
    "text": "Point estimation is the first step of statistical inference, and involves constructing a “good guess” for a feature of the unknown data generating process. To be more precise, this feature is called an estimand \\(\\theta\\) and is defined as a function of the data generating process \\(F\\):\n\\[\n\\theta = \\theta(F).\n\\]\nAn example of an estimand is the the population mean of a random variable \\(X\\): \\[\n\\mu = \\mathbb{E}[X] = \\int x \\, dF(x).\n\\]\nSince the DGP is unknown, the best we can do is use the observed data to guess the value of the estimand. An estimator \\(\\hat \\theta\\) is a function of the sample that is intended to provide a guess of the estimand:\n\\[\n\\hat{\\theta} = \\hat{\\theta}(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n).\n\\]\nWhen the estimator is evaluated at a specific realization of the sample, we obtain an estimate \\(\\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n)\\) of the estimand. It’s worth emphasizing that the estimand is a fixed but unknown number, the estimator is a random variable, and the estimate is a fixed and known number.\nIn statistics, there are several estimation principles that provide systematic ways (i.e. rules) to construct estimators. One common method is the analog principle (or plug-in principle). The idea is to construct the estimator by replacing the population quantities in the estimand with their sample analogs.1 Thus, the analog estimator for the population mean is the sample mean, defined as\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol X_i.\n\\]\n\n\nHow do we know if an estimator is any good? To answer this question, statisticians study desirable properties that an estimator should ideally satisfy. A full treatment of estimator properties is typically the focus of a mathematical statistics course, but it is still valuable to briefly highlight some fundamental properties here.\nThe error of an estimator is defined as the difference between the estimate and the estimand:\n\\[\ne(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) = \\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) - \\theta.\n\\] The bias of an estimator is the average error of the estimator across all possible samples of size \\(n\\) from the DGP:\n\\[\nB(\\hat\\theta) = \\mathbb{E}_F[\\hat{\\theta}] - \\theta\n\\] Intuitively, the bias captures the systematic error of the estimator: if the bias is positive, the estimator tends to overestimate the estimand, and if the bias is negative, the estimator tends to underestimate the estimand. We say an estimator \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\) if its bias is zero:2\n\\[\n\\mathbb{E}_F[\\hat{\\theta}] - \\theta = 0.\n\\] Thus, the errors of an unbiased estimator are purely due to randomness in the data. As it turns out, the sample mean is an unbiased estimator of the population mean under the random sampling assumption:\n\\[\n\\mathbb{E}_F[\\hat{\\mu}] = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}_F[\\boldsymbol X_i] = \\frac{1}{n} \\sum_{i=1}^n \\mu = \\mu.\n\\] The first equality follows from the linearity of expectations, the second equality follows from the random sampling assumption, and the third equality is a simplification.\nWhile bias quantifies how far the estimator’s average is from the estimand, the variance (or sampling variance) measures how much the estimator varies across repeated samples of size \\(n\\):\n\\[\nVar(\\hat\\theta) = \\mathbb{E}_F[(\\hat\\theta - \\mathbb{E}_F[\\hat\\theta])^2].\n\\] The variance of the sample mean under the random sampling assumption is given by\n\\[\n\\operatorname {Var} \\left[\\hat\\mu\\right] = \\frac{1}{n^2}\\operatorname{Var} \\left[ \\sum_{i=1}^n \\boldsymbol X_i\\right] = \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}[\\boldsymbol X_i] = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\frac{\\sigma^2}{n},\n\\] where \\(\\sigma^2\\) is the population variance \\(\\operatorname{Var}[X]\\). The first equality uses the properties of variance. The second equality follows from the fact that the independence of each \\(\\boldsymbol X_i\\) means they are uncorrelated, and so the variance of their sum equals the sum of their variance. The third equality uses the fact that each \\(\\boldsymbol X_i\\) are drawn from an identical distribution and so have the same variance \\(\\sigma^2\\). The fourth equality is an algebraic simplification."
  },
  {
    "objectID": "blog/statistical-inference.html#what-is-statistical-inference",
    "href": "blog/statistical-inference.html#what-is-statistical-inference",
    "title": "Statistical Inference II: Point Estimation",
    "section": "",
    "text": "Observational data is inherently random: if we were to measure the same variables repeatedly, we would almost certainly get different values each time. A classical explanation for the source of this randomness is the model-based (or sampling-based) perspective. In this abstraction, we assume there exists an underlying superpopulation or data generating process (DGP): a fixed but unknown probability distribution \\(F\\) that can, in principle, generate infinitely many observations. Randomness then arises because we only observe finitely many realizations from \\(F\\) — never the entire distribution. Within this framework, we define statistical inference as the process of using the observed random data to estimate features of \\(F\\) and quantify the uncertainty in those estimates.\nNotice that the exposition above implicitly assumes that there is a single underlying distribution \\(F\\) from which all observed data are drawn. To make this mathematically precise, we need to introduce the random sampling assumption. This provides the framework to connect the observed data to the DGP, and thereby lays the foundation for statistical inference."
  },
  {
    "objectID": "blog/statistical-inference.html#the-random-sampling-framework",
    "href": "blog/statistical-inference.html#the-random-sampling-framework",
    "title": "Statistical Inference II: Point Estimation",
    "section": "The Random Sampling Framework",
    "text": "The Random Sampling Framework\nThe discussion going forward will primarily focus on cross-sectional datasets. These consist of several observations of a collection of variables for a given point in time and can be denoted as\n\\[\n\\{x_{i1}, x_{i2} \\ldots, x_{iK}\\}_{i=1}^n,\n\\]\nwhere \\(x_{ik}\\) is the value of the \\(k\\)-th variable for the \\(i\\)-th unit. A typical source of cross-sectional data in economics is through surveys like the Current Population Survey (CPS) or the American Community Survey (ACS).\n\nMathematical Formalization of the Dataset\nSince observational data is random, it is natural to we view the observed data vector \\[\n\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\] as a realization of the random data vector \\[\n\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\]\nwith some associated probability distribution. For example, we can think of the CPS dataset as consisting of random vectors\n\\[\n\\boldsymbol X_i = (sex_i, age_i, educ_i, wage_i)' \\quad \\text{for } i = 1, \\ldots, n.\n\\] For some specific individual \\(i\\) in the CPS dataset, we then observe the vector of realized values1\n\\[\n\\boldsymbol x_i = (1, 25, 16, 25000)'.\n\\] Intuitively, the distinction between the random vector \\(\\boldsymbol X_i\\) and the realization \\(\\boldsymbol x_i\\) is that the former represents the \\(i\\)-th observation before viewing the data (unknown and random) and the latter represents the \\(i\\)-th observation after viewing the data (specific known value).\n\n\nRandom Sampling\nWe have now represented the dataset as a collection of random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\), each with some probability distribution \\(F_1 \\ldots, F_n\\). However, the connection between the underlying DGP and the observed data remains unclear. Specifically, we need a simplifying assumption that will allow us to connect the distributions of each \\(\\boldsymbol X_i\\) to the underlying DGP in a straightforward manner. The simplest framework is that of random sampling. Here, we assume that the random vectors \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) are independent and identically distributed (iid) with some common but unknown distribution \\(F\\) on \\(\\mathbb{R}^K\\). Thus, under this assumption, the data generating process is precisely the distribution that governs each individual random vector \\(\\boldsymbol X_i\\).\n\nAlternative Assumptions\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets2, and (ii) it is the backbone of several statistical theorems and methods.3 However, it does not necessarily have to hold. For example, we often work with data where the units are connected via some underlying factor (location, industry, etc.). In such cases, the assumption of independence across individual units is violated. An alternative approach in such cases is to instead assume mutual independence across clusters of units. Another example of a violation to the independence assumption is time-series data, where the individual unit is indexed by time. Here, consecutive observations are usually correlated and independence is instead formulated in terms of stationarity and other concepts outside the scope of this post.\n\n\n\nNotation and Example\nThe discussion so far has purely been conceptual, and so it is useful to consider a concrete example. Before doing so, however, let’s clarify some notation used in the random sampling framework. We denote the population-level random variables as \\(X_1, \\ldots, X_K\\). The data generating process \\(F\\) is the joint distribution of these random variables. For example, \\(X_1\\) could denote the generic random variable for wage in the entire US population and we are interested in making inferences about its distribution. We denote the sample-level random variables as \\(X_{i1}, \\ldots, X_{iK}\\). These represent the random variables associated with specific units in the sample. Continuing the example, \\(X_{i1}\\) denotes the random variable representing the wage of individual \\(i\\) in the sample. Finally, we denote the realized observations as \\(X_{i1}=x_{i1}, \\ldots, X_{iK}=x_{iK}\\). These are the actual values we observe. So, \\(X_{i1} = 25,000\\) means that the observed wage of individual \\(i\\) is \\(25,000\\).\nNow suppose our data generating process consists of one random variable with an exponential distribution with scale parameter \\(\\beta = 1\\): \\[\nX \\sim \\text{Exp}(1) \\quad \\text{with density } f(x) = e^{-x} \\text{ for } x \\geq 0.\n\\]\nIf we assume our dataset is a random sample of size 30 from the above DGP, then \\[\nX_{i} \\sim \\text{Exp}(1) \\, \\, \\text{ for } i = 1, \\ldots, 30 \\quad  \\text{and} \\quad  X_i \\perp X_j  \\, \\, \\text{ for } i \\neq j.\n\\]\nThe figure below plots the empirical kernel density of such a random sample (black line) and the true density of the exponential distribution (red line). In practice, we do not know the true DGP and need to guess its characteristics using the observed data. Randomness in the finite observed data makes this a non-trivial task — as illustrated by the discrepancy between the empirical and true densities in the figure below.4\n\n\nCode\n# Simulate IID sample of 30 obs from exp(1)\nset.seed(123)\nn &lt;- 30\nx &lt;- rexp(n, rate = 1)\n\n# Empirical Density \ndens &lt;- density(x)\n\n# True Exponential Density\nxs &lt;- seq(0, max(x), length.out = 200)\nys &lt;- dexp(xs, rate = 1)\n\n# Plot\nplot(dens, main = \"\", xlab = \"Observed Data\", ylab = \"Density\", xlim = c(0, 5), ylim = c(0, max(c(dens$y, ys))))\ncurve(dexp(x, rate = 1), from = min(x), add = TRUE, col = \"red\", lwd = 2)"
  },
  {
    "objectID": "blog/statistical-inference.html#point-estimation",
    "href": "blog/statistical-inference.html#point-estimation",
    "title": "Statistical Inference II: Point Estimation",
    "section": "",
    "text": "Point estimation is the first step of statistical inference, and involves constructing a “good guess” for a feature of the unknown data generating process. To be more precise, this feature is called an estimand \\(\\theta\\) and is defined as a function of the data generating process \\(F\\):\n\\[\n\\theta = \\theta(F).\n\\]\nAn example of an estimand is the the population mean of a random variable \\(X\\): \\[\n\\mu = \\mathbb{E}[X] = \\int x \\, dF(x).\n\\]\nSince the DGP is unknown, the best we can do is use the observed data to guess the value of the estimand. An estimator \\(\\hat \\theta\\) is a function of the sample that is intended to provide a guess of the estimand:\n\\[\n\\hat{\\theta} = \\hat{\\theta}(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n).\n\\]\nWhen the estimator is evaluated at a specific realization of the sample, we obtain an estimate \\(\\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n)\\) of the estimand. It’s worth emphasizing that the estimand is a fixed but unknown number, the estimator is a random variable, and the estimate is a fixed and known number.\nIn statistics, there are several estimation principles that provide systematic ways (i.e. rules) to construct estimators. One common method is the analog principle (or plug-in principle). The idea is to construct the estimator by replacing the population quantities in the estimand with their sample analogs.1 Thus, the analog estimator for the population mean is the sample mean, defined as\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol X_i.\n\\]\n\n\nHow do we know if an estimator is any good? To answer this question, statisticians study desirable properties that an estimator should ideally satisfy. A full treatment of estimator properties is typically the focus of a mathematical statistics course, but it is still valuable to briefly highlight some fundamental properties here.\nThe error of an estimator is defined as the difference between the estimate and the estimand:\n\\[\ne(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) = \\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) - \\theta.\n\\] The bias of an estimator is the average error of the estimator across all possible samples of size \\(n\\) from the DGP:\n\\[\nB(\\hat\\theta) = \\mathbb{E}_F[\\hat{\\theta}] - \\theta\n\\] Intuitively, the bias captures the systematic error of the estimator: if the bias is positive, the estimator tends to overestimate the estimand, and if the bias is negative, the estimator tends to underestimate the estimand. We say an estimator \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\) if its bias is zero:2\n\\[\n\\mathbb{E}_F[\\hat{\\theta}] - \\theta = 0.\n\\] Thus, the errors of an unbiased estimator are purely due to randomness in the data. As it turns out, the sample mean is an unbiased estimator of the population mean under the random sampling assumption:\n\\[\n\\mathbb{E}_F[\\hat{\\mu}] = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}_F[\\boldsymbol X_i] = \\frac{1}{n} \\sum_{i=1}^n \\mu = \\mu.\n\\] The first equality follows from the linearity of expectations, the second equality follows from the random sampling assumption, and the third equality is a simplification.\nWhile bias quantifies how far the estimator’s average is from the estimand, the variance (or sampling variance) measures how much the estimator varies across repeated samples of size \\(n\\):\n\\[\nVar(\\hat\\theta) = \\mathbb{E}_F[(\\hat\\theta - \\mathbb{E}_F[\\hat\\theta])^2].\n\\] The variance of the sample mean under the random sampling assumption is given by\n\\[\n\\operatorname {Var} \\left[\\hat\\mu\\right] = \\frac{1}{n^2}\\operatorname{Var} \\left[ \\sum_{i=1}^n \\boldsymbol X_i\\right] = \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}[\\boldsymbol X_i] = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\frac{\\sigma^2}{n},\n\\] where \\(\\sigma^2\\) is the population variance \\(\\operatorname{Var}[X]\\). The first equality uses the properties of variance. The second equality follows from the fact that the independence of each \\(\\boldsymbol X_i\\) means they are uncorrelated, and so the variance of their sum equals the sum of their variance. The third equality uses the fact that each \\(\\boldsymbol X_i\\) are drawn from an identical distribution and so have the same variance \\(\\sigma^2\\). The fourth equality is an algebraic simplification."
  },
  {
    "objectID": "blog/statistical-inference.html#the-necessity-for-statistical-models",
    "href": "blog/statistical-inference.html#the-necessity-for-statistical-models",
    "title": "Statistical Inference II: Point Estimation",
    "section": "The Necessity for Statistical Models",
    "text": "The Necessity for Statistical Models\nThe sampling distribution of an estimator is the probability distribution that describes how the estimator’s estimates vary across all possible samples of size \\(n\\) drawn from the DGP. Intuitively, it characterizes the behavior of the estimator under repeated sampling. Under the random sampling assumption, the sampling distribution is completely determined by the DGP \\(F\\), the sample size \\(n\\), and the functional form of the estimator \\(\\hat\\theta\\).\nLet’s revisit the example of the sample mean estimator \\(\\hat\\mu\\) for the population mean \\(\\mu\\). We have already established some features of the sampling distribution of \\(\\hat\\mu\\) despite knowing nothing about \\(F\\). Particularly, the mean of \\(\\hat\\mu\\) is \\(\\mu\\) and its variance is \\(\\sigma^2/n\\). However, to say more about the distribution of \\(\\hat\\mu\\) — like its shape — we need to make assumptions about the DGP.\nA statistical model is a set of assumptions about the general structure of the data generating process \\(F\\). Put differently, we can think of a statistical model as a family of possible distributions that \\(F\\) could belong to. To illustrate the added value of statistical models, suppose our sample \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\) is drawn iid from \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Since\n\\[\n\\hat\\mu = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol X_i,\n\\]\nis a linear combination of normally distributed random variables, it is also normally distributed. Moreover, we have previously established that \\(\\mathbb{E}_F[\\hat\\mu] = \\mu\\) and \\(\\operatorname{Var}[\\hat\\mu] = \\sigma^2/n\\) for any DGP \\(F\\). Thus, assumption of a normal DGP allows us to completely characterize the sampling distribution of \\(\\hat\\mu\\) as \\(\\mathcal{N}(\\mu, \\sigma^2/n)\\). This is powerful because we can use this sampling distribution to quantify the uncertainty in our estimates by constructing confidence intervals and conducting hypothesis tests.\n\nConstructing Confidence Intervals for \\(\\hat\\mu\\)"
  },
  {
    "objectID": "blog/statistical-inference.html#conclusion",
    "href": "blog/statistical-inference.html#conclusion",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Conclusion",
    "text": "Conclusion\n\n\n\n\n\nflowchart LR\n  classDef box fill:#f8f9fa,stroke:#444,stroke-width:1px,rx:10,ry:10;\n\n  DGP[\"Data Generating Process\"]:::box\n  Data[\"Observed Data\"]:::box\n  Model[\"Statistical Model\"]:::box\n\n  %% Main flows\n  DGP -- \"Random Sampling\" --&gt; Data\n  DGP -. \"Assumptions\" .-&gt; Model\n  Model -- \"Probability\" --&gt; Data\n  Data -- \"Inference\" --&gt; Model\n  Model -. \"Approximate Reality\" .-&gt; DGP\n\n\n\n\n\n\nIt is important to note that statistical inference is valid only if the assumptions of statistical model hold."
  },
  {
    "objectID": "blog/statistical-inference.html#footnotes",
    "href": "blog/statistical-inference.html#footnotes",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo quote my Mathematical Statistics Professor Daniel Weiner: “Do to the sample to get your estimator, as you would do to your population to get your estimand.”↩︎\nTo be more precise, \\(\\hat\\theta\\) is unbiased for \\(\\theta\\) if \\(\\mathbb{E}[\\hat\\theta]=\\theta\\) for all \\(F \\in \\mathcal{F}\\), where \\(\\mathcal{F}\\) is a class of distributions.↩︎"
  },
  {
    "objectID": "blog/linalg-basics.html#importance-of-origin",
    "href": "blog/linalg-basics.html#importance-of-origin",
    "title": "Basic Concepts in Linear Algebra",
    "section": "Importance of Origin",
    "text": "Importance of Origin\nNotice that the origin \\((0,0,0)\\) — the additive identity for \\(\\mathbb{R}^3\\) — is contained in \\(W\\). This is not a coincidence: every subspace of \\(\\mathbb{R}^3\\) must contain the origin. To see this, consider the \\(x-y\\) plane shifted up by one unit:\n\\[\nW' = \\{(x,y,1): x, y \\in \\mathbb{R}\\} \\subseteq {\\mathbb{R^3}}.\n\\]\nThis set does not include the origin, and it fails to be a subspace because the operations of vector addition and scalar multiplication are not closed in \\(W'\\). Specifically, for any \\(u = (u_1, u_2, 1) \\in W'\\), \\(v = (v_1, v_2, 1) \\in W'\\), and \\(c \\in \\{\\mathbb{R} / 1\\}\\), we have that\n\\[\n\\begin{aligned}\nu + v = &(u_1 + v_1, u_2 + v_2, 2) \\notin W' \\\\\n\\\\\ncu &= (c u_1, c u_2, c) \\notin W',\n\\end{aligned}\n\\] and so \\(W'\\) is not a valid vector space. Importantly, this is a general property not limited to \\(\\mathbb{R}^3\\): any subspace must contain the additive identity (also called the zero vector) of the parent vector space.\n\nBasis of Subspaces\nA general property of subspaces of a finite-dimensional vector space is that their dimension is less than to the dimension of the parent vector space.2 For example, in the example above, a basis for the \\(x-y\\) plane in \\(\\mathbb{R}^3\\) is\n\\[\n\\mathcal{B}_W = \\{(1,0,0), (0,1,0)\\}.\n\\]\nThus, the dimension of \\(W\\) is 2."
  },
  {
    "objectID": "blog/hypothesis.testing.html",
    "href": "blog/hypothesis.testing.html",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "",
    "text": "Recall the basic setup of frequentist statistical inference under the random sampling framework. Here, we view the observed data \\(\\boldsymbol x = (x_1, \\ldots, x_n)'\\) as a realization of the random variables \\(\\boldsymbol X = (X_1, \\ldots, X_n)'\\) independently drawn from an an unknown, common (identical) distribution \\(F\\).1 In other words, the data \\(\\boldsymbol x\\) is a realization of a random sample \\(\\boldsymbol X\\) from the population \\(F\\). The goal of statistical inference is to use the abstraction of random sampling to make statements about \\(F\\), while quantifying the uncertainty in those statements. Typically, we need to make some starting assumptions about the structure of \\(F\\) to be able to say anything interesting about it. This is called a statistical model for \\(F\\). In this post, we will work with the normal sampling model, where we assume that \\(F\\) is the normal distribution with unknown mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\).\n1 The phrasing \\(X\\) “drawn” from \\(F\\) is informal shorthand to mean the random variable \\(X\\) has the distribution \\(F\\).Previously, we discussed one form of statistical inference: point estimation. This entailed developing a rule (i.e. an estimator) that used the realized data to produce a best guess (i.e. an estimate) of some parameter of interest \\(\\theta\\) determined by the population \\(F\\). In point estimation, uncertainty arises from the fact that the estimator is a function of the random sample, and is therefore also random. The uncertainty is quantified by asking the question: “If we repeatedly drew random samples from the population and computed the estimate each time, how would the estimates vary?” The answer to this question was given by the sampling distribution of the estimator."
  },
  {
    "objectID": "blog/hypothesis.testing.html#recapitulation",
    "href": "blog/hypothesis.testing.html#recapitulation",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "",
    "text": "Recall the basic setup of statistical inference under the random sampling framework. Here, we view the observed data \\(\\boldsymbol x = (x_1, \\ldots, x_n)'\\) as a realization of the random variables \\(\\boldsymbol X = (X_1, \\ldots, X_n)'\\) independently drawn from a common, unknown distribution \\(F\\). In other words, the data is a realization of a random sample from the population \\(F\\). The goal of statistical inference is to use the random sample to make statements about \\(F\\), while quantifying the uncertainty in those statements.\nTypically, to conduct statistical inference, we need to make some starting assumptions about the structure of \\(F\\). This is called a statistical model for \\(F\\). In this post, we will work with the normal sampling model, where we assume that \\(F\\) is the normal distribution with unknown mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\)."
  },
  {
    "objectID": "blog/hypothesis.testing.html#hypotheses",
    "href": "blog/hypothesis.testing.html#hypotheses",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "Hypotheses",
    "text": "Hypotheses\nHypothesis testing is a fundamental tool to conduct statistical inference. At its core is the hypothesis: a statement about a scalar parameter of interest \\(\\theta\\) determined by the population \\(F\\). In a non-parametric model — where \\(F\\) cannot be fully characterized by a finite set of model parameters — \\(\\theta\\) is some function of \\(F\\), like \\(\\mathbb{E}[X]\\) or \\(\\operatorname{Var}(X)\\). In a parametric model — where \\(F\\) is assumed to belong to a family of distribution characterized by a finite number of parameters — \\(\\theta\\) is typically one of the model parameters.2 For example, in the normal sampling model, our hypotheses are usually about \\(\\mu\\) or \\(\\sigma^2\\).\n2 It is worth emphasizing that while the parameter of interest is often the model parameters, the two are not always the same.3 Technically, the null hypothesis can be a set of values as well. However, in this post, we focus on point (null) hypotheses.Hypothesis testing is formulated in terms of two complementary hypotheses. The null hypothesis \\(H_0\\) is the hypothesis to be tested, while the alternative hypothesis \\(H_1\\) is the complement of the null hypothesis. These hypotheses can be defined by how they restrict the parameter space of \\(\\theta\\), denoted \\(\\Theta\\). Specifically, the null is defined by the restriction \\(\\theta = \\theta_0\\) for some hypothesized value \\(\\theta_0\\), while the alternative is defined by the set \\(\\{\\theta \\in \\Theta: \\theta \\neq \\theta_0\\}\\).3\nIn this post, we will focus on the problem of testing hypotheses about the population mean \\(\\mu\\) under the normal sampling model. Specifically, our hypotheses are \\[\nH_0: \\mu = \\mu_0 \\quad \\text{and} \\quad H_1: \\mu \\neq \\mu_0,\n\\] where \\(\\mu_0\\) is some hypothesized value of \\(\\mu\\). The goal of hypothesis testing is to test the validity of \\(H_0\\) over \\(H_1\\) using the random sample. In the next few sections, we will develop the machinery required to do exactly this."
  },
  {
    "objectID": "blog/hypothesis.testing.html#test-statistic-and-critical-region",
    "href": "blog/hypothesis.testing.html#test-statistic-and-critical-region",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "Test Statistic and Critical Region",
    "text": "Test Statistic and Critical Region\nThe outcome of a hypothesis test is a decision: either accept the null or reject the null in favor of the alternative. Thus, we want a decision rule that maps the sample space — the set of all possible realizations of the random sample — into one of these two actions. One way to formulate this rule is as follows. First, we construct a function of the random sample called the test statistic\n\\[\nT: \\boldsymbol X \\rightarrow \\mathbb{R}.\n\\] The role of the test statistic is to take any random sample from the population and compress it into a single number that reflects the information most relevant to the hypothesis. Since it is a function of random variables, the test statistic is itself a random variable. Second, we define a critical region \\(C\\) to be some subset of the range of \\(T\\). The decision rule can then be framed in terms of the observed realization of the test statistic, \\(t\\): (i) reject \\(H_0\\) if \\(t \\in C\\), and (ii) accept \\(H_0\\) if \\(t \\notin C\\).\nIt’s worth pausing here to emphasize two important features of this setup. First, the effectiveness of a hypothesis test depends on the choice of both the test statistic and critical region. If \\(T\\) does not capture the right information, or if \\(C\\) is poorly specified, the resulting decision rule will not be very insightful. Second, making incorrect decisions is inevitable in hypothesis testing because of the randomness inherent in the sample. Even with a well-chosen statistic and critical region, it is entirely possible to draw a sample with a mean far from the true population mean \\(\\mu\\) but close to the hypothesized mean \\(\\mu_0\\), or conversely, a sample far from \\(\\mu_0\\) even when \\(\\mu = \\mu_0\\). In both situations, we make an incorrect decision purely due to chance.\nThus, in carrying out hypothesis tests, the focus is not on eliminating mistakes entirely, but rather on quantifying and controlling the probability of error. The following section formalizes this idea."
  },
  {
    "objectID": "blog/hypothesis.testing.html#type-i-ii-errors-and-the-classical-approach-to-testing",
    "href": "blog/hypothesis.testing.html#type-i-ii-errors-and-the-classical-approach-to-testing",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Type I & II Errors and the Classical Approach to Testing",
    "text": "Type I & II Errors and the Classical Approach to Testing\n\nt-Statistic\nLet \\(\\hat\\theta\\) be an estimator of \\(\\theta\\), some parameter of interest determined by the population \\(F\\). The t-ratio or t-statistic is defined as \\[\nt = \\frac{\\hat\\theta(\\boldsymbol x) - \\theta_0}{\\widehat{SE}(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(\\widehat{SE}(\\hat\\theta)\\) is an estimator of the standard error of \\(\\hat\\theta\\). In words, this statistic measures how many estimated standard errors the estimate \\(\\hat\\theta (\\boldsymbol x)\\) is away from the hypothesized value \\(\\theta_0\\).\nRecall that in the normal sampling model \\(X_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\), the sample mean \\(\\bar X\\) is an estimator of the population mean \\(\\mu\\), and has a standard error of \\(\\sigma / \\sqrt{n}\\). Since \\(\\sigma\\) is unknown, we estimate it using the sample standard deviation \\(s\\). Thus, the t-statistic for the normal sampling model is given by \\[\nt = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#footnotes",
    "href": "blog/hypothesis.testing.html#footnotes",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt is worth emphasizing that while the parameter of interest is often the model parameters, the two are not always the same.↩︎\nTechnically, the null hypothesis can be a set of values as well. However, in this post, we focus on point (null) hypotheses.↩︎"
  },
  {
    "objectID": "blog/hypothesis.testing.html#classical-approach-to-testing",
    "href": "blog/hypothesis.testing.html#classical-approach-to-testing",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Classical Approach to Testing",
    "text": "Classical Approach to Testing\n\nError Probabilities and Power Function\nThere are two types of incorrect decisions we could make in hypothesis testing. Rejecting the null when it is actually true is called a Type I error. Accepting the null when it is actually false is called a Type II error.\nTo build the vocabulary necessary to talk about the probability of making these two errors, we need to first introduce the power function of a hypothesis test. This is the probability of rejecting the null under the true population distribution \\(F\\), and is denoted as \\[\n\\pi(F) = \\mathbb{P}[\\text{Reject } H_0 \\mid F] = \\mathbb{P}[T \\in C \\mid F],\n\\]\nWe are interested in the probability of making these two errors. The size of the hypothesis is the probability of making a Type I error, and is denoted as \\[\n\\mathbb{P}[\\text{Reject } H_0 \\mid F_0].\n\\]\nThe probability of making a Type I error is called the size of the hypothesis test and is denoted \\[\n\\mathbb{P}[\\text{Reject } H_0 \\mid F] = \\pi(F_0).\n\\] The complement of the probability of a Type II error is called the power of the hypothesis test and is denoted \\[\n1 - \\mathbb{P}[\\text{Accept } H_0 \\mid H_1] = \\mathbb{P}[\\text{Reject } H_0 \\mid F_1] = \\pi(F_1).\n\\]\n\n\nt-Statistic\nLet \\(\\hat\\theta\\) be an estimator of \\(\\theta\\), some parameter of interest determined by the population \\(F\\). The t-ratio or t-statistic is defined as \\[\nt = \\frac{\\hat\\theta(\\boldsymbol x) - \\theta_0}{\\widehat{SE}(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(\\widehat{SE}(\\hat\\theta)\\) is an estimator of the standard error of \\(\\hat\\theta\\). In words, this statistic measures how many estimated standard errors the estimate \\(\\hat\\theta (\\boldsymbol x)\\) is away from the hypothesized value \\(\\theta_0\\).\nRecall that in the normal sampling model \\(X_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\), the sample mean \\(\\bar X\\) is an estimator of the population mean \\(\\mu\\), and has a standard error of \\(\\sigma / \\sqrt{n}\\). Since \\(\\sigma\\) is unknown, we estimate it using the sample standard deviation \\(s\\). Thus, the t-statistic for the normal sampling model is given by \\[\nt = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#error-probabilities-and-power-function",
    "href": "blog/hypothesis.testing.html#error-probabilities-and-power-function",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Error Probabilities and Power Function",
    "text": "Error Probabilities and Power Function\nThere are two types of incorrect decisions we could make in hypothesis testing. Rejecting the null when it is actually true is called a Type I error. Accepting the null when it is actually false is called a Type II error.\nTo build the vocabulary and notation required to talk about the probability of making these two errors, we need to introduce the power function of a hypothesis test. This is the probability of rejecting the null \\(H_0\\) under some population distribution \\(F\\), and is denoted \\[\n\\pi(F) = \\mathbb{P}[\\text{Reject } H_0 \\mid F] = \\mathbb{P}[T \\in C \\mid F].\n\\]\nThe power function formalizes the source of randomness in hypothesis tests. Our data is random because they are realizations of a random sample drawn from the distribution \\(F\\). Since the test statistic is computed from the data, its randomness is also induced by \\(F\\). Consequently, the decision to accept or reject the null is likewise determined by \\(F\\). The power function summarizes this chain by expressing the probability of rejection directly as a function of the underlying distribution \\(F\\).\nThe probability of making a Type I error is the size of the hypothesis test, and is simply the power function evaluated under the distribution implied by the null, \\(F_0\\): \\[\n\\mathbb{P}[\\text{Reject } H_0 \\mid F_0] = \\pi(F_0).\n\\]\nThe power of the hypothesis is the complement of the probability of making a Type II error, and is given by the power function evaluated under the distribution implied by the alternative, \\(F_1\\): \\[\n1 - \\mathbb{P}[\\text{Accept } H_0 \\mid F_1] = \\mathbb{P}[\\text{Reject } H_0 \\mid F_1] = \\pi(F_1).\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#classical-approach-to-hypothesis-testing",
    "href": "blog/hypothesis.testing.html#classical-approach-to-hypothesis-testing",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "Classical Approach to Hypothesis Testing",
    "text": "Classical Approach to Hypothesis Testing\n\nError Probabilities and Power Function\nThere are two types of incorrect decisions we could make in hypothesis testing. Rejecting the null when it is actually true is called a Type I error. Accepting the null when it is actually false is called a Type II error.\n\n\n\nTable 1: Decision outcomes in hypothesis testing.\n\n\n\\[\n\\begin{array}{c|c|c}\n& \\textbf{Accept $H_0$} & \\textbf{Reject $H_0$} \\\\\n\\hline\n\\textbf{$H_0$ True} & \\text{Correct Decision} & \\text{Type I Error} \\\\\n\\hline\n\\textbf{$H_1$ True} & \\text{Type II Error} & \\text{Correct Decision} \\\\\n\\end{array}\n\\]\n\n\n\nTo build the vocabulary and notation required to talk about the probability of making these two errors, we need to introduce the power function of a hypothesis test. This is the probability of rejecting the null \\(H_0\\) under some population distribution \\(F\\), and is denoted \\[\n\\pi(F) = \\mathbb{P}[\\text{Reject } H_0 \\mid F] = \\mathbb{P}[T \\in C \\mid F].\n\\]\nThe power function formalizes the source of randomness in hypothesis tests. Our data is random because they are realizations of a random sample drawn from the distribution \\(F\\). Since the test statistic is computed from the data, its randomness is also induced by \\(F\\). Consequently, the decision to accept or reject the null is likewise determined by \\(F\\). The power function summarizes this chain by expressing the probability of rejection directly as a function of the underlying distribution \\(F\\).\nThe probability of making a Type I error is the size of the hypothesis test, and is simply the power function evaluated under the distribution implied by the null, \\(F_0\\): \\[\n\\mathbb{P}[\\text{Reject } H_0 \\mid F_0] = \\pi(F_0).\n\\]\nThe power of the hypothesis is the complement of the probability of making a Type II error, and is given by the power function evaluated under the distribution implied by the alternative, \\(F_1\\): \\[\n1 - \\mathbb{P}[\\text{Accept } H_0 \\mid F_1] = \\mathbb{P}[\\text{Reject } H_0 \\mid F_1] = \\pi(F_1).\n\\]\n\n\nClassical Approach to the Fundamental Tradeoff\nNotice that we could mechanically decrease the probability of a Type I error by reducing the size of \\(C\\). However, this would in turn increase the probability of a Type II error. Conversely, increasing the size of \\(C\\) would decrease the probability of a Type II error, but increase the probability of a Type I error. This is the fundamental tradeoff in hypothesis testing: reducing the probability of one type of error comes at the cost of increasing the probability of the other.\nThe classical approach to hypothesis testing is to bound the size of the test at some pre-specified level \\(\\alpha \\in (0,1)\\), called the significance level. More formally, this means choosing the critical region \\(C\\) so that \\[\nP[T \\in C \\mid F_0] \\leq \\alpha.\n\\]\nTo construct such a critical region, we need to know the distribution of the test statistic \\(T\\) under the null hypothesis \\(H_0\\), called the null sampling distribution:\n\\[\nG_0(t) = \\mathbb{P}[T \\leq t \\mid F_0].\n\\]\nOne reason why we focus on bounding the probability of Type I errors instead of Type II errors is because the null sampling distribution is typically easier to derive than the distribution of \\(T\\) under the various alternative hypotheses.\n\n\nCritical Values, One-Sided and Two-Sided Tests\nFor most classical test statistics, the null sampling distribution is unimodal and symmetric, with probability that steadily decreases as we move away from the center. This implies that the least likely realizations of the test statistic under the null lie in the tails of the distribution. In such cases, the critical region can be fully characterized by a single critical value \\(c\\). For a one-sided test, the critical region is \\[\nC = \\{t: t &gt; c\\} \\quad \\text{or} \\quad C = \\{t: t &lt; c\\}.\n\\] For a two-sided test, the critical region is\n\\[\nC = \\{t: |t| &gt; c\\}.\n\\]\nThe critical value \\(c\\) is chosen so that the size of the test is equal to the significance level \\(\\alpha\\). By distributing the critical region across the tails of the null sampling distribution, we maximize the test’s power while ensuring that its size is exactly controlled at \\(\\alpha\\)."
  },
  {
    "objectID": "blog/hypothesis.testing.html#example-two-sided-test-for-normal-samplign-model",
    "href": "blog/hypothesis.testing.html#example-two-sided-test-for-normal-samplign-model",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Example: Two-Sided Test for Normal Samplign Model",
    "text": "Example: Two-Sided Test for Normal Samplign Model\n\nt-Statistic\nLet \\(\\hat\\theta\\) be an estimator of \\(\\theta\\), some parameter of interest determined by the population \\(F\\). The t-ratio or t-statistic is defined as \\[\nt = \\frac{\\hat\\theta(\\boldsymbol x) - \\theta_0}{\\widehat{SE}(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(\\widehat{SE}(\\hat\\theta)\\) is an estimator of the standard error of \\(\\hat\\theta\\). In words, this statistic measures how many estimated standard errors the estimate \\(\\hat\\theta (\\boldsymbol x)\\) is away from the hypothesized value \\(\\theta_0\\).\nRecall that in the normal sampling model \\(X_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\), the sample mean \\(\\bar X\\) is an estimator of the population mean \\(\\mu\\), and has a standard error of \\(\\sigma / \\sqrt{n}\\). Since \\(\\sigma\\) is unknown, we estimate it using the sample standard deviation \\(s\\). Thus, the t-statistic for the normal sampling model is given by \\[\nt = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#acknowledgements",
    "href": "blog/hypothesis.testing.html#acknowledgements",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nThe notation in this post primarily borrows from Bruce Hansen’s Probability and Statistics for Economists (2022)."
  },
  {
    "objectID": "blog/hypothesis.testing.html#example-two-sided-test-for-normal-sampling-model",
    "href": "blog/hypothesis.testing.html#example-two-sided-test-for-normal-sampling-model",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Example: Two-Sided Test for Normal Sampling Model",
    "text": "Example: Two-Sided Test for Normal Sampling Model\n\nt-Statistic\nLet \\(\\hat\\theta\\) be an estimator of \\(\\theta\\), some parameter of interest determined by the population \\(F\\). The t-ratio or t-statistic is defined as \\[\nt = \\frac{\\hat\\theta(\\boldsymbol x) - \\theta_0}{\\widehat{SE}(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(\\widehat{SE}(\\hat\\theta)\\) is an estimator of the standard error of \\(\\hat\\theta\\). In words, this statistic measures how many estimated standard errors the estimate \\(\\hat\\theta (\\boldsymbol x)\\) is away from the hypothesized value \\(\\theta_0\\).\nRecall that in the normal sampling model \\(X_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\), the sample mean \\(\\bar X\\) is an estimator of the population mean \\(\\mu\\), and has a standard error of \\(\\sigma / \\sqrt{n}\\). Since \\(\\sigma\\) is unknown, we estimate it using the sample standard deviation \\(s\\). Thus, the t-statistic for the normal sampling model is given by \\[\nt = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#example-two-sided-test-for-the-normal-sampling-model",
    "href": "blog/hypothesis.testing.html#example-two-sided-test-for-the-normal-sampling-model",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Example: Two-Sided Test for the Normal Sampling Model",
    "text": "Example: Two-Sided Test for the Normal Sampling Model\n\nt-Statistic\nLet \\(\\hat\\theta\\) be an estimator of \\(\\theta\\), some parameter of interest determined by the population \\(F\\). The t-ratio or t-statistic is defined as \\[\nt = \\frac{\\hat\\theta(\\boldsymbol x) - \\theta_0}{\\widehat{SE}(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(\\widehat{SE}(\\hat\\theta)\\) is an estimator of the standard error of \\(\\hat\\theta\\). In words, this statistic measures how many estimated standard errors the estimate \\(\\hat\\theta (\\boldsymbol x)\\) is away from the hypothesized value \\(\\theta_0\\).\nRecall that in the normal sampling model \\(X_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\), the sample mean \\(\\bar X\\) is an estimator of the population mean \\(\\mu\\), and has a standard error of \\(\\sigma / \\sqrt{n}\\). Since \\(\\sigma\\) is unknown, we estimate it using the sample standard deviation \\(s\\). Thus, the t-statistic for the normal sampling model is given by \\[\nt = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#example-two-sided-test-in-the-normal-sampling-model",
    "href": "blog/hypothesis.testing.html#example-two-sided-test-in-the-normal-sampling-model",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Example: Two-Sided Test in the Normal Sampling Model",
    "text": "Example: Two-Sided Test in the Normal Sampling Model\nWe have now developed all the theory needed to carry out the hypothesis test of the mean under the normal sampling model.\n\nt-Statistic\nLet \\(\\hat\\theta\\) be an estimator of \\(\\theta\\), some parameter of interest determined by the population \\(F\\). The t-ratio or t-statistic is defined as \\[\nt = \\frac{\\hat\\theta(\\boldsymbol x) - \\theta_0}{\\widehat{SE}(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(\\widehat{SE}(\\hat\\theta)\\) is an estimator of the standard error of \\(\\hat\\theta\\). In words, this statistic measures how many estimated standard errors the estimate \\(\\hat\\theta (\\boldsymbol x)\\) is away from the hypothesized value \\(\\theta_0\\).\nRecall that in the normal sampling model \\(X_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\), the sample mean \\(\\bar X\\) is an estimator of the population mean \\(\\mu\\), and has a standard error of \\(\\sigma / \\sqrt{n}\\). Since \\(\\sigma\\) is unknown, we estimate it using the sample standard deviation \\(s\\). Thus, the t-statistic for the normal sampling model is given by \\[\nt = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#critical-values-one-sided-and-two-sided-tests",
    "href": "blog/hypothesis.testing.html#critical-values-one-sided-and-two-sided-tests",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "Critical Values, One-Sided and Two-Sided Tests",
    "text": "Critical Values, One-Sided and Two-Sided Tests\nFor most classical test statistics, the null sampling distribution is unimodal and symmetric, with probability that steadily decreases as we move away from the center. This implies that the least likely realizations of the test statistic under the null lie in the tails of the distribution. In such cases, the critical region can be fully characterized by a single critical value \\(c\\). For a one-sided test, the critical region is \\[\nC = \\{t: t &gt; c\\} \\quad \\text{or} \\quad C = \\{t: t &lt; c\\}.\n\\] For a two-sided test, the critical region is\n\\[\nC = \\{t: |t| &gt; c\\}.\n\\]"
  },
  {
    "objectID": "blog/hypothesis.testing.html#p-values",
    "href": "blog/hypothesis.testing.html#p-values",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "p-Values",
    "text": "p-Values\nBlah Blah"
  },
  {
    "objectID": "blog/hypothesis.testing.html#two-sided-test-of-the-mean-in-the-normal-sampling-model",
    "href": "blog/hypothesis.testing.html#two-sided-test-of-the-mean-in-the-normal-sampling-model",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "Two-Sided Test of the Mean in the Normal Sampling Model",
    "text": "Two-Sided Test of the Mean in the Normal Sampling Model\nWe have now developed all the terminology needed to carry out the hypothesis test of the mean under the normal sampling model.\n\nt-Statistic\nThe first step to any hypothesis test is to choose a test statistic. A common choice is the t-ratio or t-statistic. For some estimator \\(\\hat\\theta\\) of the parameter of interest \\(\\theta\\), the t-statistic is defined as\n\\[\nT = \\frac{\\hat\\theta - \\theta_0}{SE(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(SE(\\hat\\theta)\\) is the standard error of \\(\\hat\\theta\\) — i.e., an estimator of the standard deviation of \\(\\hat\\theta\\). In words, the realization of this statistic measures how many standard errors away the estimate \\(\\hat\\theta(\\boldsymbol x)\\) is from the hypothesized value \\(\\theta_0\\). Thus, the realization of the t-statistic has an intuitive interpretation: a large magnitude indicates that the estimate is far from the hypothesized value in the realized sample, while small values indicate that the estimate is close to the hypothesized value.\nIn the context of testing the mean \\(\\mu\\) in the normal sampling model, the sample mean \\(\\bar X\\) is a natural estimator. Recall that the variance of the sample mean \\(\\bar X\\) in the normal sampling model is \\(\\sigma^2 / n\\). However, since \\(\\sigma^2\\) is unknown, we use the bias-corrected variance estimator \\[\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar X)^2\n\\] to estimate \\(\\sigma^2\\). The standard error of \\(\\bar X\\) is then given by the estimator \\[\nSE(\\bar X) = \\frac{s}{\\sqrt{n}}.\n\\]\nThus, the t-statistic for testing the mean \\(\\mu\\) in the normal sampling model is given by\n\\[\nT = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]\n\n\nNull Sampling Distribution\nTo construct the critical region, we need to derive the null sampling distribution of the t-statistic. A special property of the t-statistic in the normal sampling model is that it is a pivotal quantity, meaning that its null sampling distribution does not depend on unknown parameters.\nIf \\(\\sigma^2\\) is known, it can be shown that the null sampling distribution of the t-statistic is the standard normal distribution. If \\(\\sigma^2\\) is unknown, however, then the null sampling distribution is the Student’s t-distribution with \\(n-1\\) degrees of freedom. An important property of the Student’s t-distribution is that it converges to the standard normal distribution as the sample size \\(n\\) increases.\n\n\n\n\n\n\n\n\nFigure 1: The t-Distribution versus the Standard Normal Distribution.\n\n\n\n\n\n\nChoosing the Critical Value\nBlah Blah"
  },
  {
    "objectID": "blog/hypothesis.testing.html#recap",
    "href": "blog/hypothesis.testing.html#recap",
    "title": "Hypothesis Testing for the Normal Sampling Model",
    "section": "",
    "text": "Recall the basic setup of statistical inference under the random sampling framework. Here, we view the observed data \\(\\boldsymbol x = (x_1, \\ldots, x_n)'\\) as a realization of the random variables \\(\\boldsymbol X = (X_1, \\ldots, X_n)'\\) independently drawn from a common, unknown distribution \\(F\\). In other words, the data is a realization of a random sample from the population \\(F\\). The goal of statistical inference is to use the random sample to make statements about \\(F\\), while quantifying the uncertainty in those statements.\nTypically, to conduct statistical inference, we need to make some starting assumptions about the structure of \\(F\\). This is called a statistical model for \\(F\\). In this post, we will work with the normal sampling model, where we assume that \\(F\\) is the normal distribution with unknown mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\)."
  },
  {
    "objectID": "blog/hypothesis.testing.html#introduction",
    "href": "blog/hypothesis.testing.html#introduction",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "",
    "text": "Recall the basic setup of frequentist statistical inference under the random sampling framework. Here, we view the observed data \\(\\boldsymbol x = (x_1, \\ldots, x_n)'\\) as a realization of the random variables \\(\\boldsymbol X = (X_1, \\ldots, X_n)'\\) independently drawn from an an unknown, common (identical) distribution \\(F\\).1 In other words, the data \\(\\boldsymbol x\\) is a realization of a random sample \\(\\boldsymbol X\\) from the population \\(F\\). The goal of statistical inference is to use the abstraction of random sampling to make statements about \\(F\\), while quantifying the uncertainty in those statements. Typically, we need to make some starting assumptions about the structure of \\(F\\) to be able to say anything interesting about it. This is called a statistical model for \\(F\\). In this post, we will work with the normal sampling model, where we assume that \\(F\\) is the normal distribution with unknown mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\).\n1 The phrasing \\(X\\) “drawn” from \\(F\\) is informal shorthand to mean the random variable \\(X\\) has the distribution \\(F\\).Previously, we discussed one form of statistical inference: point estimation. This entailed developing a rule (i.e. an estimator) that used the realized data to produce a best guess (i.e. an estimate) of some parameter of interest \\(\\theta\\) determined by the population \\(F\\). In point estimation, uncertainty arises from the fact that the estimator is a function of the random sample, and is therefore also random. The uncertainty is quantified by asking the question: “If we repeatedly drew random samples from the population and computed the estimate each time, how would the estimates vary?” The answer to this question was given by the sampling distribution of the estimator."
  },
  {
    "objectID": "blog/hypothesis.testing.html#confidence-intervals",
    "href": "blog/hypothesis.testing.html#confidence-intervals",
    "title": "Frequentist Statistical Inference II: Hypothesis Testing and Confidence Intervals",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nBlah blah"
  },
  {
    "objectID": "blog/statistical-inference-1.html",
    "href": "blog/statistical-inference-1.html",
    "title": "Statistical Inference I: Random Sampling",
    "section": "",
    "text": "This post is the first in a three-part series on statistical inference — which I broadly define for now as the process of deriving conclusions about underlying truths from observed data. In this sense, statistical inference forms the foundation of empirical research, and a clear grasp of its underlying ideas is essential for conducting and critically evaluating empirical work. The goal of this post is to introduce the frequentist formalization of statistical inference. The subsequent posts discuss the two major types of inference in the frequentist paradigm: point estimation and hypothesis testing."
  },
  {
    "objectID": "blog/statistical-inference-1.html#what-is-statistical-inference",
    "href": "blog/statistical-inference-1.html#what-is-statistical-inference",
    "title": "Statistical Inference I: Random Sampling",
    "section": "What is Statistical Inference?",
    "text": "What is Statistical Inference?\nObservational data is inherently random: if we were to measure the same variables repeatedly, we would almost certainly get different values each time. A classical explanation for the source of this randomness is the model-based (or sampling-based) perspective. In this abstraction, we assume there exists an underlying superpopulation or data generating process (DGP): a fixed but unknown probability distribution \\(F\\) that can, in principle, generate infinitely many observations. Randomness then arises because we only observe finitely many realizations from \\(F\\) — never the entire distribution. Within this framework, we define statistical inference as the process of using the observed random data to estimate features of \\(F\\) and quantify the uncertainty in those estimates.\nNotice that the exposition above implicitly assumes that there is a single underlying distribution \\(F\\) from which all observed data are drawn. To make this mathematically precise, we need to introduce the random sampling assumption. This provides the framework to connect the observed data to the DGP, and thereby lays the foundation for statistical inference."
  },
  {
    "objectID": "blog/statistical-inference-1.html#the-random-sampling-framework",
    "href": "blog/statistical-inference-1.html#the-random-sampling-framework",
    "title": "Statistical Inference I: Random Sampling",
    "section": "The Random Sampling Framework",
    "text": "The Random Sampling Framework\nSo far, we have introduced the frequentist thought experiment in a general setting, where uncertainty is formalized in terms of repeated draws from some fixed joint distribution \\(F\\) on \\(\\mathbb{R}^{Kn}\\). However, this generality makes it difficult to conceptualize the form of the DGP and what “repeated sampling” from it entails. To make things tractable, we impose simplifying assumptions on the dependence structure across \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\).\nThe most common approach is to assume that the random vectors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\) are independent and identically distributed (iid) with some common but unknown marginal distribution \\(G\\) on \\(\\mathbb{R}^K\\). Statisticians refer to \\(\\boldsymbol X_1, \\ldots , \\boldsymbol X_n\\) as a random sample from \\(G\\) if they satisfy these two properties. Under this assumption, the DGP simplifies considerably. Because of independence, the joint distribution can be written as the product of the marginals: \\[\nF(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n) = G(\\boldsymbol X_1) \\times \\ldots \\times G(\\boldsymbol X_n) = \\prod _{i=1}^n G(\\boldsymbol X_i).\n\\tag{1}\\] The factorization in Equation 1 shows us that the DGP \\(F\\) is fully characterized by the single marginal distribution \\(G\\). In other words, under random sampling, drawing once from \\(F\\) is equivalent to independently drawing \\(n\\) random variables from \\(G\\). Since \\(G\\) now fully specifies the DGP, we will henceforth refer to it as the DGP and denote it as \\(F\\).4\n4 That is, the random sampling assumption allows us to simplify the DGP from a joint distribution over \\(R^{Kn}\\) to a single marginal distribution over \\(R^K\\).\nEvaluating the Random Sampling Assumption\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets5, and (ii) it is the backbone of several statistical theorems and methods.6 However, it does not necessarily have to hold. For example, we often work with data where the units are connected via some underlying factor (location, industry, etc.). In such cases, the assumption of independence across individual units is violated. An alternative approach in such cases is to instead assume mutual independence across clusters of units. Another example of a violation to the independence assumption is time-series data, where the individual unit is indexed by time. Here, consecutive observations are usually correlated and independence is instead formulated in terms of stationarity and other concepts outside the scope of this post.\n5 For example, if we collected data on a random subset of individuals from a large common population, it is reasonable to assume that the characteristics of one individual are independent of another individual and that all individuals’ characteristics follow the same distribution.6 Crucial theorems in asymptotic statistical theory, like the Law of Large Numbers and the Central Limit Theorem, require the random sampling assumption to hold."
  },
  {
    "objectID": "blog/statistical-inference-3.html",
    "href": "blog/statistical-inference-3.html",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "",
    "text": "Recall the basic setup of frequentist statistical inference under the random sampling framework. Here, we view the observed data \\(\\boldsymbol x = (x_1, \\ldots, x_n)'\\) as a realization of the random variables \\(\\boldsymbol X = (X_1, \\ldots, X_n)'\\) independently drawn from an an unknown, common (identical) distribution \\(F\\).1 In other words, the data \\(\\boldsymbol x\\) is a realization of a random sample \\(\\boldsymbol X\\) from the population \\(F\\). The goal of statistical inference is to use the abstraction of random sampling to make statements about \\(F\\), while quantifying the uncertainty in those statements. Typically, we need to make some starting assumptions about the structure of \\(F\\) to be able to say anything interesting about it. This is called a statistical model for \\(F\\). In this post, we will work with the normal sampling model, where we assume that \\(F\\) is the normal distribution with unknown mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\).\n1 The phrasing \\(X\\) “drawn” from \\(F\\) is informal shorthand to mean the random variable \\(X\\) has the distribution \\(F\\).Previously, we discussed one form of statistical inference: point estimation. This entailed developing a rule (i.e. an estimator) that used the realized data to produce a best guess (i.e. an estimate) of some parameter of interest \\(\\theta\\) determined by the population \\(F\\). In point estimation, uncertainty arises from the fact that the estimator is a function of the random sample, and is therefore also random. The uncertainty is quantified by asking the question: “If we repeatedly drew random samples from the population and computed the estimate each time, how would the estimates vary?” The answer to this question was given by the sampling distribution of the estimator."
  },
  {
    "objectID": "blog/statistical-inference-3.html#introduction",
    "href": "blog/statistical-inference-3.html#introduction",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "",
    "text": "Recall the basic setup of frequentist statistical inference under the random sampling framework. Here, we view the observed data \\(\\boldsymbol x = (x_1, \\ldots, x_n)'\\) as a realization of the random variables \\(\\boldsymbol X = (X_1, \\ldots, X_n)'\\) independently drawn from an an unknown, common (identical) distribution \\(F\\).1 In other words, the data \\(\\boldsymbol x\\) is a realization of a random sample \\(\\boldsymbol X\\) from the population \\(F\\). The goal of statistical inference is to use the abstraction of random sampling to make statements about \\(F\\), while quantifying the uncertainty in those statements. Typically, we need to make some starting assumptions about the structure of \\(F\\) to be able to say anything interesting about it. This is called a statistical model for \\(F\\). In this post, we will work with the normal sampling model, where we assume that \\(F\\) is the normal distribution with unknown mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\).\n1 The phrasing \\(X\\) “drawn” from \\(F\\) is informal shorthand to mean the random variable \\(X\\) has the distribution \\(F\\).Previously, we discussed one form of statistical inference: point estimation. This entailed developing a rule (i.e. an estimator) that used the realized data to produce a best guess (i.e. an estimate) of some parameter of interest \\(\\theta\\) determined by the population \\(F\\). In point estimation, uncertainty arises from the fact that the estimator is a function of the random sample, and is therefore also random. The uncertainty is quantified by asking the question: “If we repeatedly drew random samples from the population and computed the estimate each time, how would the estimates vary?” The answer to this question was given by the sampling distribution of the estimator."
  },
  {
    "objectID": "blog/statistical-inference-3.html#hypotheses",
    "href": "blog/statistical-inference-3.html#hypotheses",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "Hypotheses",
    "text": "Hypotheses\nHypothesis testing is a fundamental tool to conduct statistical inference. At its core is the hypothesis: a statement about a scalar parameter of interest \\(\\theta\\) determined by the population \\(F\\). In a non-parametric model — where \\(F\\) cannot be fully characterized by a finite set of model parameters — \\(\\theta\\) is some function of \\(F\\), like \\(\\mathbb{E}[X]\\) or \\(\\operatorname{Var}(X)\\). In a parametric model — where \\(F\\) is assumed to belong to a family of distribution characterized by a finite number of parameters — \\(\\theta\\) is typically one of the model parameters.2 For example, in the normal sampling model, our hypotheses are usually about \\(\\mu\\) or \\(\\sigma^2\\).\n2 It is worth emphasizing that while the parameter of interest is often the model parameters, the two are not always the same.3 Technically, the null hypothesis can be a set of values as well. However, in this post, we focus on point (null) hypotheses.Hypothesis testing is formulated in terms of two complementary hypotheses. The null hypothesis \\(H_0\\) is the hypothesis to be tested, while the alternative hypothesis \\(H_1\\) is the complement of the null hypothesis. These hypotheses can be defined by how they restrict the parameter space of \\(\\theta\\), denoted \\(\\Theta\\). Specifically, the null is defined by the restriction \\(\\theta = \\theta_0\\) for some hypothesized value \\(\\theta_0\\), while the alternative is defined by the set \\(\\{\\theta \\in \\Theta: \\theta \\neq \\theta_0\\}\\).3\nIn this post, we will focus on the problem of testing hypotheses about the population mean \\(\\mu\\) under the normal sampling model. Specifically, our hypotheses are \\[\nH_0: \\mu = \\mu_0 \\quad \\text{and} \\quad H_1: \\mu \\neq \\mu_0,\n\\] where \\(\\mu_0\\) is some hypothesized value of \\(\\mu\\). The goal of hypothesis testing is to test the validity of \\(H_0\\) over \\(H_1\\) using the random sample. In the next few sections, we will develop the machinery required to do exactly this."
  },
  {
    "objectID": "blog/statistical-inference-3.html#test-statistic-and-critical-region",
    "href": "blog/statistical-inference-3.html#test-statistic-and-critical-region",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "Test Statistic and Critical Region",
    "text": "Test Statistic and Critical Region\nThe outcome of a hypothesis test is a decision: either accept the null or reject the null in favor of the alternative. Thus, we want a decision rule that maps the sample space — the set of all possible realizations of the random sample — into one of these two actions. One way to formulate this rule is as follows. First, we construct a function of the random sample called the test statistic\n\\[\nT: \\boldsymbol X \\rightarrow \\mathbb{R}.\n\\] The role of the test statistic is to take any random sample from the population and compress it into a single number that reflects the information most relevant to the hypothesis. Since it is a function of random variables, the test statistic is itself a random variable. Second, we define a critical region \\(C\\) to be some subset of the range of \\(T\\). The decision rule can then be framed in terms of the observed realization of the test statistic, \\(t\\): (i) reject \\(H_0\\) if \\(t \\in C\\), and (ii) accept \\(H_0\\) if \\(t \\notin C\\).\nIt’s worth pausing here to emphasize two important features of this setup. First, the effectiveness of a hypothesis test depends on the choice of both the test statistic and critical region. If \\(T\\) does not capture the right information, or if \\(C\\) is poorly specified, the resulting decision rule will not be very insightful. Second, making incorrect decisions is inevitable in hypothesis testing because of the randomness inherent in the sample. Even with a well-chosen statistic and critical region, it is entirely possible to draw a sample with a mean far from the true population mean \\(\\mu\\) but close to the hypothesized mean \\(\\mu_0\\), or conversely, a sample far from \\(\\mu_0\\) even when \\(\\mu = \\mu_0\\). In both situations, we make an incorrect decision purely due to chance.\nThus, in carrying out hypothesis tests, the focus is not on eliminating mistakes entirely, but rather on quantifying and controlling the probability of error. The following section formalizes this idea."
  },
  {
    "objectID": "blog/statistical-inference-3.html#classical-approach-to-hypothesis-testing",
    "href": "blog/statistical-inference-3.html#classical-approach-to-hypothesis-testing",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "Classical Approach to Hypothesis Testing",
    "text": "Classical Approach to Hypothesis Testing\n\nError Probabilities and Power Function\nThere are two types of incorrect decisions we could make in hypothesis testing. Rejecting the null when it is actually true is called a Type I error. Accepting the null when it is actually false is called a Type II error.\n\n\n\nTable 1: Decision outcomes in hypothesis testing.\n\n\n\\[\n\\begin{array}{c|c|c}\n& \\textbf{Accept $H_0$} & \\textbf{Reject $H_0$} \\\\\n\\hline\n\\textbf{$H_0$ True} & \\text{Correct Decision} & \\text{Type I Error} \\\\\n\\hline\n\\textbf{$H_1$ True} & \\text{Type II Error} & \\text{Correct Decision} \\\\\n\\end{array}\n\\]\n\n\n\nTo build the vocabulary and notation required to talk about the probability of making these two errors, we need to introduce the power function of a hypothesis test. This is the probability of rejecting the null \\(H_0\\) under some population distribution \\(F\\), and is denoted \\[\n\\pi(F) = \\mathbb{P}[\\text{Reject } H_0 \\mid F] = \\mathbb{P}[T \\in C \\mid F].\n\\]\nThe power function formalizes the source of randomness in hypothesis tests. Our data is random because they are realizations of a random sample drawn from the distribution \\(F\\). Since the test statistic is computed from the data, its randomness is also induced by \\(F\\). Consequently, the decision to accept or reject the null is likewise determined by \\(F\\). The power function summarizes this chain by expressing the probability of rejection directly as a function of the underlying distribution \\(F\\).\nThe probability of making a Type I error is the size of the hypothesis test, and is simply the power function evaluated under the distribution implied by the null, \\(F_0\\): \\[\n\\mathbb{P}[\\text{Reject } H_0 \\mid F_0] = \\pi(F_0).\n\\]\nThe power of the hypothesis is the complement of the probability of making a Type II error, and is given by the power function evaluated under the distribution implied by the alternative, \\(F_1\\): \\[\n1 - \\mathbb{P}[\\text{Accept } H_0 \\mid F_1] = \\mathbb{P}[\\text{Reject } H_0 \\mid F_1] = \\pi(F_1).\n\\]\n\n\nClassical Approach to the Fundamental Tradeoff\nNotice that we could mechanically decrease the probability of a Type I error by reducing the size of \\(C\\). However, this would in turn increase the probability of a Type II error. Conversely, increasing the size of \\(C\\) would decrease the probability of a Type II error, but increase the probability of a Type I error. This is the fundamental tradeoff in hypothesis testing: reducing the probability of one type of error comes at the cost of increasing the probability of the other.\nThe classical approach to hypothesis testing is to bound the size of the test at some pre-specified level \\(\\alpha \\in (0,1)\\), called the significance level. More formally, this means choosing the critical region \\(C\\) so that \\[\nP[T \\in C \\mid F_0] \\leq \\alpha.\n\\]\nTo construct such a critical region, we need to know the distribution of the test statistic \\(T\\) under the null hypothesis \\(H_0\\), called the null sampling distribution:\n\\[\nG_0(t) = \\mathbb{P}[T \\leq t \\mid F_0].\n\\]\nOne reason why we focus on bounding the probability of Type I errors instead of Type II errors is because the null sampling distribution is typically easier to derive than the distribution of \\(T\\) under the various alternative hypotheses.\n\n\nCritical Values, One-Sided and Two-Sided Tests\nFor most classical test statistics, the null sampling distribution is unimodal and symmetric, with probability that steadily decreases as we move away from the center. This implies that the least likely realizations of the test statistic under the null lie in the tails of the distribution. In such cases, the critical region can be fully characterized by a single critical value \\(c\\). For a one-sided test, the critical region is \\[\nC = \\{t: t &gt; c\\} \\quad \\text{or} \\quad C = \\{t: t &lt; c\\}.\n\\] For a two-sided test, the critical region is\n\\[\nC = \\{t: |t| &gt; c\\}.\n\\]\nThe critical value \\(c\\) is chosen so that the size of the test is equal to the significance level \\(\\alpha\\). By distributing the critical region across the tails of the null sampling distribution, we maximize the test’s power while ensuring that its size is exactly controlled at \\(\\alpha\\)."
  },
  {
    "objectID": "blog/statistical-inference-3.html#two-sided-test-of-the-mean-in-the-normal-sampling-model",
    "href": "blog/statistical-inference-3.html#two-sided-test-of-the-mean-in-the-normal-sampling-model",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "Two-Sided Test of the Mean in the Normal Sampling Model",
    "text": "Two-Sided Test of the Mean in the Normal Sampling Model\nWe have now developed all the terminology needed to carry out the hypothesis test of the mean under the normal sampling model.\n\nt-Statistic\nThe first step to any hypothesis test is to choose a test statistic. A common choice is the t-ratio or t-statistic. For some estimator \\(\\hat\\theta\\) of the parameter of interest \\(\\theta\\), the t-statistic is defined as\n\\[\nT = \\frac{\\hat\\theta - \\theta_0}{SE(\\hat\\theta)},\n\\] where \\(\\theta_0\\) is a hypothesized value of \\(\\theta\\) and \\(SE(\\hat\\theta)\\) is the standard error of \\(\\hat\\theta\\) — i.e., an estimator of the standard deviation of \\(\\hat\\theta\\). In words, the realization of this statistic measures how many standard errors away the estimate \\(\\hat\\theta(\\boldsymbol x)\\) is from the hypothesized value \\(\\theta_0\\). Thus, the realization of the t-statistic has an intuitive interpretation: a large magnitude indicates that the estimate is far from the hypothesized value in the realized sample, while small values indicate that the estimate is close to the hypothesized value.\nIn the context of testing the mean \\(\\mu\\) in the normal sampling model, the sample mean \\(\\bar X\\) is a natural estimator. Recall that the variance of the sample mean \\(\\bar X\\) in the normal sampling model is \\(\\sigma^2 / n\\). However, since \\(\\sigma^2\\) is unknown, we use the bias-corrected variance estimator \\[\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar X)^2\n\\] to estimate \\(\\sigma^2\\). The standard error of \\(\\bar X\\) is then given by the estimator \\[\nSE(\\bar X) = \\frac{s}{\\sqrt{n}}.\n\\]\nThus, the t-statistic for testing the mean \\(\\mu\\) in the normal sampling model is given by\n\\[\nT = \\frac{\\bar X - \\mu_0}{s / \\sqrt{n}}.\n\\]\n\n\nNull Sampling Distribution\nTo construct the critical region, we need to derive the null sampling distribution of the t-statistic. A special property of the t-statistic in the normal sampling model is that it is a pivotal quantity, meaning that its null sampling distribution does not depend on unknown parameters.\nIf \\(\\sigma^2\\) is known, it can be shown that the null sampling distribution of the t-statistic is the standard normal distribution. If \\(\\sigma^2\\) is unknown, however, then the null sampling distribution is the Student’s t-distribution with \\(n-1\\) degrees of freedom. An important property of the Student’s t-distribution is that it converges to the standard normal distribution as the sample size \\(n\\) increases.\n\n\n\n\n\n\n\n\nFigure 1: The t-Distribution versus the Standard Normal Distribution.\n\n\n\n\n\n\nChoosing the Critical Value\nBlah Blah"
  },
  {
    "objectID": "blog/statistical-inference-3.html#p-values",
    "href": "blog/statistical-inference-3.html#p-values",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "p-Values",
    "text": "p-Values\nBlah Blah"
  },
  {
    "objectID": "blog/statistical-inference-3.html#confidence-intervals",
    "href": "blog/statistical-inference-3.html#confidence-intervals",
    "title": "Statistical Inference III: Hypothesis Testing and Confidence Intervals",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nBlah blah"
  },
  {
    "objectID": "blog/statistical-inference-2.html",
    "href": "blog/statistical-inference-2.html",
    "title": "Statistical Inference II: Point Estimation",
    "section": "",
    "text": "This is the second post in a three-part series on statistical inference. Previously, I introduced the general framework of frequentist statistical inference under the random sampling assumption. Here, we view the observed data \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) as a realization of the random vectors \\(\\{\\boldsymbol X_i\\}_{i=1}^n\\) independently drawn from an an unknown, common distribution \\(F\\).1 The goal of frequentist statistical inference is to use this abstraction to make conclusions about \\(F\\) based on the observed data and quantify the uncertainty in those statements. Specifically, the frequentist thought experiment reasons about uncertainty by asking how frequently we would see the observed data if we repeatedly sampled from the data generating process \\(F\\).\n1 Recall that \\(\\boldsymbol x_i = (x_{i1}, \\ldots, x_{iK})'\\) and \\(\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})\\).We have not yet discussed the type of conclusions we make about \\(F\\) in statistical inference. In this post, I focus on point estimation, which is a form of statistical inference that involves constructing a “good guess” of a feature of \\(F\\)."
  },
  {
    "objectID": "blog/statistical-inference-2.html#point-estimation",
    "href": "blog/statistical-inference-2.html#point-estimation",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Point Estimation",
    "text": "Point Estimation\n\nNotation\nBefore formally developing the notion of point estimation, it is useful to clarify the notation used in this post. Previously, I had introduced the random sampling framework using vector-valued quantities \\(\\boldsymbol X_i, \\boldsymbol x_i \\in \\mathbb{R}^K\\). To keep the exposition in this post simple, I focus on the case where \\(K=1\\). In this setting, the data generating process \\(F\\) is a univariate distribution, and our discussion of point estimation is limited to scalar-valued quantities.2\n2 Nevertheless, the conceptual ideas discussed here extend to vector quantities in a fairly straightforward manner.3 I don’t think this is standard terminology, but it helps with my intuition.Under this set up, a random sample of size \\(n\\) from \\(F\\) consists of the random variables \\(X_1, \\ldots, X_n\\). Their corresponding realizations are the scalars \\(x_1, \\ldots, x_n\\). Additionally, when discussing statistical inference in the random sampling framework, it is useful to distinguish between population-level and sample-level random variables.3 The population-level random variable, denoted \\(X\\), is a generic random variable with distribution \\(F\\) that is used as a reference variable when defining features of the DGP. The sample-level random variables, denoted \\(X_i\\), represent the specific draws that make up our random sample. With this notation established, we are now ready to formally discuss point estimation.\n\n\nEstimand, Estimator, and Estimate\nThe feature of the DGP \\(F\\) that we want to learn about is called an estimand \\(\\theta\\) and is defined as a function of \\(F\\): \\[\n\\theta = \\theta(F).\n\\]\nCommon examples of an estimand include the the population mean \\[\n\\mu = \\mathbb{E}[X],\n\\] and population variance \\[\n\\sigma^2 = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2.\n\\] Since the DGP is unknown, the best we can do is use the random sample to guess the value of the estimand. An estimator \\(\\hat \\theta\\) is a function of the sample that is intended to provide a guess of the estimand:\n\\[\n\\hat{\\theta} = \\hat{\\theta}(X_1, \\ldots, X_n).\n\\] When the estimator is evaluated at a specific realization of the sample, we obtain an estimate \\[\n\\hat\\theta = \\hat\\theta(x_1, \\ldots, x_n)\n\\] of the estimand. Notice that the notation \\(\\hat\\theta\\) is used to denote both the estimator and the estimate — the context should make it clear which one is being referred to.\nIt’s worth emphasizing that the estimand is a fixed but unknown scalar because it is a function of the fixed but unknown DGP \\(F\\), the estimator is a random variable because it is a function of the random sample, and the estimate is a fixed and known scalar because it is a function of the observed data."
  },
  {
    "objectID": "blog/statistical-inference-2.html#the-necessity-for-statistical-models",
    "href": "blog/statistical-inference-2.html#the-necessity-for-statistical-models",
    "title": "Statistical Inference II: Point Estimation",
    "section": "The Necessity for Statistical Models",
    "text": "The Necessity for Statistical Models\nThe sampling distribution of an estimator is the probability distribution that describes how the estimator’s estimates vary across all possible samples of size \\(n\\) drawn from the DGP. Intuitively, it characterizes the behavior of the estimator under repeated sampling. Under the random sampling assumption, the sampling distribution is completely determined by the DGP \\(F\\), the sample size \\(n\\), and the functional form of the estimator \\(\\hat\\theta\\).\nLet’s revisit the example of the sample mean estimator \\(\\hat\\mu\\) for the population mean \\(\\mu\\). We have already established some features of the sampling distribution of \\(\\hat\\mu\\) despite knowing nothing about \\(F\\). Particularly, the mean of \\(\\hat\\mu\\) is \\(\\mu\\) and its variance is \\(\\sigma^2/n\\). However, to say more about the distribution of \\(\\hat\\mu\\) — like its shape — we need to make assumptions about the DGP.\nA statistical model is a set of assumptions about the general structure of the data generating process \\(F\\). Put differently, we can think of a statistical model as a family of possible distributions that \\(F\\) could belong to. To illustrate the added value of statistical models, suppose our sample \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n\\) is drawn iid from \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Since\n\\[\n\\hat\\mu = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol X_i,\n\\]\nis a linear combination of normally distributed random variables, it is also normally distributed. Moreover, we have previously established that \\(\\mathbb{E}_F[\\hat\\mu] = \\mu\\) and \\(\\operatorname{Var}[\\hat\\mu] = \\sigma^2/n\\) for any DGP \\(F\\). Thus, assumption of a normal DGP allows us to completely characterize the sampling distribution of \\(\\hat\\mu\\) as \\(\\mathcal{N}(\\mu, \\sigma^2/n)\\). This is powerful because we can use this sampling distribution to quantify the uncertainty in our estimates by constructing confidence intervals and conducting hypothesis tests."
  },
  {
    "objectID": "blog/statistical-inference-2.html#conclusion",
    "href": "blog/statistical-inference-2.html#conclusion",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Conclusion",
    "text": "Conclusion\n\n\n\n\n\nflowchart LR\n  classDef box fill:#f8f9fa,stroke:#444,stroke-width:1px,rx:10,ry:10;\n\n  DGP[\"Data Generating Process\"]:::box\n  Data[\"Observed Data\"]:::box\n  Model[\"Statistical Model\"]:::box\n\n  %% Main flows\n  DGP -- \"Random Sampling\" --&gt; Data\n  DGP -. \"Assumptions\" .-&gt; Model\n  Model -- \"Probability\" --&gt; Data\n  Data -- \"Inference\" --&gt; Model\n  Model -. \"Approximate Reality\" .-&gt; DGP\n\n\n\n\n\n\nIt is important to note that statistical inference is valid only if the assumptions of statistical model hold."
  },
  {
    "objectID": "blog/statistical-inference-2.html#footnotes",
    "href": "blog/statistical-inference-2.html#footnotes",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTechnically, under iid sampling, the empirical distribution converges to the true distribution as the sample size tends to infinity — a result known as the Glivenko–Cantelli theorem. Nevertheless, in any finite sample, uncertainty remains, and with it the need for statistical inference.↩︎\nTo quote my Mathematical Statistics Professor Daniel Weiner: “Do to the sample to get your estimator, as you would do to your population to get your estimand.”↩︎\nTo be more precise, \\(\\hat\\theta\\) is unbiased for \\(\\theta\\) if \\(\\mathbb{E}[\\hat\\theta]=\\theta\\) for all \\(F \\in \\mathcal{F}\\), where \\(\\mathcal{F}\\) is a class of distributions.↩︎"
  },
  {
    "objectID": "blog/statistical-inference-1.html#introduction",
    "href": "blog/statistical-inference-1.html#introduction",
    "title": "Statistical Inference I: Random Sampling",
    "section": "",
    "text": "This post is the first in a three-part series on statistical inference — which I broadly define for now as the process of deriving conclusions about underlying truths from observed data. In this sense, statistical inference forms the foundation of empirical research, and a clear grasp of its underlying ideas is essential for conducting and critically evaluating empirical work. The goal of this post is to introduce the frequentist formalization of statistical inference. The subsequent posts discuss the two major types of inference in the frequentist paradigm: point estimation and hypothesis testing."
  },
  {
    "objectID": "blog/statistical-inference-1.html#the-frequentist-thought-experiment",
    "href": "blog/statistical-inference-1.html#the-frequentist-thought-experiment",
    "title": "Statistical Inference I: Random Sampling",
    "section": "The Frequentist Thought Experiment",
    "text": "The Frequentist Thought Experiment\nLet’s denote the observed data as the scalar vectors \\[\n\\boldsymbol x_i = (x_{i1}, \\ldots, x_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n\n\\] where \\(i\\) indexes the observational unit, \\(x_{ik}\\) is the value of the \\(k\\)-th variable for the \\(i\\)-th unit, \\(K\\) is the number of variables, and \\(n\\) is the number of units. For example, \\(\\boldsymbol x_i\\) is the \\(i\\)-th row of the CPS dataset above, \\(x_{11}\\) is the age of the first individual, \\(x_{24}\\) is the education of the second individual, and so on.\nAs a mathematical abstraction, we will view the observed data \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) as a realization of the random vectors \\[\n\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n.\n\\] The data generating process (DGP) \\(F\\) is then the joint distribution of \\((\\boldsymbol X_1, \\ldots, \\boldsymbol X_n)\\). As things stand, these quantities seem like vacuous mathematical objects. To see their relevance in reasoning about the uncertainty in our observed data, let’s consider the following thought experiment. Fix some DGP \\(F\\) and repeatedly draw from it. For each new draw \\(\\{\\boldsymbol X_i\\}_{i=1}^n\\), we would obtain a different realization \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) based on the probabilistic structure induced by \\(F\\).2 The frequentist perspective of statistical inference frames uncertainty in terms of how frequently we would observe data similar to \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) in such (hypothetical) repeated draw.\n2 As far as I know, there is no formal definition of draw in statistics. Here, I simply mean we collect \\(n\\) random variables whose joint distribution is given by \\(F\\).3 In this way, the quantities \\(\\{\\boldsymbol X_i\\}_{i=1}^n\\) and \\(F\\) are theoretical constructs that formalize the frequentist thought experiment. In contrast, \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) is the actual data we observe.Let’s revisit the CPS dataset and see how the thought experiment helps motivate the notation we have developed. We view each each variable (column) in the CPS — age, sex, race, earnings, etc. — as random vectors. For example, \\(X_{11}\\) denotes the age of the first individual in any draw from the DGP. This is in contrast to the realized value \\(x_{11}\\), which denotes the realized age of the first individual in the specific draw we observe. More generally, the random variable \\(X_{i1}\\) captures the frequentist idea of variability in the age of the \\(i\\)-th observational unit across repeated draws from \\(F\\).3 Intuitively, we can think about the random vectors \\(\\{\\boldsymbol X_i\\}_{i=1}^n\\) as the data before viewing the specific draw, and the deterministic realizations \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) as the data after viewing the draw.\n\nAlternative Thought Experiments\nIt should be noted that the frequentist perspective is a mental model that helps us reason about uncertainty. Therefore, we must still consider whether it is a reasonable description of how uncertainty arises in our conclusions from observational data. An alternative explanation for the source of uncertainty is the Bayesian perspective. Here, we do not assume that the DGP is a fixed distribution as in the frequentist perspective. Instead, the data is treated as fixed once realized, and uncertainty in our conclusions is formalized by placing a probability distribution over the possible DGPs that could have generated the specific instance of the data.\nThere is no universal answer to which perspective is correct. The choice between the two is typically driven by the context of the empirical problem at hand. As far as applied microeconomics is concerned, the frequentist perspective can almost always be justified as a reasonable description of uncertainty in our conclusions."
  },
  {
    "objectID": "blog/statistical-inference-1.html#footnotes",
    "href": "blog/statistical-inference-1.html#footnotes",
    "title": "Statistical Inference I: Random Sampling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nInductive reasoning refers to making generalized conclusions based on specific instances.↩︎"
  },
  {
    "objectID": "blog/statistical-inference-1.html#formalizing-the-source-of-uncertainty",
    "href": "blog/statistical-inference-1.html#formalizing-the-source-of-uncertainty",
    "title": "Statistical Inference I: Random Sampling",
    "section": "Formalizing the Source of Uncertainty",
    "text": "Formalizing the Source of Uncertainty\nUncertainty exists in any general conclusion we make from observed data because the underlying process that generated the data is unknown to us. Statistical inference involves quantifying the uncertainty in our conclusions. To this end, let’s start by positing that there exists some probability distribution \\(F\\) — called the data generating process (DGP) — that produces the data we observe and represents the quantity (the underlying truth) we seek to make statements about. Observed data is then viewed as a realized sample from \\(F\\).2 This mathematical abstraction will allow us to use the tools of probability theory to reason about the uncertainty in our conclusions.\n2 A sample from \\(F\\) is a collection of random variables with the distribution \\(F\\).Let’s introduce some notation to make this idea more clear. We will denote the observed data as \\[\n\\boldsymbol{x}_i = (x_{i1}, \\ldots, x_{iK}) \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n,\n\\] where \\(i\\) indexes the observational unit, \\(x_{ik}\\) is the value of the \\(k\\)-th variable for the \\(i\\)-th unit, \\(K\\) is the number of variables, and \\(n\\) is the number of units. We view \\(\\boldsymbol x_i\\) as a realization of the random vector \\[\n\\boldsymbol{X}_i = (X_{i1}, \\ldots, X_{iK})' \\in \\mathbb{R}^K \\quad \\text{for } i = 1, \\ldots, n.\n\\] The DGP \\(F\\) is then the joint distribution of \\((\\boldsymbol X_1, \\ldots, \\boldsymbol X_n)\\).\nTo see how this abstraction helps in describing uncertainty, consider the following thought experiment. Suppose we repeatedly sample from some fixed DGP \\(F\\). Then, each new sample \\(\\{\\boldsymbol X_i\\}_{i=1}^n\\) would yield a different realization \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\). In this context, the frequentist perspective on statistical inference frames uncertainty in terms of how frequently we would observe data similar to \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) if we repeatedly sampled from \\(F\\).\nIt’s useful to situate this discussion in the context of a real empirical dataset. Let’s consider the March 2009 Current Population Survey (CPS) dataset, which surveyed \\(50,742\\) individuals in the US and recorded their demographic and labor market characteristics.\nWe view each variable in the CPS dataset — age, sex, race, education, earnings, etc. — as random and the observed data points as realizations of these random variables. For example, \\(X_{11}\\) denotes the age of the first individual in the sample and \\(x_{11}\\) denotes the realized age of the first individual in the sample, which is \\(52\\). This captures the frequentist idea that if we were to resample from the underlying DGP, the realized value of the first individual would change. Intuitively, we can also think about the realization of a random variable as viewing the sample. In this formulation, \\(X_{i1}\\) denotes the age before viewing the sample (unknown and random) and \\(x_{i1}\\) denotes the age after viewing the sample (known and deterministic)."
  },
  {
    "objectID": "blog/statistical-inference-1.html#the-random-sampling-framework-1",
    "href": "blog/statistical-inference-1.html#the-random-sampling-framework-1",
    "title": "Statistical Inference I: Random Sampling",
    "section": "The Random Sampling Framework",
    "text": "The Random Sampling Framework\n\nEvaluating the Frequentist Mental Model\nIt should be noted that the frequentist perspective is a mental model that helps us reason about uncertainty.2 Therefore, we must still consider whether it is a reasonable description of how uncertainty arises in our conclusions from observational data. We will revisit this important question after developing the frequentist perspective further in the next section.\n2 The Bayesian perspective is an alternative explanation for the source of uncertainty. Here, the DGP is random. Specifically, the data is treated as fixed once realized, and uncertainty in our conclusions is formalized by placing a probability distribution over the possible DGPs that could have generated the specific instance of the data.The random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets[^2], and (ii) it is the backbone of several statistical theorems and methods.[^3] However, it does not necessarily have to hold. For example, we often work with data where the units are connected via some underlying factor (location, industry, etc.). In such cases, the assumption of independence across individual units is violated. An alternative approach in such cases is to instead assume mutual independence across clusters of units. Another example of a violation to the independence assumption is time-series data, where the individual unit is indexed by time. Here, consecutive observations are usually correlated and independence is instead formulated in terms of stationarity and other concepts outside the scope of this post.\n\n\nExample\nThe discussion so far has purely been conceptual, and so it is useful to consider a concrete example. Before doing so, however, let’s clarify some notation used in the random sampling framework. We denote the population-level random variables as \\(X_1, \\ldots, X_K\\). The data generating process \\(F\\) is the joint distribution of these random variables. For example, \\(X_1\\) could denote the generic random variable for wage in the entire US population and we are interested in making inferences about its distribution. We denote the sample-level random variables as \\(X_{i1}, \\ldots, X_{iK}\\). These represent the random variables associated with specific units in the sample. Continuing the example, \\(X_{i1}\\) denotes the random variable representing the wage of individual \\(i\\) in the sample. Finally, we denote the realized observations as \\(X_{i1}=x_{i1}, \\ldots, X_{iK}=x_{iK}\\). These are the actual values we observe. So, \\(X_{i1} = 25,000\\) means that the observed wage of individual \\(i\\) is \\(25,000\\).\nNow suppose our data generating process consists of one random variable with an exponential distribution with scale parameter \\(\\beta = 1\\): \\[\nX \\sim \\text{Exp}(1) \\quad \\text{with density } f(x) = e^{-x} \\text{ for } x \\geq 0.\n\\]\nIf we assume our dataset is a random sample of size 30 from the above DGP, then \\[\nX_{i} \\sim \\text{Exp}(1) \\, \\, \\text{ for } i = 1, \\ldots, 30 \\quad  \\text{and} \\quad  X_i \\perp X_j  \\, \\, \\text{ for } i \\neq j.\n\\]\nThe figure below plots the empirical kernel density of such a random sample (black line) and the true density of the exponential distribution (red line). In practice, we do not know the true DGP and need to guess its characteristics using the observed data. Randomness in the finite observed data makes this a non-trivial task — as illustrated by the discrepancy between the empirical and true densities in the figure below.[^4]\n\n\nCode\n# Simulate IID sample of 30 obs from exp(1)\nset.seed(123)\nn &lt;- 30\nx &lt;- rexp(n, rate = 1)\n\n# Empirical Density \ndens &lt;- density(x)\n\n# True Exponential Density\nxs &lt;- seq(0, max(x), length.out = 200)\nys &lt;- dexp(xs, rate = 1)\n\n# Plot\nplot(dens, main = \"\", xlab = \"Observed Data\", ylab = \"Density\", xlim = c(0, 5), ylim = c(0, max(c(dens$y, ys))))\ncurve(dexp(x, rate = 1), from = min(x), add = TRUE, col = \"red\", lwd = 2)"
  },
  {
    "objectID": "blog/statistical-inference-1.html#evaluating-the-frequentist-mental-model",
    "href": "blog/statistical-inference-1.html#evaluating-the-frequentist-mental-model",
    "title": "Statistical Inference I: Random Sampling",
    "section": "Evaluating the Frequentist Mental Model",
    "text": "Evaluating the Frequentist Mental Model\nThe random sampling assumption is one potential way to characterize the dependence structure across the observed data points. It is popular because (i) it is often reasonable when working with cross-sectional datasets[^2], and (ii) it is the backbone of several statistical theorems and methods.[^3] However, it does not necessarily have to hold. For example, we often work with data where the units are connected via some underlying factor (location, industry, etc.). In such cases, the assumption of independence across individual units is violated. An alternative approach in such cases is to instead assume mutual independence across clusters of units. Another example of a violation to the independence assumption is time-series data, where the individual unit is indexed by time. Here, consecutive observations are usually correlated and independence is instead formulated in terms of stationarity and other concepts outside the scope of this post.\n\nExample\nThe discussion so far has purely been conceptual, and so it is useful to consider a concrete example. Before doing so, however, let’s clarify some notation used in the random sampling framework. We denote the population-level random variables as \\(X_1, \\ldots, X_K\\). The data generating process \\(F\\) is the joint distribution of these random variables. For example, \\(X_1\\) could denote the generic random variable for wage in the entire US population and we are interested in making inferences about its distribution. We denote the sample-level random variables as \\(X_{i1}, \\ldots, X_{iK}\\). These represent the random variables associated with specific units in the sample. Continuing the example, \\(X_{i1}\\) denotes the random variable representing the wage of individual \\(i\\) in the sample. Finally, we denote the realized observations as \\(X_{i1}=x_{i1}, \\ldots, X_{iK}=x_{iK}\\). These are the actual values we observe. So, \\(X_{i1} = 25,000\\) means that the observed wage of individual \\(i\\) is \\(25,000\\).\nNow suppose our data generating process consists of one random variable with an exponential distribution with scale parameter \\(\\beta = 1\\): \\[\nX \\sim \\text{Exp}(1) \\quad \\text{with density } f(x) = e^{-x} \\text{ for } x \\geq 0.\n\\]\nIf we assume our dataset is a random sample of size 30 from the above DGP, then \\[\nX_{i} \\sim \\text{Exp}(1) \\, \\, \\text{ for } i = 1, \\ldots, 30 \\quad  \\text{and} \\quad  X_i \\perp X_j  \\, \\, \\text{ for } i \\neq j.\n\\]\nThe figure below plots the empirical kernel density of such a random sample (black line) and the true density of the exponential distribution (red line). In practice, we do not know the true DGP and need to guess its characteristics using the observed data. Randomness in the finite observed data makes this a non-trivial task — as illustrated by the discrepancy between the empirical and true densities in the figure below.[^4]\n\n\nCode\n# Simulate IID sample of 30 obs from exp(1)\nset.seed(123)\nn &lt;- 30\nx &lt;- rexp(n, rate = 1)\n\n# Empirical Density \ndens &lt;- density(x)\n\n# True Exponential Density\nxs &lt;- seq(0, max(x), length.out = 200)\nys &lt;- dexp(xs, rate = 1)\n\n# Plot\nplot(dens, main = \"\", xlab = \"Observed Data\", ylab = \"Density\", xlim = c(0, 5), ylim = c(0, max(c(dens$y, ys))))\ncurve(dexp(x, rate = 1), from = min(x), add = TRUE, col = \"red\", lwd = 2)"
  },
  {
    "objectID": "blog/statistical-inference-1.html#random-sampling-and-the-frequentist-thought-experiment",
    "href": "blog/statistical-inference-1.html#random-sampling-and-the-frequentist-thought-experiment",
    "title": "Statistical Inference I: Random Sampling",
    "section": "Random Sampling and the Frequentist Thought Experiment",
    "text": "Random Sampling and the Frequentist Thought Experiment\nTo this end, let’s start by positing that there exists some fixed probability distribution \\(F\\) — called the data generating process (DGP) — that produces the data we observe and represents the quantity (the underlying truth) we seek to make statements about. Within this mathematical abstraction, we view observed data as a realization of random variables\nTo this end, let’s start by positing that there exists some probability distribution \\(F\\) — called the data generating process (DGP) — that produces the data we observe and represents the quantity (the underlying truth) we seek to make statements about. Observed data is then viewed as a realized sample from \\(F\\).1 This mathematical abstraction will allow us to use the tools of probability theory to reason about the uncertainty in our conclusions.\n1 A sample from \\(F\\) is a collection of random variables with the distribution \\(F\\).\nAlternative Assumptions to Random Sampling\n\n\nSimulated Example"
  },
  {
    "objectID": "blog/statistical-inference-1.html#reasoning-about-uncertainty",
    "href": "blog/statistical-inference-1.html#reasoning-about-uncertainty",
    "title": "Statistical Inference I: Random Sampling",
    "section": "Reasoning About Uncertainty",
    "text": "Reasoning About Uncertainty\nUncertainty is inherent in any general conclusion we make from data because we only observe a finite manifestation of a much larger, unobserved process. For example, consider the March 2009 Current Population Survey (CPS) dataset, which surveyed 50,742 individuals in the US and recorded their demographic and labor market characteristics.1\n1 To put this number into perspective, the population of the US was 306.8 million in 2009.\n\nCode\ncps &lt;- read_excel(\n  here(\"hasen-econometrics-datasets\", \"cps09mar\", \"cps09mar.xlsx\"), \n  col_names = TRUE\n)\n\nhead(cps)\n\n\n# A tibble: 6 × 12\n    age female  hisp education earnings hours  week union uncov region  race\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1    52      0     0        12   146000    45    52     0     0      1     1\n2    38      0     0        18    50000    45    52     0     0      1     1\n3    38      0     0        14    32000    40    51     0     0      1     1\n4    41      1     0        13    47000    40    52     0     0      1     1\n5    42      0     0        13   161525    50    52     1     0      1     1\n6    66      1     0        13    33000    40    52     0     0      1     1\n# ℹ 1 more variable: marital &lt;dbl&gt;\n\n\n\nround(mean(cps$earnings))\n\n[1] 55092\n\n\nThe average earnings of individuals in this dataset is $55,092. However, we recognize that the specific average we find depends on the households we happen to observe in the dataset. We can easily imagine that if we had surveyed a different set of households, we would have obtained a different average. Thus, it is intuitively clear that there is uncertainty in how representative this number is of the average earnings of all individuals in the US.\nStatistical inference involves quantifying the uncertainty in the (generalized) conclusions we make from observed data. Doing so requires us to formalize the source of this uncertainty, which we achieve by combining mathematical abstraction and thought experiments."
  },
  {
    "objectID": "blog/statistical-inference-1.html#alternative-thought-experiments",
    "href": "blog/statistical-inference-1.html#alternative-thought-experiments",
    "title": "Statistical Inference I: Random Sampling",
    "section": "Alternative Thought Experiments",
    "text": "Alternative Thought Experiments\nIt should be noted that the frequentist perspective is a mental model that helps us reason about uncertainty. Therefore, we must still consider whether it is a reasonable description of how uncertainty arises in our conclusions from observational data. An alternative explanation for the source of uncertainty is the Bayesian perspective. Here, we do not assume that the DGP is a fixed distribution as in the frequentist perspective. Instead, the data is treated as fixed once realized, and uncertainty in our conclusions is formalized by placing a probability distribution over the possible DGPs that could have generated the specific instance of the data."
  },
  {
    "objectID": "blog/statistical-inference-2.html#motivating-example",
    "href": "blog/statistical-inference-2.html#motivating-example",
    "title": "Statistical Inference II: Point Estimation",
    "section": "",
    "text": "suppose our data generating process consists of one random variable with an exponential distribution with scale parameter \\(\\beta = 1\\): \\[\nX \\sim \\text{Exp}(1) \\quad \\text{with density } f(x) = e^{-x} \\text{ for } x \\geq 0.\n\\]\nIf we assume our dataset is a random sample of size 30 from the above DGP, then \\[\nX_{i} \\sim \\text{Exp}(1) \\, \\, \\text{ for } i = 1, \\ldots, 30 \\quad  \\text{and} \\quad  X_i \\perp X_j  \\, \\, \\text{ for } i \\neq j.\n\\]\nThe figure below plots the empirical kernel density of such a random sample (black line) and the true density of the exponential distribution (red line). In practice, we do not know the true DGP and need to guess its characteristics using the observed data. Randomness in the finite observed data makes this a non-trivial task — as illustrated by the discrepancy between the empirical and true densities in the figure below.1\n\n\nCode\n# Simulate IID sample of 30 obs from exp(1)\nset.seed(123)\nn &lt;- 30\nx &lt;- rexp(n, rate = 1)\n\n# Empirical Density \ndens &lt;- density(x)\n\n# True Exponential Density\nxs &lt;- seq(0, max(x), length.out = 200)\nys &lt;- dexp(xs, rate = 1)\n\n# Plot\nplot(dens, main = \"\", xlab = \"Observed Data\", ylab = \"Density\", xlim = c(0, 5), ylim = c(0, max(c(dens$y, ys))))\ncurve(dexp(x, rate = 1), from = min(x), add = TRUE, col = \"red\", lwd = 2)"
  },
  {
    "objectID": "blog/statistical-inference-2.html#introduction",
    "href": "blog/statistical-inference-2.html#introduction",
    "title": "Statistical Inference II: Point Estimation",
    "section": "",
    "text": "This is the second post in a three-part series on statistical inference. Previously, I introduced the general framework of frequentist statistical inference under the random sampling assumption. Here, we view the observed data \\(\\{\\boldsymbol x_i\\}_{i=1}^n\\) as a realization of the random vectors \\(\\{\\boldsymbol X_i\\}_{i=1}^n\\) independently drawn from an an unknown, common distribution \\(F\\).1 The goal of frequentist statistical inference is to use this abstraction to make conclusions about \\(F\\) based on the observed data and quantify the uncertainty in those statements. Specifically, the frequentist thought experiment reasons about uncertainty by asking how frequently we would see the observed data if we repeatedly sampled from the data generating process \\(F\\).\n1 Recall that \\(\\boldsymbol x_i = (x_{i1}, \\ldots, x_{iK})'\\) and \\(\\boldsymbol X_i = (X_{i1}, \\ldots, X_{iK})\\).We have not yet discussed the type of conclusions we make about \\(F\\) in statistical inference. In this post, I focus on point estimation, which is a form of statistical inference that involves constructing a “good guess” of a feature of \\(F\\)."
  },
  {
    "objectID": "blog/statistical-inference-2.html#notation",
    "href": "blog/statistical-inference-2.html#notation",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Notation",
    "text": "Notation\nWhile I previously introduced the random sampling framework using the general notation of vector valued quantities \\(\\boldsymbol X_i, \\boldsymbol x_i \\in \\mathbb{R}^K\\), it is simpler to discuss statistical inference on scalars. Thus, in this post, I focus on the case where \\(K=1\\) and so the data generating process \\(F\\) is a univariate distribution. In this case, a random sample of size \\(n\\) from \\(F\\) is a collection of random variables \\(X_1, \\ldots, X_n\\), and the realizations are the scalars \\(x_1, \\ldots, x_n\\)."
  },
  {
    "objectID": "blog/statistical-inference-2.html#estimand-estimator-and-estimate",
    "href": "blog/statistical-inference-2.html#estimand-estimator-and-estimate",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Estimand, Estimator, and Estimate",
    "text": "Estimand, Estimator, and Estimate\nThe feature of the DGP \\(F\\) that we want to learn about is called an estimand \\(\\theta\\) and is more precisely defined as a function of \\(F\\):\n\\[\n\\theta = \\theta(F).\n\\]\nAn example of an estimand is the the population mean of a random variable \\(X\\): \\[\n\\mu = \\mathbb{E}[X] = \\int x \\, dF(x).\n\\]\nSince the DGP is unknown, the best we can do is use the observed data to guess the value of the estimand. An estimator \\(\\hat \\theta\\) is a function of the sample that is intended to provide a guess of the estimand:\n\\[\n\\hat{\\theta} = \\hat{\\theta}(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n).\n\\]\nWhen the estimator is evaluated at a specific realization of the sample, we obtain an estimate \\(\\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n)\\) of the estimand. It’s worth emphasizing that the estimand is a fixed but unknown number, the estimator is a random variable, and the estimate is a fixed and known number.\nIn statistics, there are several estimation principles that provide systematic ways (i.e. rules) to construct estimators. One common method is the analog principle (or plug-in principle). The idea is to construct the estimator by replacing the population quantities in the estimand with their sample analogs.3 Thus, the analog estimator for the population mean is the sample mean, defined as\n3 To quote my Mathematical Statistics Professor Daniel Weiner: “Do to the sample to get your estimator, as you would do to your population to get your estimand.”\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol X_i.\n\\]\n\nEstimator Properties\nHow do we know if an estimator is any good? To answer this question, statisticians study desirable properties that an estimator should ideally satisfy. A full treatment of estimator properties is typically the focus of a mathematical statistics course, but it is still valuable to briefly highlight some fundamental properties here.\nThe error of an estimator is defined as the difference between the estimate and the estimand:\n\\[\ne(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) = \\hat\\theta(\\boldsymbol x_1, \\ldots, \\boldsymbol x_n) - \\theta.\n\\] The bias of an estimator is the average error of the estimator across all possible samples of size \\(n\\) from the DGP:\n\\[\nB(\\hat\\theta) = \\mathbb{E}_F[\\hat{\\theta}] - \\theta\n\\] Intuitively, the bias captures the systematic error of the estimator: if the bias is positive, the estimator tends to overestimate the estimand, and if the bias is negative, the estimator tends to underestimate the estimand. We say an estimator \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\) if its bias is zero:4\n4 To be more precise, \\(\\hat\\theta\\) is unbiased for \\(\\theta\\) if \\(\\mathbb{E}[\\hat\\theta]=\\theta\\) for all \\(F \\in \\mathcal{F}\\), where \\(\\mathcal{F}\\) is a class of distributions.\\[\n\\mathbb{E}_F[\\hat{\\theta}] - \\theta = 0.\n\\] Thus, the errors of an unbiased estimator are purely due to randomness in the data. As it turns out, the sample mean is an unbiased estimator of the population mean under the random sampling assumption:\n\\[\n\\mathbb{E}_F[\\hat{\\mu}] = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}_F[\\boldsymbol X_i] = \\frac{1}{n} \\sum_{i=1}^n \\mu = \\mu.\n\\] The first equality follows from the linearity of expectations, the second equality follows from the random sampling assumption, and the third equality is a simplification.\nWhile bias quantifies how far the estimator’s average is from the estimand, the variance (or sampling variance) measures how much the estimator varies across repeated samples of size \\(n\\):\n\\[\nVar(\\hat\\theta) = \\mathbb{E}_F[(\\hat\\theta - \\mathbb{E}_F[\\hat\\theta])^2].\n\\] The variance of the sample mean under the random sampling assumption is given by\n\\[\n\\operatorname {Var} \\left[\\hat\\mu\\right] = \\frac{1}{n^2}\\operatorname{Var} \\left[ \\sum_{i=1}^n \\boldsymbol X_i\\right] = \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}[\\boldsymbol X_i] = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\frac{\\sigma^2}{n},\n\\] where \\(\\sigma^2\\) is the population variance \\(\\operatorname{Var}[X]\\). The first equality uses the properties of variance. The second equality follows from the fact that the independence of each \\(\\boldsymbol X_i\\) means they are uncorrelated, and so the variance of their sum equals the sum of their variance. The third equality uses the fact that each \\(\\boldsymbol X_i\\) are drawn from an identical distribution and so have the same variance \\(\\sigma^2\\). The fourth equality is an algebraic simplification."
  },
  {
    "objectID": "blog/statistical-inference-2.html#plug-in-principle",
    "href": "blog/statistical-inference-2.html#plug-in-principle",
    "title": "Statistical Inference II: Point Estimation",
    "section": "Plug-In Principle",
    "text": "Plug-In Principle\nPerhaps it is already obvious, but let’s consider a simulated example to see why point estimation is difficult. Suppose we have a random sample of size 30 from a DGP that is the single-variable exponential distribution with rate parameter \\(\\alpha= 1\\): \\[\nX_{i} \\sim \\text{Exp}(1) \\, \\, \\text{ for } i = 1, \\ldots, 30 \\quad  \\text{and} \\quad  X_i \\perp X_j  \\, \\, \\text{ for } i \\neq j.\n\\]\nThe figure below plots the empirical kernel density of the realizations of this random sample (black line) and the true density of the exponential distribution (red line). In practice, we do not know the true DGP and need to guess its characteristics using the observed data. However, uncertainty induced by the sampling process makes this a non-trivial task — as illustrated by the discrepancy between the empirical and true densities in the figure below.\n\n\nCode\n# Simulate IID sample of 30 obs from exp(1)\nset.seed(123)\nn &lt;- 30\nx &lt;- rexp(n, rate = 1)\n\n# Empirical Density \ndens &lt;- density(x)\n\n# True Exponential Density\nxs &lt;- seq(0, max(x), length.out = 200)\nys &lt;- dexp(xs, rate = 1)\n\n# Plot\nplot(dens, main = \"\", xlab = \"Observed Data\", ylab = \"Density\", xlim = c(0, 5), ylim = c(0, max(c(dens$y, ys))))\ncurve(dexp(x, rate = 1), from = min(x), add = TRUE, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n\nStatisticians have addressed the challenge of point estimation by developing several estimation principles that provide systematic ways (i.e. rules) to construct estimators. One common method is the plug-in principle (or analog principle). The idea is to construct the estimator by replacing the population quantities in the estimand with their sample analogs.4 Thus, the plug-in estimator for the population mean is the sample mean\n4 To quote my Mathematical Statistics Professor, “Do to the sample to get your estimator, as you would do to your population to get your estimand.”\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\] Similarly, the plug-in estimator of the population variance \\(\\sigma^2\\) is the sample variance \\[\n\\hat \\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n X_i^2 - \\left(\\frac{1}{n}\\sum X_i\\right)^2 =\\frac{1}{n} \\sum_{i=1}^n \\left(X_i - \\bar{X}\\right)^2.\n\\]\n\nEstimator Properties\nHow do we know if an estimator is any good? Frequentists evaluate estimators based on their theoretical properties in (hypothetical) repeated samples. A full treatment of estimator properties is typically the focus of a mathematical statistics course, but it is still valuable to briefly highlight some fundamental properties here.\nThe error of an estimator is defined as the difference between the estimate and the estimand: \\[\ne(x_1, \\ldots, x_n) = \\hat\\theta(x_1, \\ldots, x_n) - \\theta.\n\\] The bias of an estimator is the average error of the estimator across repeated samples of size \\(n\\) from the DGP5: \\[\nB(\\hat\\theta) = \\mathbb{E}[\\hat{\\theta}(X_1, \\ldots,X_n)] - \\theta.\n\\] Intuitively, the bias captures the systematic error of the estimator: if the bias is positive, the estimator tends to overestimate the estimand, and if the bias is negative, the estimator tends to underestimate the estimand. We say an estimator \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\) if its bias is zero:\n5 An alternate, but equivalent, formulation is that the bias is the average error across all possible samples of size \\(n\\).\\[\n\\mathbb{E}[\\hat{\\theta}] - \\theta = 0.\n\\] Thus, the errors of an unbiased estimator are purely due to the uncertainty induced by sampling a finite number of draws from \\(F\\). As it turns out, the sample mean is an unbiased estimator of the population mean under the random sampling assumption: \\[\n\\mathbb{E}[\\bar X] = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}[X_i] = \\frac{1}{n} \\sum_{i=1}^n \\mu = \\mu.\n\\tag{1}\\] The first equality follows from the linearity of expectations, the second equality follows from the random sampling assumption, and the third equality is a simplification.\nWhile bias quantifies how far the estimator’s average is from the estimand, the variance (or sampling variance) measures how much the estimator varies across repeated samples of size \\(n\\):\n\\[\nVar(\\hat\\theta) = \\mathbb{E}_F[(\\hat\\theta - \\mathbb{E}_F[\\hat\\theta])^2].\n\\] The variance of the sample mean under the random sampling assumption is given by\n\\[\n\\operatorname {Var} \\left[\\hat\\mu\\right] = \\frac{1}{n^2}\\operatorname{Var} \\left[ \\sum_{i=1}^n \\boldsymbol X_i\\right] = \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}[\\boldsymbol X_i] = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\frac{\\sigma^2}{n},\n\\tag{2}\\] where \\(\\sigma^2\\) is the population variance \\(\\operatorname{Var}[X]\\). The first equality uses the properties of variance. The second equality follows from the fact that the independence of each \\(\\boldsymbol X_i\\) means they are uncorrelated, and so the variance of their sum equals the sum of their variance. The third equality uses the fact that each \\(\\boldsymbol X_i\\) are drawn from an identical distribution and so have the same variance \\(\\sigma^2\\). The fourth equality is an algebraic simplification.\nLet’s confirm Equation 1 and Equation 2 in the motivating example introduced previously. The population mean and variance of an exponential distribution with \\(\\alpha = 1\\) both equal \\(1\\). Thus, we expect the sample mean to have a mean of \\(1\\) and a variance of \\(1/30 \\approx 0.0333\\). The code below simulates drawing a random sample of size \\(n=30\\) from \\(Exp(1)\\) \\(10,000\\) times and computes the average and variance of the sample means in each sample:\n\nset.seed(123)\n\n# Simulation parameters\nn        &lt;- 30               # sample size\nn_sims   &lt;- 10000            # number of repeated draws \n\n# Store sample means for the 10000 repeated samples\nsample_means &lt;- replicate(\n  n_sims,\n  mean(rexp(n, rate = 1))\n)\n\n# Average and variance of sample means\nc(mean(sample_means), var(sample_means))\n\n[1] 0.99712085 0.03284092"
  },
  {
    "objectID": "blog/summary-index.html",
    "href": "blog/summary-index.html",
    "title": "Summary Index",
    "section": "",
    "text": "This post is in progress"
  },
  {
    "objectID": "blog/summary-index.html#notation",
    "href": "blog/summary-index.html#notation",
    "title": "Summary Index",
    "section": "Notation",
    "text": "Notation\nLet \\(i = 1, \\ldots, n\\) index the observations, \\(j = 1, \\ldots, J\\) index the domains, and \\(k = 1, \\ldots, K_j\\) index the outcomes within domain \\(j\\). We standardize each outcome value \\(y_{ijk}\\) into effect-size units as \\[\n\\tilde{y}_{ijk} \\equiv \\frac{y_{ijk} - \\bar{y}_{jk}^{control}}{\\sigma_{jk}^{control}},\n\\tag{1}\\] where \\(\\bar{y}_{jk}^{control}\\) is the sample mean of outcome \\(k\\) in domain \\(j\\) among untreated individuals, and \\(\\sigma_{jk}^{control}\\) is the corresponding sample standard deviation. In words, Equation 1 represents the value of outcome \\(k\\) for individual \\(i\\) in domain \\(j\\) in terms of the number of control-group standard deviations that \\(y_{ijk}\\) is above or below the control-group mean for that outcome. Since \\(y_{ijk}\\) is positively oriented, \\(\\tilde{y}_{ijk} &gt; 0\\) indicates a positive treatment effect on outcome \\(k\\) for individual \\(i\\) in domain \\(j\\), while \\(\\tilde{y}_{ijk} &lt; 0\\) indicates a negative treatment effect.\nWe denote the vector of standardized outcome for individual \\(i\\) in domain \\(j\\) as \\[\n\\tilde{\\boldsymbol y}_{ij} \\equiv \\begin{pmatrix}\\tilde{y}_{ij1} \\\\ \\vdots\\\\ \\tilde{y}_{ijK_j} \\end{pmatrix} \\in \\mathbb{R}^{K_j}.\n\\] The covariance matrix of the standardized outcomes in domain \\(j\\) \\[\n\\boldsymbol \\Sigma_j \\equiv \\begin{pmatrix}\n\\Sigma_{j11} & \\ldots & \\Sigma_{j1K_j}\n\\\\\n\\vdots & \\ddots & \\vdots\n\\\\\n\\Sigma_{jK_j1} & \\ldots & \\Sigma_{jK_jK_j}\n\\end{pmatrix} \\in \\mathbb{R}^{K_j \\times K_j}\n\\] captures the unconditional covariance structure between the outcomes in domain \\(j\\) across individuals in the control-group. Specifically, the diagonal elements \\(\\Sigma_{jkk}\\) measure the unconditional variance of outcome \\(k\\) in domain \\(j\\) \\[\n\\Sigma_{jkk} \\equiv \\operatorname{Var}(\\tilde{y}_{ijk}),\n\\] and the off-diagonal elements \\(\\Sigma_{jkk'}\\) measure the unconditional covariance between outcomes \\(k\\) and \\(k'\\) in domain \\(j\\) \\[\n\\Sigma_{jkk} \\equiv \\operatorname{Cov}(\\tilde{y}_{ijk}, \\tilde{y}_{ijk'}).\n\\] The inverse of the covariance matrix is denoted as \\[\n\\boldsymbol \\Sigma_j^{-1} \\equiv \\boldsymbol \\Omega_j = \\begin{pmatrix} \\Omega_{j11} & \\ldots & \\Omega_{j1K_j} \\\\\n\\vdots & \\ddots & \\vdots \\\\ \\Omega_{jK_j1} & \\ldots & \\Omega_{jK_jK_j} \\end{pmatrix} \\in \\mathbb{R}^{K_j \\times K_j},\n\\] and is called the precision matrix. This matrix plays a key role in aggregating outcomes within the same domain because it captures the conditional dependence structure between the outcomes in domain \\(j\\).1 The diagonal elements \\(\\Omega_{jkk}\\) equal the inverse of the conditional variance of outcome \\(k\\) given all other outcomes in domain \\(j\\): \\[\n\\Omega_{jkk} = \\frac{1}{\\operatorname{Var}(\\tilde{y}_{ijk} \\mid \\tilde{\\boldsymbol y}_{ij-k})}.\n\\] In other words, \\(\\Omega_{jkk}\\) measures how noisy an outcome is conditioned on the other outcomes, with larger values indicating less noise.2 The off-diagonal elements \\(\\Omega_{jkk'}\\) equal the negative conditional covariance between outcomes \\(k\\) and \\(k'\\), scaled by the product of their inverse conditional variances: \\[\n\\Omega_{jkk'} = \\frac{-\\operatorname{Cov}(\\tilde{y}_{ijk}, \\tilde{y}_{ijk'} \\mid \\tilde{\\boldsymbol y}_{ij-\\{k,k'\\}})}{\\operatorname{Var}(\\tilde{y}_{ijk} \\mid \\tilde{\\boldsymbol y}_{ij-k}) \\operatorname{Var}(\\tilde{y}_{ijk'} \\mid \\tilde{\\boldsymbol y}_{ij-k'})}.\n\\] Recall that conditional covariance is the covariance between the residuals of the regression of \\(y_{ijk}\\) and \\(y_{ijk'}\\) on all other outcomes in domain \\(j\\). Thus, \\(\\Omega_{jkk'}\\) measures how much overlapping information exists between outcomes \\(k\\) and \\(k'\\) after controlling for the other outcomes in domain \\(j\\), with larger magnitudes indicating more redundancy. Intuitively, the scaling factor discounts the measured redundancy is discounted when the outcomes are noisy, since the shared information is potentially unreliable.\n1 To show how \\(\\boldsymbol \\Omega_j\\) represents the conditional relationships involves deriving it from \\(\\boldsymbol \\Sigma_j\\) using the Schur complement. Relevant references include this, this, and this.2 Perhaps it is obvious, but it is worth emphasizing that the diagonal elements are always non-negative because variances are non-negative."
  },
  {
    "objectID": "blog/summary-index.html#summary-index",
    "href": "blog/summary-index.html#summary-index",
    "title": "Summary Index",
    "section": "Summary Index",
    "text": "Summary Index\nFor every individual \\(i\\), we want to combine the multiple outcomes \\(k = 1, \\ldots, K_j\\) in domain \\(j\\) into a single domain-level summary index \\(\\bar{s}_{ij}\\). Anderson (2008) proposes the following index:\n\\[\n\\bar{s}_{ij} \\equiv\n\\underbrace{\\color{#FF7F0E}{(\\boldsymbol 1' \\boldsymbol \\Sigma _j^{-1} \\boldsymbol 1)^{-1}}}_{\\color{#FF7F0E}{\\text{normalizing scalar}}}\n\\;\n\\underbrace{\\color{#2CA02C}{(\\boldsymbol 1' \\boldsymbol \\Sigma _j^{-1})}}_{\\color{#2CA02C}{\\text{raw weights}}}\n\\;\n\\underbrace{\\color{#1F77B4}{(\\tilde{\\boldsymbol y}_{ij})}}_{\\color{#1F77B4}{\\text{outcome}}}.\n\\]\nwhere \\(\\boldsymbol 1 \\in \\mathbb{R}^{K_j \\times 1}\\) is a vector of ones. To understand how the summary index aggregates outcomes in the same domain, it’s useful to interpret each component of the index separately.\nFirst, the matrix multiplication \\(\\color{#2CA02C}{\\boldsymbol 1 ' \\boldsymbol \\Sigma_j^{-1}}\\) results in the following \\(1 \\times K_j\\) vector\n\\[\n\\boldsymbol w_j \\equiv \\begin{pmatrix} 1 & \\ldots & 1 \\end{pmatrix} \\begin{pmatrix} \\Omega_{j11} & \\ldots & \\Omega_{j1K_j} \\\\\n\\vdots & \\ddots & \\vdots \\\\ \\Omega_{jK_j1} & \\ldots & \\Omega_{jK_jK_j} \\end{pmatrix} = \\begin{pmatrix} w_{j1} = \\sum_{k=1}^{K_j} \\Omega_{jk1} \\\\ \\vdots \\\\ w_{jK_j}=\\sum_{k=1}^{K_j} \\Omega_{jkK_j} \\end{pmatrix}' \\in \\mathbb{R}^{1 \\times K_j}.\n\\]\nIn other words, each element \\(w_{jk}\\) is simply the sum of the corresponding \\(k\\)-th column of \\(\\boldsymbol \\Omega_j\\). To be able to interpret these elements, suppose the conditional covariance between arbitrary outcomes \\(k\\) and \\(k'\\) in domain \\(j\\) is strictly non-negative so that \\(\\Omega_{jkk'}\\) is strictly non-positive.3 This is often a reasonable assumption since we positively oriented the outcomes and group them by some shared domain. Under this assumption, the positive diagonal elements \\(\\Omega_{jkk}\\) decrease as conditional variance (noise) increases and the negative off-diagonal elements \\(\\Omega_{jkk'}\\) become more negative as conditional covariance (redundancy) increases. Thus, the sum \\(w_{jk}\\) can be interpreted as a weight that captures the conditional noise and overall redundancy in outcome \\(k\\), with higher weights assigned to outcomes that are less noisy and redundant.\n3 I believe this is what Anderson (2008) was referring to when they state “Summary index tests make sense … when there is an a priori reason to believe that a group of outcomes will be affected in a consistent direction” (p. 1488).The matrix multiplication \\(\\color{green}{(\\boldsymbol 1 ' \\boldsymbol \\Sigma_j^{-1})}\\color{#1F77B4}{(\\tilde{\\boldsymbol y}_{ij})}\\) results in a scalar that is a weighted sum of all the outcomes in domain \\(j\\) for individual \\(i\\): \\[\ns_{ij} \\equiv \\begin{pmatrix} w_{j1} & w_{jK_J} \\end{pmatrix} \\begin{pmatrix} \\tilde{y}_{ij1} \\\\ \\vdots \\\\ \\tilde{y}_{ijK_j} \\end{pmatrix} =\\sum_{k=1}^{K_j} w_{jk} \\tilde{y}_{ijk}.\n\\] The quantity \\((\\boldsymbol 1' \\boldsymbol \\Sigma _j^{-1} \\boldsymbol 1)\\) is simply the sum of all the weights in \\(\\boldsymbol w_j\\): \\[\n\\begin{pmatrix} w_{j1} & \\ldots & w_{jK_j}\\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\sum_{k=1}^{K_j} w_{jk}.\n\\] Finally, multiplying the weighted sum \\(\\color{green}{(\\boldsymbol 1 ' \\boldsymbol \\Sigma_j^{-1})}\\color{#1F77B4}{(\\tilde{\\boldsymbol y}_{ij})}\\) by the inverse \\(\\color{#FF7F0E}{(\\boldsymbol 1' \\boldsymbol \\Sigma _j^{-1} \\boldsymbol 1)^{-1}}\\) results in a weighted average of the outcomes in domain \\(j\\) for individual \\(i\\): \\[\n\\bar{s}_{ij} = \\frac{\\sum_{k=1}^{K_j} w_{jk} \\tilde{y}_{ijk}}{\\sum_{k=1}^{K_j} w_{jk}}.\n\\] Thus, the summary index \\(\\bar{s}_{ij}\\) is a weighted average of all the outcomes in domain \\(j\\) for individual \\(i\\), where the weights \\(w_{jk}\\) capture the conditional noise and overall redundancy in outcome \\(k\\). This weighting scheme ensures that outcomes providing stable, unique information about the domain are prioritized in the summary index."
  },
  {
    "objectID": "blog/summary-index.html#introduction",
    "href": "blog/summary-index.html#introduction",
    "title": "Summary Index",
    "section": "",
    "text": "This post is in progress"
  },
  {
    "objectID": "blog/summary-index.html#notation-and-set-up",
    "href": "blog/summary-index.html#notation-and-set-up",
    "title": "Summary Index",
    "section": "Notation and Set Up",
    "text": "Notation and Set Up\nLet \\(i = 1, \\ldots, n\\) index the observations, \\(j = 1, \\ldots, J\\) index the domains, and \\(k = 1, \\ldots, K_j\\) index the outcomes within domain \\(j\\). We standardize each outcome value \\(y_{ijk}\\) into effect-size units as \\[\n\\tilde{y}_{ijk} \\equiv \\frac{y_{ijk} - \\bar{y}_{jk}^{control}}{\\sigma_{jk}^{control}},\n\\tag{1}\\] where \\(\\bar{y}_{jk}^{control}\\) is the sample mean of outcome \\(k\\) in domain \\(j\\) among untreated individuals, and \\(\\sigma_{jk}^{control}\\) is the corresponding sample standard deviation. In words, Equation 1 represents the value of outcome \\(k\\) for individual \\(i\\) in domain \\(j\\) in terms of the number of control-group standard deviations that \\(y_{ijk}\\) is above or below the control-group mean for that outcome. Since \\(y_{ijk}\\) is positively oriented, \\(\\tilde{y}_{ijk} &gt; 0\\) indicates a positive treatment effect on outcome \\(k\\) for individual \\(i\\) in domain \\(j\\), while \\(\\tilde{y}_{ijk} &lt; 0\\) indicates a negative treatment effect.\nWe denote the vector of standardized outcome for individual \\(i\\) in domain \\(j\\) as \\[\n\\tilde{\\boldsymbol y}_{ij} \\equiv \\begin{pmatrix}\\tilde{y}_{ij1} \\\\ \\vdots\\\\ \\tilde{y}_{ijK_j} \\end{pmatrix} \\in \\mathbb{R}^{K_j}.\n\\] The covariance matrix of the standardized outcomes in domain \\(j\\) \\[\n\\boldsymbol \\Sigma_j \\equiv \\begin{pmatrix}\n\\Sigma_{j11} & \\ldots & \\Sigma_{j1K_j}\n\\\\\n\\vdots & \\ddots & \\vdots\n\\\\\n\\Sigma_{jK_j1} & \\ldots & \\Sigma_{jK_jK_j}\n\\end{pmatrix} \\in \\mathbb{R}^{K_j \\times K_j}\n\\] captures the unconditional covariance structure between the outcomes in domain \\(j\\) across individuals in the control-group. Specifically, the diagonal elements \\(\\Sigma_{jkk}\\) measure the unconditional variance of outcome \\(k\\) in domain \\(j\\) \\[\n\\Sigma_{jkk} \\equiv \\operatorname{Var}(\\tilde{y}_{ijk}),\n\\] and the off-diagonal elements \\(\\Sigma_{jkk'}\\) measure the unconditional covariance between outcomes \\(k\\) and \\(k'\\) in domain \\(j\\) \\[\n\\Sigma_{jkk'} \\equiv \\operatorname{Cov}(\\tilde{y}_{ijk}, \\tilde{y}_{ijk'}).\n\\]\nThe inverse of the covariance matrix is denoted as \\[\n\\boldsymbol \\Omega_j \\equiv \\boldsymbol \\Sigma_j^{-1} = \\begin{pmatrix} \\Omega_{j11} & \\ldots & \\Omega_{j1K_j} \\\\\n\\vdots & \\ddots & \\vdots \\\\ \\Omega_{jK_j1} & \\ldots & \\Omega_{jK_jK_j} \\end{pmatrix} \\in \\mathbb{R}^{K_j \\times K_j},\n\\] and is called the precision matrix. This matrix plays a key role in aggregating outcomes within the same domain because it captures the conditional dependence structure between the outcomes in domain \\(j\\).1 The diagonal elements \\(\\Omega_{jkk}\\) equal the inverse of the conditional variance of outcome \\(k\\) given all other outcomes in domain \\(j\\): \\[\n\\Omega_{jkk} = \\frac{1}{\\operatorname{Var}(\\tilde{y}_{ijk} \\mid \\tilde{\\boldsymbol y}_{ij-k})}.\n\\] In other words, \\(\\Omega_{jkk}\\) measures how noisy an outcome is conditioned on the other outcomes, with larger values indicating less noise.2 The off-diagonal elements \\(\\Omega_{jkk'}\\) equal the negative conditional covariance between outcomes \\(k\\) and \\(k'\\), scaled by the product of their inverse conditional variances: \\[\n\\Omega_{jkk'} = \\frac{-\\operatorname{Cov}(\\tilde{y}_{ijk}, \\tilde{y}_{ijk'} \\mid \\tilde{\\boldsymbol y}_{ij-\\{k,k'\\}})}{\\operatorname{Var}(\\tilde{y}_{ijk} \\mid \\tilde{\\boldsymbol y}_{ij-k}) \\operatorname{Var}(\\tilde{y}_{ijk'} \\mid \\tilde{\\boldsymbol y}_{ij-k'})}.\n\\] Recall that conditional covariance is the covariance between the residuals of the regression of \\(y_{ijk}\\) and \\(y_{ijk'}\\) on all other outcomes in domain \\(j\\). Thus, \\(\\Omega_{jkk'}\\) measures how much overlapping information exists between outcomes \\(k\\) and \\(k'\\) after controlling for the other outcomes in domain \\(j\\), with larger magnitudes indicating more redundancy. Intuitively, the scaling factor discounts the measured redundancy when the outcomes are noisy, since the shared information is potentially unreliable.\n1 To show how \\(\\boldsymbol \\Omega_j\\) represents the conditional relationships involves deriving it from \\(\\boldsymbol \\Sigma_j\\) using the Schur complement. Relevant references include this, this, and this.2 Perhaps it is obvious, but it is worth emphasizing that the diagonal elements are always non-negative because variances are non-negative."
  },
  {
    "objectID": "blog/summary-index.html#footnotes",
    "href": "blog/summary-index.html#footnotes",
    "title": "Summary Index",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo show how \\(\\boldsymbol \\Omega_j\\) represents the conditional relationships involves deriving it from \\(\\boldsymbol \\Sigma_j\\) using the Schur complement. Relevant references include this, this, and this.↩︎\nPerhaps it is obvious, but it is worth emphasizing that the diagonal elements are always non-negative because variances are non-negative.↩︎\nI believe this is what Anderson (2008) was referring to when they state “Summary index tests make sense … when there is an a priori reason to believe that a group of outcomes will be affected in a consistent direction” (p. 1488).↩︎"
  },
  {
    "objectID": "blog/lin-reg-model.html",
    "href": "blog/lin-reg-model.html",
    "title": "The Linear Regression Model and its OLS Estimation",
    "section": "",
    "text": "We are interested in datasets of the form \\(\\{y_{i}, x_{i1}, \\ldots, x_{iK}\\}_{i=1}^n\\) where \\(y_{i}\\) is the outcome and \\(x_{i1}, \\ldots, x_{iK}\\) are the regressors. To mathematically formalize how this data was generated, we view the observations as realizations of random variables that are drawn from some joint distribution \\(F\\), also called the data generating process (DGP). The random sampling assumption is one possible characterization of these draws.\n\nAssumption 1. Random Sampling\nThe observations \\(\\{y_i, x_{i1}, \\ldots, x_{iK}\\}^n_{i=1}\\) are realizations of the random variables \\(\\{Y_i, X_{i1}, \\ldots , X_{iK}\\}_{i=1}^n\\), which are independent and identically distributed (i.i.d) draws from the joint distribution \\(F(Y,X_1, \\ldots, X_K)\\).\n\nIt’s easy to get confused about the notation and terminology here, so let’s clarify. The random variables \\(Y, X_1, \\ldots, X_K\\) are theoretical objects that are used when talking about the data generating process in general. The random variables \\(Y_i, X_{i1}, \\ldots, X_{iK}\\) are the theoretical objects that correspond to each observation in the sample. Intuitively, we can think of these as the data before it was collected. The realizations \\(y_i, x_{i1}, \\ldots, x_{iK}\\) are the actual data (numbers) we observe after data collection. This abstraction allows us to use the tools of probability theory and mathematical statistics to infer from our dataset.1"
  },
  {
    "objectID": "blog/lin-reg-model.html#random-sampling-framework",
    "href": "blog/lin-reg-model.html#random-sampling-framework",
    "title": "The Linear Regression Model and its OLS Estimation",
    "section": "",
    "text": "We are interested in datasets of the form \\(\\{y_{i}, x_{i1}, \\ldots, x_{iK}\\}_{i=1}^n\\) where \\(y_{i}\\) is the outcome and \\(x_{i1}, \\ldots, x_{iK}\\) are the regressors. To mathematically formalize how this data was generated, we view the observations as realizations of random variables that are drawn from some joint distribution \\(F\\), also called the data generating process (DGP). The random sampling assumption is one possible characterization of these draws.\n\nAssumption 1. Random Sampling\nThe observations \\(\\{y_i, x_{i1}, \\ldots, x_{iK}\\}^n_{i=1}\\) are realizations of the random variables \\(\\{Y_i, X_{i1}, \\ldots , X_{iK}\\}_{i=1}^n\\), which are independent and identically distributed (i.i.d) draws from the joint distribution \\(F(Y,X_1, \\ldots, X_K)\\).\n\nIt’s easy to get confused about the notation and terminology here, so let’s clarify. The random variables \\(Y, X_1, \\ldots, X_K\\) are theoretical objects that are used when talking about the data generating process in general. The random variables \\(Y_i, X_{i1}, \\ldots, X_{iK}\\) are the theoretical objects that correspond to each observation in the sample. Intuitively, we can think of these as the data before it was collected. The realizations \\(y_i, x_{i1}, \\ldots, x_{iK}\\) are the actual data (numbers) we observe after data collection. This abstraction allows us to use the tools of probability theory and mathematical statistics to infer from our dataset.1"
  },
  {
    "objectID": "blog/lin-reg-model.html#defining-the-linear-regression-model",
    "href": "blog/lin-reg-model.html#defining-the-linear-regression-model",
    "title": "The Linear Regression Model and its OLS Estimation",
    "section": "Defining the Linear Regression Model",
    "text": "Defining the Linear Regression Model\nRecall that a statistical model is simply a set of assumptions about some DGP. In the case of the linear regression model, we are interested in the joint distribution \\(F(Y, X_1, \\ldots, X_K)\\). Under the random sampling assumption, however, each observation \\(Y_i, X_{i1}, \\ldots X_{iK}\\) is an i.i.d draw from \\(F\\). This means that we can just as well frame our assumptions in terms of the random variables \\(\\{Y_i, X_{i1}, \\ldots, X_{iK}\\}_{i=1}^n\\). As we will see, this formulation of the model is useful because it allows us to use matrix algebra to derive the estimator for the parameters.\n\nAssumption 2. The Linear Regression Model\n(A) (Linearity) The outcome \\(Y_i\\) is a linear combination of the regressors \\(X_{i1}, \\ldots, X_{iK}\\), plus some random error \\(e_i\\) that captures measurement error and idiosyncratic fluctuation in \\(Y_i\\): \\[\nY_i = \\beta_1X_{i1} + \\ldots + \\beta_kX_{iK} + e_i \\quad \\forall \\, i = 1, \\ldots, n.\n\\tag{1}\\]\n(B) (No Multicollinearity) None of the regressors are an exact linear combination of each other.\n(C) (Strict Exogeneity) The error \\(e_i\\) has a conditional mean of zero given the regressors of all observations \\[\n\\mathbb{E}[e_i \\mid \\boldsymbol{X}_1 \\ldots , \\boldsymbol{X}_n] = 0 \\quad \\forall \\, i = 1, \\ldots, n\n\\tag{2}\\] where \\(\\boldsymbol{X}_i = (X_{i1}, \\ldots, X_{iK})'\\).\n\nFor notational compactness, it is useful to recast the model in matrix notation. First note that we can stack Equation 1 as a system of \\(n\\) equations\n\\[\n\\begin{aligned}\nY_1 &= \\beta_1 X_{11} + \\ldots + \\beta_k X_{1K} + e_1 = \\boldsymbol{X}_1'\\boldsymbol{\\beta} + e_1\\\\\\\nY_2 &= \\beta_1 X_{21}+ \\ldots + \\beta_k X_{2K} + e_2 = \\boldsymbol{X}_2'\\boldsymbol{\\beta} + e_2 \\\\\n&\\;\\;\\vdots \\\\\nY_n &= \\beta_1X_{n1} + \\ldots + \\beta_k X_{nK} + e_n= \\boldsymbol{X}_n'\\boldsymbol{\\beta} + e_n,\n\\end{aligned}\n\\] where \\[\n\\boldsymbol{X}_i = \\begin{pmatrix} X_{i1} \\\\ \\vdots \\\\ X_{iK} \\end{pmatrix} \\in \\mathbb{R}^{K \\times 1} \\quad  \\text{and} \\quad \\boldsymbol{\\beta}= \\begin{pmatrix} \\beta_1 \\\\ \\vdots \\\\ \\beta_K \\end{pmatrix} \\in \\mathbb{R}^{K \\times 1}.\n\\]\nNow, we can collapse this system of equations into a single matrix equation: \\[\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{e},\n\\tag{3}\\] where \\[\n\\boldsymbol{Y} = \\begin{pmatrix} Y_1 \\\\ \\vdots \\\\ Y_n \\end{pmatrix} \\in \\mathbb{R}^{n \\times 1}, \\quad \\boldsymbol{e} = \\begin{pmatrix} e_1 \\\\ \\vdots \\\\ e_n \\end{pmatrix} \\in \\mathbb{R}^{n \\times 1}, \\quad  \\mathbf{X} = \\begin{pmatrix} \\boldsymbol{X}_1' \\\\ \\vdots \\\\ \\boldsymbol{X}_n' \\end{pmatrix} = \\begin{pmatrix} X_{11} & \\ldots & X_{1K} \\\\ \\vdots & \\ddots & \\vdots \\\\ X_{n1} & \\ldots & X_{nK} \\end{pmatrix} \\in \\mathbb{R}^{n \\times K}.\n\\]\nThe quantity \\(\\mathbf{X}\\) is called the design matrix. 2"
  },
  {
    "objectID": "blog/lin-reg-model.html#interpreting-the-assumptions",
    "href": "blog/lin-reg-model.html#interpreting-the-assumptions",
    "title": "The Linear Regression Model and its OLS Estimation",
    "section": "Interpreting the Assumptions",
    "text": "Interpreting the Assumptions\nIt is good practice to carefully think through what is being assumed in any given model. The linearity assumption in Equation 1 and Equation 3 states that (i) the functional form of the relationship between the outcome and regressors is linear in the parameters, and (ii) the error is additive.\nThe assumption of no multicollinearity ensures that the design matrix \\(\\mathbf{X}\\) has full column rank.3 This in turn means the square matrix \\(\\mathbf{X}'\\mathbf{X}\\) is invertible, which is a crucial property when deriving the ordinary least squares (OLS) estimator for the parameters.\nThe strict exogeneity assumption states that the conditional expectation of the error given the regressors of all observations is zero. This is a crucial assumption of the model, and has several implications:\n\nThe unconditional mean of the error is zero: \\[\n\\mathbb{E}[e_i] \\overset{(a)}{=} \\mathbb{E}[\\mathbb{E}[e_i \\mid \\mathbf{X}]] \\overset{(b)}{=} 0 \\quad \\forall \\, i = 1, \\ldots, n,\n\\tag{4}\\] where \\((a)\\) uses the law of iterated expectations and \\((b)\\) follow from Equation 2. Also, since the conditional mean equals the unconditional mean, the error \\(e_i\\) is mean independent of the regressors \\(\\boldsymbol X_1, \\ldots, \\boldsymbol X_n.\\)\nThe error is orthogonal to the regressors of all observations: \\[\n\\begin{align}\n\\mathbb{E}[X_{jk}e_i]\n&\\overset{(a)}{=} \\mathbb{E}\\big[\\mathbb{E}[X_{jk}e_i \\mid X_{jk}]\\big] \\\\\n&\\overset{(b)}{=} \\mathbb{E}\\big[X_{jk} \\mathbb{E}[e_i \\mid X_{jk}]\\big]  \\\\\n&\\overset{(c)}{=} 0 \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\forall \\, i,j = 1, \\ldots, n; k = 1, \\ldots, K,\n\\end{align}\n\\tag{5}\\] where \\((a)\\) uses the law of iterated expectations, \\((b)\\) uses the linearity of expectations, and \\((c)\\) follows from the fact that \\[\n\\mathbb{E}[e_i \\mid X_{jk} ]= \\mathbb{E}\\big[\\mathbb{E}[e_i \\mid \\mathbf{X} ] \\mid X_{jk}\\big] =0\n\\] by the generalized law of iterated expectations.\nThe error is uncorrelated with the regressors of all observations: \\[\n\\text{Cov}(e_i, X_{jk})\n\\overset{(a)}{=} \\mathbb{E}[X_{jk}e_i] - \\mathbb{E}[X_{jk}]\\mathbb{E}[e_i]\n\\overset{(b)}{=} \\mathbb{E}[e_iX_{jk}]\n\\overset{(c)}{=} 0\n\\quad \\forall \\, i,j,k,\n\\tag{6}\\] where \\((a)\\) is the definition, \\((b)\\) uses Equation 4, and \\((c)\\) uses Equation 5. Intuitively, this means the error term and regressors do not contain any information about one another.\nThe conditional expectation of \\(\\boldsymbol{Y}\\) given \\(\\mathbf{X}\\), called the regression of \\(\\boldsymbol{Y}\\) on \\(\\mathbf{X}\\), is a linear function of the realized values: \\[\n\\mathbb{E}[\\boldsymbol{Y} \\mid \\mathbf{X}] = \\mathbb{E}[\\mathbf{X}\\beta + \\boldsymbol{e} \\mid \\mathbf{X}]=\\mathbb{E}[{\\mathbf{X}\\beta \\mid  \\mathbf{X}}]=\\mathbf{X}\\beta.\n\\]\n\n\nRestrictiveness of the Assumptions\nThe linearity and no-multicollinearity assumptions are non-trivial in the sense that it is possible for a dataset to violate them. The assumption that the conditional mean of the error is a constant function is also non-trivial, but the fact that this constant equals zero is trivial (i.e. not restrictive) if the linear regression model is of the form \\[\nY_i = \\beta_1 + \\beta_2X_{i2} + \\ldots + \\beta_kX_{iK} + e_i \\quad \\forall \\, i = 1, \\ldots, n.\n\\tag{7}\\]\nIn Equation 7, we set the first regressor to equal one for all observations and thus obtain a constant intercept term \\(\\beta_1\\) in the model. In this setting, if the conditional mean of the error is some non-zero constant \\(\\mu\\), we can simply redefine the intercept term to be \\(\\beta_1^\\star = \\beta_1 + \\mu\\) and the error to be \\(e_i^\\star = e_i - \\mu\\). Then, the conditional mean of the new error \\(e_i^\\star\\) is zero:\n\\[\n\\mathbb{E}[e_i^\\star \\mid \\boldsymbol{X}_1, \\ldots, \\boldsymbol{X}_n] = \\mathbb{E}[e_i - \\mu \\mid \\boldsymbol{X}_1, \\ldots, \\boldsymbol{X}_n] = \\mathbb{E}[e_i \\mid \\boldsymbol{X}_1, \\ldots, \\boldsymbol{X}_n] - \\mu = 0.\n\\]\nFor this reason, it is generally recommended to include a constant intercept term in the linear regression model.\n\n\nImplications of Random Sampling\nRandom sampling has two key implications for the linear regression model. First, it implies that the errors are independent (and therefore uncorrelated) across observations. To see this, first note that under random sampling\n\\[\n(Y_i, \\boldsymbol{X}_i) \\perp (Y_j, \\boldsymbol{X}_j) \\quad \\forall \\, i \\neq j.\n\\] Since independence is preserved under functional transformations, and the error is a function of the outcome and regressors, \\[\ne_i = f(Y_i, \\boldsymbol{X}_i) = Y_i - \\boldsymbol{X}_i\\boldsymbol{\\beta} \\quad \\forall \\, i = 1, \\ldots, n,\n\\]\nit follows that the errors \\(e_i\\) are independent across observations.\nA second implication is that random sampling allows us to simplify the strict exogeneity assumption. Specifically, since random sampling implies4\n\\[\n(e_i, \\boldsymbol{X}_i) \\perp (\\boldsymbol{X}_j) \\quad \\forall \\, i \\neq j,\n\\] it follows that\n\\[\n\\mathbb{E}[e_i \\mid \\boldsymbol{X}_1, \\ldots, \\boldsymbol{X}_n] = \\mathbb{E}[e_i \\mid \\boldsymbol{X}_i] \\quad \\forall \\, i = 1, \\ldots, n.\n\\]\nThus, under random sampling, the strict exogeneity assumption is equivalent to the simpler assumption\n\\[\n\\mathbb{E}[e_i \\mid \\boldsymbol{X}_i] = 0 \\quad \\forall \\, i = 1, \\ldots, n.\n\\]\nIntuitively, random sampling eliminates any cross-sectional dependence between the error term and the regressors of other observations. As a result, the linear regression model only needs to assert that each error \\(e_i\\) is mean independent of its own regressors \\(\\boldsymbol{X}_i\\).\n\n\nWhat is NOT Assumed\nBefore proceeding, it is worth clarifying what we do not assume in the linear regression model. First, we do not assume that \\(Y\\) is a linear function of \\((X_1, \\ldots, X_k)\\) in Equation 1; we only require that the parameters \\(\\boldsymbol{\\beta}\\) enter the equation linearly. This means that we are free to include non-linear transformations of the regressor variables in Equation 1 as long as linearity in \\(\\boldsymbol{\\beta}\\) is preserved (see Equation 10 for an example). Second, we make no assumptions about the distribution of the covariates. Third, we do not make assumptions about the distribution or variance of the error term \\(e\\)."
  },
  {
    "objectID": "blog/lin-reg-model.html#ordinary-least-squares-ols-estimation",
    "href": "blog/lin-reg-model.html#ordinary-least-squares-ols-estimation",
    "title": "The Linear Regression Model and its OLS Estimation",
    "section": "Ordinary Least Squares (OLS) Estimation",
    "text": "Ordinary Least Squares (OLS) Estimation\n\nPrinciple of OLS\nRecall that an estimation method is the guiding principle we follow to construct an estimator — a function that maps the data to the parameters of a statistical model. One common estimation method for the linear regression model is the principle of ordinary least squares (OLS). This method finds the parameter values that minimize the sum of squared differences between the observed outcomes and the part of the outcome explained by the regressors. Formally, the ordinary least squares estimator \\(\\hat{\\boldsymbol{\\beta}}_{OLS}\\) is defined as the solution of the quadratic minimization problem\n\\[\n\\begin{aligned}\n\\hat{\\boldsymbol{\\beta}} &:= \\underset{\\boldsymbol\\beta \\in \\mathbb{R^{k\\times1}}}{\\arg\\min} \\, S(\\boldsymbol\\beta) \\\\\n\\text{where} \\quad S(\\boldsymbol{\\beta}) := \\sum_{i=1}^n (Y_i &- \\boldsymbol{X}_i'\\boldsymbol{\\beta})^2 =  (\\boldsymbol{Y} - \\mathbf{X}\\boldsymbol{\\beta})'(\\boldsymbol{Y} - \\mathbf{X}\\boldsymbol{\\beta}).\n\\end{aligned}\n\\tag{8}\\]\nThe quantity \\(S(\\boldsymbol\\beta)\\) is called the sum of squared errors (SSE). Intuitively, the motivation behind OLS is to choose the parameters such that the fitted outcomes of the form \\(\\hat{Y}_i = \\boldsymbol X_i' \\hat{\\boldsymbol\\beta}\\) lie as close as possible to the observed outcomes \\(Y_i\\) in terms of their total squared vertical distance. This is visualized in Figure 2 below.\n\n\nDeriving the OLS Estimator\nWe choose the OLS estimator to be the solution to the minimization problem in Equation 8. In other words, it is the estimator that satisfies the first-order condition (FOC).5 Using matrix algebra and calculus, the FOC is given by \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial \\boldsymbol\\beta}S(\\boldsymbol\\beta)\n&\\overset{(a)}{=} \\frac{\\partial}{\\partial \\boldsymbol\\beta}\\big( \\boldsymbol Y'\\boldsymbol Y-\\boldsymbol Y'\\boldsymbol X\\boldsymbol \\beta -  (\\boldsymbol X \\boldsymbol \\beta)'\\boldsymbol Y + (\\boldsymbol X \\boldsymbol \\beta)'(\\boldsymbol X \\boldsymbol \\beta) \\big) \\\\\n&\\overset{(b)}{=} \\frac{\\partial}{\\partial \\boldsymbol\\beta} \\big( \\boldsymbol Y'\\boldsymbol Y - \\boldsymbol Y' \\boldsymbol X \\boldsymbol \\beta - \\boldsymbol\\beta ' \\boldsymbol X' \\boldsymbol Y + \\boldsymbol \\beta' \\boldsymbol X' \\boldsymbol X \\boldsymbol \\beta \\big) \\\\\n&\\overset{(c)}{=} \\frac{\\partial}{\\partial \\boldsymbol\\beta} \\big( \\boldsymbol Y'\\boldsymbol Y - \\boldsymbol Y' \\boldsymbol X \\boldsymbol \\beta - (\\boldsymbol Y' \\boldsymbol X \\boldsymbol \\beta)' + \\boldsymbol \\beta' \\boldsymbol X' \\boldsymbol X \\boldsymbol \\beta \\big) \\\\\n&\\overset{(d)}{=} \\frac{\\partial}{\\partial \\boldsymbol\\beta} \\big( \\boldsymbol Y'\\boldsymbol Y - 2(\\boldsymbol Y' \\boldsymbol X \\boldsymbol \\beta) + \\boldsymbol \\beta' \\boldsymbol X' \\boldsymbol X \\boldsymbol \\beta \\big) \\\\\n&\\overset{(e)}{=} -2 \\boldsymbol X' \\boldsymbol Y + 2 \\boldsymbol X' \\boldsymbol X \\boldsymbol \\beta. \\\\\n&= 0,\n\\end{aligned}\n\\]\nwhere \\((a)\\) expands Equation 8, \\((b)\\) follows from \\((\\boldsymbol X \\boldsymbol \\beta)' = \\boldsymbol \\beta' \\boldsymbol X'\\), \\((c)\\) follows from \\((\\boldsymbol Y' \\boldsymbol X \\boldsymbol \\beta)' = \\boldsymbol \\beta' \\boldsymbol X' \\boldsymbol Y\\), \\((d)\\) uses the fact that the scalar \\(\\boldsymbol Y' \\boldsymbol X \\boldsymbol \\beta\\) equals its transpose, and \\((e)\\) applies the following matrix calculus results:\n\\[\n\\frac{\\partial}{\\partial \\boldsymbol b}(\\boldsymbol a' \\boldsymbol b) = \\boldsymbol a \\quad \\text{and} \\quad \\frac{\\partial}{\\partial \\boldsymbol b}(\\boldsymbol b' \\boldsymbol A \\boldsymbol b) = 2\\boldsymbol A\\boldsymbol b,\n\\] for any conformable vectors \\(\\boldsymbol a, \\boldsymbol b\\) and any conformable symmetric matrix \\(\\boldsymbol A\\).\nRearranging the FOC above, we see that the OLS estimator satisfies the least squares normal equations \\[\n\\boldsymbol X' \\boldsymbol X \\hat{\\boldsymbol \\beta}_{OLS}  = \\boldsymbol X' \\boldsymbol Y.\n\\] Since the matrix \\(\\boldsymbol X' \\boldsymbol X\\) is invertible, we have the the following closed form representation of the OLS estimator\n\\[\n\\hat{\\boldsymbol\\beta}_{OLS} = (\\boldsymbol X' \\boldsymbol X)^{-1} \\boldsymbol X' \\boldsymbol Y.\n\\tag{9}\\]"
  },
  {
    "objectID": "blog/lin-reg-model.html#example-ols-in-action",
    "href": "blog/lin-reg-model.html#example-ols-in-action",
    "title": "The Linear Regression Model and its OLS Estimation",
    "section": "Example: OLS in Action",
    "text": "Example: OLS in Action\nThe phrase “OLS fits the best line to the data” is often used to describe what the OLS estimator does. However, this language is a bit loose and perpetuates the common misconception that the least squares estimation method can only fit a straight line to the data. In reality, the functional form of the relationship between \\(Y\\) and \\(X\\) is entirely determined by the researcher’s choice of regressors to include when specifying the model. Least squares simply chooses the linear combination of those regressors that best fits the data in terms of minimizing the total squared vertical distance to the observed outcomes.\nLet’s walk through a simple example to illustrate this point. Suppose we observe the following dataset:\n\n\nShow code\nset.seed(42)\n\n# Simulated data\nn  &lt;- 30\nX  &lt;- seq(-3, 3, length.out = n)\nY  &lt;- 2 + 0.5 * X^2 + rnorm(n, 0, 1)\n\ndf &lt;- data.frame(X = X, Y = Y)\n\n# Plot the observed data\nggplot(df, aes(X, Y)) +\n  geom_point(color = \"black\", shape = 4, size = 2) +\n  labs(x = \"X\", y = \"Y\") +\n  theme_classic() +\n  theme(panel.border = element_rect(color = \"black\", fill = NA))\n\n\n\n\n\n\n\n\nFigure 1: Observed Data with Nonlinear Relationship Between Outcome and Regressor\n\n\n\n\n\nThe scatter plot in Figure 1 suggests that the functional form of the relationship between \\(Y\\) and \\(X\\) is approximately a quadratic function. Thus, we can specify the linear regression model as \\[\nY = \\beta_1 + \\beta_2 X + \\beta_3 X^2 + e.\n\\tag{10}\\]\nThe next step is to estimate the parameters \\(\\beta_1, \\beta_2, \\beta_3\\) using the principle of ordinary least squares. We can do this using the lm function in R.\n\nfit &lt;- lm(Y ~ X + I(X^2), data = df)\nprint(fit)\n\n\nCall:\nlm(formula = Y ~ X + I(X^2), data = df)\n\nCoefficients:\n(Intercept)            X       I(X^2)  \n     1.9706      -0.1942       0.5306  \n\n\nThese numbers correspond to what we would get if we applied Equation 9 to the data.\n\nX &lt;- cbind(1, df$X, (df$X)^2)                     # Design matrix\nY &lt;- df$Y                                         # Outcome vector\nbeta_hat &lt;- solve(crossprod(X), crossprod(X, Y))  # Solves (X'X) b = X'Y\nc((beta_hat[1]), (beta_hat[2]), (beta_hat[3]))\n\n[1]  1.9705793 -0.1941996  0.5305615\n\n\nThe benefit of using the lm function is that it also can report inferential statistics — such as, the p-value, standard error, etc. — for the estimates. The meaning of these quantities is discussed in this post.\n\nsummary(fit)\n\n\nCall:\nlm(formula = Y ~ X + I(X^2), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.5348 -0.4087 -0.1239  0.7664  2.1883 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.97058    0.34115   5.776 3.82e-06 ***\nX           -0.19420    0.12688  -1.531    0.138    \nI(X^2)       0.53056    0.07935   6.686 3.54e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.245 on 27 degrees of freedom\nMultiple R-squared:  0.6354,    Adjusted R-squared:  0.6084 \nF-statistic: 23.53 on 2 and 27 DF,  p-value: 1.216e-06\n\n\nFinally, we can visualize the estimation results. In Figure 2, the black crosses are the observed data points, the red curve is a plot of the fitted function \\[\n\\hat{Y}_i = \\hat{\\beta}_1 + \\hat{\\beta}_2 X_i + \\hat{\\beta}_3 X_i^2\n\\]\nin the \\(X-Y\\) plane, and the vertical dotted lines represent the residuals \\(e_i = Y_i - \\hat{Y}_i\\).\n\n\nShow code\n# Fitted values\ndf$Yhat &lt;- fitted(fit)\n\n# Smooth curve for plotting (only over observed range)\nxg   &lt;- seq(min(df$X), max(df$X), length.out = 400)\ngrid &lt;- data.frame(X = xg)\ngrid$Yhat &lt;- predict(fit, newdata = grid)\n\n# Plot\nggplot(df, aes(X, Y)) +\n  geom_point(aes(color = \"Observed Data\"), shape = 4, size = 2) +\n  geom_segment(aes(x = X, xend = X,\n                   y = pmin(Y, Yhat), yend = pmax(Y, Yhat)),\n               linetype = \"dotted\", linewidth = 0.4, color = \"blue\") +\n  geom_line(data = grid, aes(y = Yhat, color = \"OLS Best Fit Curve\"), linewidth = 1) +\n  scale_color_manual(values = c(\"Observed Data\" = \"black\",\n                                \"OLS Best Fit Curve\" = \"red\"),\n                     breaks = c(\"Observed Data\", \"OLS Best Fit Curve\"),\n                     name = NULL) +\n  labs(x = \"X\", y = \"Y\") +\n  coord_cartesian(xlim = range(df$X)) +  # avoid accidental extrapolation\n  theme_classic() +\n  theme(panel.border = element_rect(color = \"black\", fill = NA)) +\n  theme(\n    legend.position = c(0.15, 0.18),\n    legend.background = element_blank(),\n    legend.key = element_blank()\n  )\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\nFigure 2: OLS Estimation for Linear Regression Model with Quadratic Regressor"
  },
  {
    "objectID": "blog/lin-reg-model.html#footnotes",
    "href": "blog/lin-reg-model.html#footnotes",
    "title": "The Linear Regression Model and its OLS Estimation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis post discuses the big picture intuition for statistical modeling and inference in more detail.↩︎\nThere is some notational ambiguity here. Any bold, italicized letter represents a vector. Any bold, upright letter represents a matrix. So, \\(\\boldsymbol{X}_i\\) refers to the vector of random regressor variables \\((X_{i1}, \\ldots, X_{ik})\\), while \\(\\mathbf{X}\\) refers to the design matrix.↩︎\nBecause in any given row of the design matrix, the column entries are linearly independent of one another.↩︎\nThis is again because \\((e_i, \\boldsymbol X_i)\\) and \\(\\boldsymbol X_j\\) are simply functional transformations of the outcome and regressors.↩︎\nTechnically we have to also check the second order condition as well. But this follows from the fact that \\(\\boldsymbol{X}\\) has a full column rank, and so \\(\\boldsymbol X' \\boldsymbol X\\) is positive definite.↩︎"
  },
  {
    "objectID": "blog/linear-regression.html",
    "href": "blog/linear-regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "Much of modern empirical economics research can be understood as an organized attempt to answer variants of the causal question: “How does \\(X\\) affect \\(Y\\)?” For example, Eissa and Liebman (1996) ask how taxes affect labor supply; Donaldson and Hornbeck (2016) ask how railroads affect economic growth; Angrist and Krueger (1991) ask how the education affects earnings, and so on.\nFormally, we view \\(X\\) and \\(Y\\) as random variables jointly distributed according to some fixed, unknown distribution \\(F\\), called the data generating process (DGP).1 To study questions like the ones posed above, we are especially interested in a particular feature of the DGP: the conditional expectation function (CEF), \\[\n\\mu(x) \\equiv \\mathbb{E}[Y \\mid X = x].\n\\] The CEF summarizes the average association between \\(X\\) and \\(Y\\) implied by the DGP. Since the DGP is unknown and typically high-dimensional, the CEF is also unknown and potentially complicated.2 3\n1 Also called the population.2 High-dimensional here refers to the fact that \\(X\\) can be a vector of many random variables.3 Also, since the DGP is fixed, the CEF is a deterministic function as well.4 See this for a review of frequentist statistical inference and this for a review of point estimation.To be clear, the CEF by itself is purely a descriptive object: it captures statistical associations, not causal effects. Under additional assumptions, however, the CEF can be given a causal interpretation. For now, we defer any discussion of causality and instead focus on estimating \\(\\mu(x)\\).4 Understanding how to estimate the CEF well is nevertheless an essential step towards answering the bigger question of causality.\n\n\nMotivating the CEF purely through its potential causal interpretation might be unsatisfying. As it turns out, the CEF also has a fundamental statistical property in its own right: \\(\\mu(x)\\) is the best predictor of \\(Y\\) given \\(X\\).\nThere are different ways to define the notion of “best”. Here, we specifically mean that the CEF minimizes the mean squared error (MSE) function: \\[\n\\mu(x) = \\arg\\min_{g(x)} \\mathbb{E}[(Y - g(x))^2],\n\\] where \\(g(x)\\) is any arbitrary function evaluated at \\(X = x\\). To see this, let’s start by defining the CEF error \\[\ne \\equiv Y - \\mu(x).\n\\tag{1}\\] By definition, we have that \\(e\\) is mean-independent of \\(X\\): \\[\n\\begin{align}\n\\mathbb{E}[e \\mid X] &= \\mathbb{E}[(Y-\\mu(x)) \\mid X] \\\\\n&= \\mathbb{E}[Y \\mid X] - \\mathbb{E}[\\,\\mu(x) \\mid X] \\\\\n&= \\mu(x) - \\mu(x) = 0.\n\\end{align}\n\\tag{2}\\]\nIt immediately follows that \\(e\\) has mean-zero \\[\n\\mathbb{E}[e] = \\mathbb{E}[\\mathbb{E}[e \\mid X]] = 0,\n\\tag{3}\\] is orthogonal with any function of \\(X\\) \\[\n\\begin{align}\n\\mathbb{E}[h(X)e] &= \\mathbb{E} [\\mathbb{E}[h(X) \\, e\\mid X]] \\\\ &= \\mathbb{E}[h(X)\\,  \\mathbb{E}[e \\mid X]] = 0,\n\\end{align}\n\\tag{4}\\] and is uncorrelated with any function of \\(X\\) \\[\n\\operatorname{Cov}(e,h(X))=\\mathbb{E}\\,[h(X)\\, e] - \\mathbb{E}[h(X)]\\mathbb{E}[e] = 0.\n\\tag{5}\\]\nNow, consider the MSE of any arbitrary predictor \\(g(x)\\):\n\\[\n\\begin{align}\n\\mathbb{E}[(Y - g(x))^2] &= \\mathbb{E}[(e + \\mu(x) - g(x))^2] \\\\\n&= \\mathbb{E}[e^2] + 2\\,\\mathbb{E}[(\\mu(x) - g(x))\\, e] + \\mathbb{E}[(\\mu(x) - g(x))^2] \\\\\n&=\\mathbb{E}[e^2] + \\mathbb{E}[(\\mu(x) - g(x))^2]  \\\\\n&\\geq \\mathbb{E}[e^2] \\\\\n&= \\mathbb{E}[(Y - \\mu(x))^2].\n\\end{align}\n\\] Thus, the MSE for any predictor \\(g(x)\\) is at least as large as that for the CEF \\(\\mu(x)\\), proving that the CEF is indeed the best predictor of \\(Y\\) given \\(X\\) (in the MSE sense)."
  },
  {
    "objectID": "blog/linear-regression.html#the-conditional-expectation-function",
    "href": "blog/linear-regression.html#the-conditional-expectation-function",
    "title": "Linear Regression",
    "section": "",
    "text": "Much of modern empirical economics research can be understood as an organized attempt to answer variants of the causal question: “How does \\(X\\) affect \\(Y\\)?” For example, Eissa and Liebman (1996) ask how taxes affect labor supply; Donaldson and Hornbeck (2016) ask how railroads affect economic growth; Angrist and Krueger (1991) ask how the education affects earnings, and so on.\nFormally, we view \\(X\\) and \\(Y\\) as random variables jointly distributed according to some fixed, unknown distribution \\(F\\), called the data generating process (DGP).1 To study questions like the ones posed above, we are especially interested in a particular feature of the DGP: the conditional expectation function (CEF), \\[\n\\mu(x) \\equiv \\mathbb{E}[Y \\mid X = x].\n\\] The CEF summarizes the average association between \\(X\\) and \\(Y\\) implied by the DGP. Since the DGP is unknown and typically high-dimensional, the CEF is also unknown and potentially complicated.2 3\n1 Also called the population.2 High-dimensional here refers to the fact that \\(X\\) can be a vector of many random variables.3 Also, since the DGP is fixed, the CEF is a deterministic function as well.4 See this for a review of frequentist statistical inference and this for a review of point estimation.To be clear, the CEF by itself is purely a descriptive object: it captures statistical associations, not causal effects. Under additional assumptions, however, the CEF can be given a causal interpretation. For now, we defer any discussion of causality and instead focus on estimating \\(\\mu(x)\\).4 Understanding how to estimate the CEF well is nevertheless an essential step towards answering the bigger question of causality.\n\n\nMotivating the CEF purely through its potential causal interpretation might be unsatisfying. As it turns out, the CEF also has a fundamental statistical property in its own right: \\(\\mu(x)\\) is the best predictor of \\(Y\\) given \\(X\\).\nThere are different ways to define the notion of “best”. Here, we specifically mean that the CEF minimizes the mean squared error (MSE) function: \\[\n\\mu(x) = \\arg\\min_{g(x)} \\mathbb{E}[(Y - g(x))^2],\n\\] where \\(g(x)\\) is any arbitrary function evaluated at \\(X = x\\). To see this, let’s start by defining the CEF error \\[\ne \\equiv Y - \\mu(x).\n\\tag{1}\\] By definition, we have that \\(e\\) is mean-independent of \\(X\\): \\[\n\\begin{align}\n\\mathbb{E}[e \\mid X] &= \\mathbb{E}[(Y-\\mu(x)) \\mid X] \\\\\n&= \\mathbb{E}[Y \\mid X] - \\mathbb{E}[\\,\\mu(x) \\mid X] \\\\\n&= \\mu(x) - \\mu(x) = 0.\n\\end{align}\n\\tag{2}\\]\nIt immediately follows that \\(e\\) has mean-zero \\[\n\\mathbb{E}[e] = \\mathbb{E}[\\mathbb{E}[e \\mid X]] = 0,\n\\tag{3}\\] is orthogonal with any function of \\(X\\) \\[\n\\begin{align}\n\\mathbb{E}[h(X)e] &= \\mathbb{E} [\\mathbb{E}[h(X) \\, e\\mid X]] \\\\ &= \\mathbb{E}[h(X)\\,  \\mathbb{E}[e \\mid X]] = 0,\n\\end{align}\n\\tag{4}\\] and is uncorrelated with any function of \\(X\\) \\[\n\\operatorname{Cov}(e,h(X))=\\mathbb{E}\\,[h(X)\\, e] - \\mathbb{E}[h(X)]\\mathbb{E}[e] = 0.\n\\tag{5}\\]\nNow, consider the MSE of any arbitrary predictor \\(g(x)\\):\n\\[\n\\begin{align}\n\\mathbb{E}[(Y - g(x))^2] &= \\mathbb{E}[(e + \\mu(x) - g(x))^2] \\\\\n&= \\mathbb{E}[e^2] + 2\\,\\mathbb{E}[(\\mu(x) - g(x))\\, e] + \\mathbb{E}[(\\mu(x) - g(x))^2] \\\\\n&=\\mathbb{E}[e^2] + \\mathbb{E}[(\\mu(x) - g(x))^2]  \\\\\n&\\geq \\mathbb{E}[e^2] \\\\\n&= \\mathbb{E}[(Y - \\mu(x))^2].\n\\end{align}\n\\] Thus, the MSE for any predictor \\(g(x)\\) is at least as large as that for the CEF \\(\\mu(x)\\), proving that the CEF is indeed the best predictor of \\(Y\\) given \\(X\\) (in the MSE sense)."
  },
  {
    "objectID": "blog/linear-regression.html#the-curse-of-dimensionality",
    "href": "blog/linear-regression.html#the-curse-of-dimensionality",
    "title": "Linear Regression",
    "section": "The Curse of Dimensionality",
    "text": "The Curse of Dimensionality\nLet’s return to the problem of estimating the CEF, wherein we want to make a good guess of \\(\\mu(x)\\) using the finite random sample \\(\\{X_i,Y_i\\}_{i=1}^n\\) drawn from the DGP \\(F\\). Recall that a natural method of estimation is the plug-in principle, where we construct the estimator by replacing population quantities with their sample analogues. In this case, the plug-in estimator is the sample conditional mean \\[\nB(x) = \\frac{\\sum_{i=1}^n Y_i \\, \\mathbf{1}(X_i=x)}{\\sum_{i=1}^n \\mathbf{1}(X_i=x)}.\n\\] We refer to \\(B(x)\\) as the binning estimator because it groups (“bins”) the sample by the values of \\(X_i\\) and takes the simple average of \\(Y_i\\) within each bin. The binning estimator is random since it is a function of the random sample.5 When evaluated for a specific realized sample — that is, for the data \\(\\{x_i,y_i\\}_{i=1}^n\\) that we actually observe — the binning estimate is the fixed scalar \\[\n{b}(x) = \\frac{\\sum_{i=1}^n y_i \\, \\mathbf{1}(x_i=x)}{\\sum_{i=1}^n \\mathbf{1}(x_i=x)}.\n\\]\n5 A different draw from \\(F\\) could have resulted in a different realization of \\(X_i\\).6 The notation here implicitly assumes \\(X_i\\) is discrete. To extend it to the continuous case, we would simply replace the equality with a set membership condition.The binning estimator suffers from what is called the curse of dimensionality: as the dimension of \\(X_i\\) increases, the effective sample size of each bin \\[\n\\begin{align}\n\\mathbb{E}\\left[\\sum_{i=1}^n \\boldsymbol 1 (X_i = x)\\right] &\\equiv n \\times \\mathbb{P}(X_i=x) \\\\ &= n \\prod_{j=1}^d \\mathbb{P}(X_{ij} = x_j)\n\\end{align}\n\\] decreases.6 As a result, most bins contain very few — or even zero — observations, making the binning estimator very noisy or undefined. To illustrate this idea, consider the following simulation. Draw a random sample of size \\(n=2000\\) from the following DGP: \\[\n\\begin{align}\nX_i &\\overset{iid}{\\sim} (Bernoulli(0.5))^K, \\quad i=1,\\ldots,n, \\\\\n\\\\\nY_i = \\mu(x) &+ e_i, \\quad \\mu(x) = \\sum_{j=1}^K (X_{ij} = x_j), \\quad e_i \\overset{iid}{\\sim} N(0,1).\n\\end{align}\n\\] To assess the performance of the binning estimator as the dimension \\(K\\) of \\(X_i\\) increases, we can examine the empirical bias and variance of \\(B(x)\\) evaluated at the bin \\(x=(1,1,\\ldots,1)\\) across \\(10000\\) repeated samples.\nAs the figure above shows, the binned estimator remains unbiased regardless of the dimension \\(K\\), but its variance increases exponentially with \\(K\\). This occurs because the probability of being in the bin, \\(\\mathbb{P}(X_i = x)\\), decreases exponentially towards \\(0\\) as \\(K\\) increases, causing the effective sample size used to compute \\(b(x)\\) to shrink rapidly. Thus, the more variables we condition on, the less data we have to estimate each conditional mean, regardless of how large the overall sample size is.\nThe curse of dimensionality arises because \\(B(x)\\) requires observing the specific value \\(X_i = x\\) to say anything about \\(\\mu(x)\\). A natural solution, then, is to relax this requirement and use \\(X_i \\neq x\\) to inform our estimate of \\(\\mu(x)\\). Non-parametric approaches consider “near-by” values of \\(X_i\\) to \\(x\\), and use a weighted average of the corresponding \\(Y_i\\) to estimate \\(\\mu(x)\\). Parametric approaches instead impose a functional form on \\(\\mu(x)\\) and use all values of \\(X_i\\) to estimate \\(\\mu(x)\\). In what follows, we focus on the simplest and most widely used parametric specification — one where \\(\\mu(x)\\) is a linear function of \\(x\\)."
  },
  {
    "objectID": "blog/linear-regression.html#linear-regression-as-a-statistical-model",
    "href": "blog/linear-regression.html#linear-regression-as-a-statistical-model",
    "title": "Linear Regression",
    "section": "Linear Regression: As a Statistical Model",
    "text": "Linear Regression: As a Statistical Model\nWe are interested in estimating the CEF \\(\\mu(x)\\). Recall that performing point estimation within a statistical model — that is, a set of assumptions about the DGP — is often more informative than proceeding with no assumptions at all, because it allows us to characterize the sampling distribution of the estimator.7 In this section, we will develop the linear regression model: a statistical model that assumes \\(\\mu(x)\\) is a linear function of \\(x\\) and results in an estimator with appealing asymptotic properties.\n7 Of course, working within a model is “more informative” only if the model is a good approximation of reality.Before proceeding, it’s useful to clarify the notation we will use going forward. For unit \\(i\\) in the random sample, the regressand \\(Y_i\\) denotes the outcome of interest and the vector of regressors \\(X_i \\equiv [X_{i1}, \\ldots, X_{iK}]'\\) denotes the set of variables that we condition on. The corresponding realizations of the random sample is denoted by the scalar \\(y_i\\) and vector \\(x_i \\equiv [x_{i1}, \\ldots, x_{iK}]'\\). The vector \\(x \\equiv [x_1, \\ldots, x_K]'\\) denotes the specific regressor values at which we want to evaluate the CEF \\(\\mu(x) \\equiv \\mathbb{E}[Y_i \\mid X_i = x]\\).\n\nDefining the Model\nThe linear regression model is commonly defined by the following two fundamental assumptions about the underlying data-generating process.8 9 10\n8 I omit (i) technical assumptions needed to ensure the estimator of the model parameters are well-defined, and (ii) additional “classical” assumptions about the error term that are needed to derive finite-sample properties of the estimator. These assumptions are introduced later in the post as necessary.9 Older econometrics textbooks typically impose the “strict exogeneity” assumption, where we condition on \\(X_1, \\ldots, X_n\\) instead of only \\(X_i\\). However, under iid sampling, conditioning on \\(X_i\\) implies the stricter condition because of independence.10 Technically, the linear regression model should be introduced without the \\(i\\) subscripts, since the assumptions are about the DGP. However, under iid sampling, the assumptions must hold for each unit \\(i\\) as well. Moreover, the unit-level notation will be useful when deriving the estimator of the coefficients.\nAssumption 1. The Linear Regression Model (Traditional Formulation)\n(A) (Linearity) The regressand \\(Y_i\\) is a linear combination of the regressors \\(X_{i1}, \\ldots, X_{iK}\\), plus some random variable \\(e_i\\) called the error: \\[\nY_i = \\beta_1X_{i1} + \\ldots + \\beta_KX_{iK} + e_i \\quad \\forall \\, i = 1, \\ldots, n.\n\\tag{6}\\]\n(B) (Exogeneity) The error \\(e_i\\) has a conditional mean of zero given the regressors of all observations: \\[\n\\mathbb{E}[e_i \\mid X_i] = 0 \\quad \\forall \\, i = 1, \\ldots, n.\n\\tag{7}\\]\n\nTaken together, assumptions (A) and (B) imply that the CEF is a linear function of \\(x\\): \\[\n\\begin{align}\n\\mu(x) &= \\mathbb{E}[\\beta_1X_{i1} + \\ldots + \\beta_KX_{iK} + e_i \\mid X_i = x] \\\\\n&= \\beta_1 x_1 + \\ldots + \\beta_K x_K + \\mathbb{E}[e_i \\mid X_i = x] \\\\\n&= \\beta_1 x_1 + \\ldots + \\beta_K x_K \\\\\n&= x' \\beta,\n\\end{align}\n\\tag{8}\\] where \\(\\beta \\equiv [\\beta_1, \\ldots, \\beta_K]'\\) is the vector of coefficients.\nHowever, since our focus is on using the linear regression model to estimate the CEF, it is natural to treat Equation 8 as the defining assumption of the model.\n\nAssumption 2. The Linear Regression Model (CEF Formulation)\nThere exists a fixed coefficient vector \\(\\beta \\in \\mathbb{R}^K\\) such that the conditional expectation function of \\(Y_i\\) given \\(X_i = x\\) is linear in \\(x\\): \\[\n\\mu(x) \\equiv \\mathbb{E}[Y_i \\mid X_i = x] = x' \\beta \\quad \\forall \\, x \\in \\mathbb{R}^K.\n\\tag{9}\\]\n\nAs in Equation 1, we can define the linear regression error as\n\\[\ne_i \\equiv Y_i - X_i' \\beta.\n\\tag{10}\\]\nWe can now recover Equation 6 by simply rearranging the above definition. Additionally, the assumption in Equation 9 and the definition in Equation 10 together imply that the previously discussed properties of the CEF error \\(e\\) all hold for the linear regression error \\(e_i\\). Specifically, \\(e_i\\) is mean-independent, has mean-zero, and is orthogonal and uncorrelated to any function of \\(X_i\\). The proofs are omitted because they are the same as before (see Equation 2, Equation 3, Equation 4, Equation 5).\n\n\nInterpreting the Assumptions\nIt’s worth spending a moment to understand what exactly is (and is not) being assumed in the linear regression model. The assumption of linearity states that (i) \\(Y_i\\) is a linear function of \\(X_i\\) in terms of the coefficients \\(\\beta\\), and (ii) the error \\(e_i\\) is additive. Both these assumptions are non-trivial in the sense that they can be violated in practice. For example, it is entirely possible that the true DGP is given by a function like \\[\nY_i = \\exp(\\beta X_{i}) \\times e_i, \\quad e_i \\sim N(0,\\sigma^2).  \n\\] Nevertheless, the linearity assumption is not as restrictive as it may seem at first glance. Consider the figure below, which plots data where the CEF seems to be approximately exponential (i.e. non-linear) in the univariate regressor \\(X_{i1}\\). The blue plot corresponds to the CEF estimated using the linear regression model \\[\nY_i = \\beta_1 X_{i1} + e_i.\n\\] It’s obvious that this model is unlikely to reflect the true DGP. However, observe that nothing prevents us from adding non-linear functions of \\(X_{i1}\\) to our regression model. For example, the pink plot corresponds to the CEF estimated using a linear regression model that includes both \\(X_{i1}\\) and \\(\\exp(X_{i1})\\) as regressors: \\[\nY_i = \\beta_1 X_{i1} + \\beta_2 \\exp(X_{i1}) + e_i.\n\\] This fits the data much better while preserving linearity in the coefficients. Alternatively, the orange plot is the CEF estimated using the polynomial regression model \\[\nY_i = \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i1}^2 + \\beta_3 X_{i1}^3 + \\beta_4 X_{i1}^4 + e_i.\n\\] This also preserves linearity while fitting the data well. The overall point here is that the functional form of the CEF \\(\\mu(x)\\) in terms of the regressors \\(X_i\\) is very flexible despite the linearity assumption.\n\n\n\n\n\n\n\n\n\n\n\nSolving for the (Population) Coefficients\n\nMatrix Notation\nFor notational compactness, it is useful to recast the model in matrix notation. First note that we can stack Equation 6 as a system of \\(n\\) equations\n\\[\n\\begin{aligned}\nY_1 &= \\beta_1 X_{11} + \\ldots + \\beta_k X_{1K} + e_1 = {X}_1'{\\beta} + e_1\\\\\\\nY_2 &= \\beta_1 X_{21}+ \\ldots + \\beta_k X_{2K} + e_2 = {X}_2'{\\beta} + e_2 \\\\\n&\\;\\;\\vdots \\\\\nY_n &= \\beta_1X_{n1} + \\ldots + \\beta_k X_{nK} + e_n= {X}_n'{\\beta} + e_n,\n\\end{aligned}\n\\] where \\(\\beta \\equiv [\\beta_1, \\ldots, \\beta_K]'\\) denotes the vector of coefficients.\nNow, we can collapse this system of equations into a single matrix equation \\[\n{Y} = \\mathbf{X}\\beta + e,\n\\tag{11}\\] where the \\(n \\times K\\) design matrix (or data matrix) stacks the regressors \\(X_i'\\) of all units: \\[\n\\mathbf{X} = \\begin{bmatrix} {X}_1' \\\\ \\vdots \\\\ {X}_n' \\end{bmatrix} = \\begin{bmatrix} X_{11} & \\ldots & X_{1K} \\\\ \\vdots & \\ddots & \\vdots \\\\ X_{n1} & \\ldots & X_{nK} \\end{bmatrix}.\n\\]\n\n\n\nDeriving the Analog Estimator of the Coefficients"
  },
  {
    "objectID": "blog/linear-regression.html#linear-regression-as-the-best-linear-predictor",
    "href": "blog/linear-regression.html#linear-regression-as-the-best-linear-predictor",
    "title": "Linear Regression",
    "section": "Linear Regression: As the Best Linear Predictor",
    "text": "Linear Regression: As the Best Linear Predictor"
  },
  {
    "objectID": "blog/linear-regression.html#linear-regression-as-the-best-linear-approximation",
    "href": "blog/linear-regression.html#linear-regression-as-the-best-linear-approximation",
    "title": "Linear Regression",
    "section": "Linear Regression: As the Best Linear Approximation",
    "text": "Linear Regression: As the Best Linear Approximation"
  },
  {
    "objectID": "blog/linear-regression.html#synthesizing-the-three-perspectives",
    "href": "blog/linear-regression.html#synthesizing-the-three-perspectives",
    "title": "Linear Regression",
    "section": "Synthesizing the Three Perspectives",
    "text": "Synthesizing the Three Perspectives"
  },
  {
    "objectID": "blog/global-test.html",
    "href": "blog/global-test.html",
    "title": "Multiple Inference",
    "section": "",
    "text": "Following the empirical example in Duflo, Dupas, and Kremer (2011), we are interested in estimating the following regression model \\[\nY_{ij} = \\alpha T_j + \\boldsymbol X'_{ij} \\boldsymbol \\beta + e_{ij} \\quad i = 1, \\ldots, n_j \\quad j = 1, \\ldots, J,\n\\tag{1}\\] where \\(Y_{ij}\\) is the test score of student \\(i\\) in school \\(j\\), \\(T_j\\) is a binary variable indicating whether or not school \\(j\\) was tracking, and \\(\\boldsymbol X'_{ij}\\) is a \\(d_x \\times 1\\) vector that includes a constant and other student and school control variables.\nThe schools record each student’s score on \\(d_y\\) separate sections of the test. Suppose we are interested in estimating separate regressions of the form in Equation 1 for each of these test scores. Let \\(\\boldsymbol Y_{ij} \\equiv \\begin{bmatrix} Y_{ij1}, \\ldots, Y_{ijd_y} \\end{bmatrix}'\\) , \\(\\boldsymbol \\alpha \\equiv \\begin{bmatrix} \\alpha_1, \\ldots, \\alpha_{d_y} \\end{bmatrix}'\\), \\(\\mathbf{B} \\equiv \\begin{bmatrix} \\beta_1', \\ldots, \\beta_{d_y}' \\end{bmatrix}'\\), \\(\\boldsymbol e_{ij} \\equiv \\begin{bmatrix} e_{ij1} \\ldots, e_{ijd_y} \\end{bmatrix}'\\). Then we can write the system of \\(d_y\\) regressions as \\[\n\\boldsymbol Y_{ij} = \\boldsymbol \\alpha T_j + \\boldsymbol X'_{ij} \\mathbf{B} + \\boldsymbol e_{ij} \\quad i = 1, \\ldots, n_j \\quad j = 1, \\ldots, J.\n\\]\n\n\nCode\n* Load the data\nglobal data \"~/Git/vigneshsomjit.github.io/hasen-econometrics-datasets/DDK2011\"\nuse \"$data/DDK2011.dta\", clear\n\n* Store variables in macros\nlocal outcomes wordscore sentscore letterscore spellscore additions_score substractions_score multiplications_score\nlocal controls agetest girl bottomhalf etpteacher lowstream\nlocal treatment tracking\n\n* Loop over outcomes \nforeach y of local outcomes {\n    * Store inverse of SD of control group\n    quietly sum `y' if `treatment' == 0\n    local scale = 1/r(sd)\n    \n    * Estimate the regression and scale the coefficient\n    quietly reg `y' `treatment' `controls', vce(cluster schoolid)\n    quietly lincom `treatment' * `scale'\n    \n    * Store the results \n    local b = r(estimate)\n    local se = r(se)\n    local t = r(t)\n    local p = r(p)\n    \n    * Append to matrix \n    matrix effects = nullmat(effects) \\ (`b', `se', `t', `p')\n}\n\n*Label matrix \nmatrix colnames effects = coef se t p\nmatrix rownames effects = `outcomes'\n\nmatrix list effects\n\n\n\n\n\n\neffects[7,4]\n                   coef         se          t          p\n   wordscore  .14447841  .10102279  1.4301567   .1555064\n   sentscore  .10568769  .08410808    1.25657  .21157131\n letterscore  .26383718  .09923162  2.6588015    .009012\n  spellscore  .16041144  .10070153  1.5929394  .11404336\nadditions_~e  .16563474  .07356356  2.2515869  .02633487\nsubstracti~e  .10596988  .06667975  1.5892363  .11487721\nmultiplica~e  .10575871  .06536277  1.6180268  .10852081"
  }
]